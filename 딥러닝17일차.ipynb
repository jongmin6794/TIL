{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist 분류\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-0282ce62f2e7>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "#one_hot 원핫 인코딩 상태로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tf.Variable(tf.random_normal([784,10]))\n",
    "b=tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf=tf.nn.softmax(tf.matmul(x,w)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=tf.reduce_mean(-tf.reduce_sum(y*tf.log(hf),axis=1))\n",
    "train= tf.train.GradientDescentOptimizer(0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "isCorrect=tf.equal(tf.argmax(hf,1),tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=tf.reduce_mean(tf.cast(isCorrect,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs=15\n",
    "batchSize=100\n",
    "numIter = int(mnist.train.num_examples/batchSize)\n",
    "# 60000 / 100 = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭:0001, cost:2.785632732\n",
      "에폭:0002, cost:1.108958920\n",
      "에폭:0003, cost:0.883038990\n",
      "에폭:0004, cost:0.771663821\n",
      "에폭:0005, cost:0.703109534\n",
      "에폭:0006, cost:0.652969799\n",
      "에폭:0007, cost:0.615393525\n",
      "에폭:0008, cost:0.585987460\n",
      "에폭:0009, cost:0.561219451\n",
      "에폭:0010, cost:0.540234084\n",
      "에폭:0011, cost:0.522381218\n",
      "에폭:0012, cost:0.506761632\n",
      "에폭:0013, cost:0.493253635\n",
      "에폭:0014, cost:0.480946563\n",
      "에폭:0015, cost:0.469640679\n",
      "정확도: 0.8874\n",
      "레이블: [7]\n",
      "예측: [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #트레이닝\n",
    "    for epoch in range(numEpochs):#15에폭\n",
    "        avgCv=0\n",
    "        for i in range(numIter):#600\n",
    "            batchX,batchY=mnist.train.next_batch(batchSize)\n",
    "            _,cv=sess.run([train,cost],feed_dict={x:batchX,y:batchY})\n",
    "            avgCv+=cv/numIter\n",
    "        print(\"에폭:{:04d}, cost:{:.9f}\".format(epoch+1,avgCv))\n",
    "    print(\"정확도:\",accuracy.eval(session=sess,feed_dict={x:mnist.test.images,y:mnist.test.labels}))\n",
    "    \n",
    "    r=random.randint(0,mnist.test.num_examples-1)\n",
    "    print(\"레이블:\",sess.run(tf.argmax(mnist.test.labels[r:r+1],1)))\n",
    "    print(\"예측:\",sess.run(tf.argmax(hf,1),feed_dict={x:mnist.test.images[r:r+1]}))\n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28),cmap='Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 모델 저장/불러오기 (케라스 버전으로 해보기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다층퍼셉트론 모델\n",
    "# 훈련셋, 검증셋, 시험셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain,yTrain),(xTest,yTest)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리\n",
    "xTrain=xTrain.reshape(60000,784).astype('float32')/255.0\n",
    "xTest=xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain=np_utils.to_categorical(yTrain)#원 핫 인코딩\n",
    "yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest=np_utils.to_categorical(yTest)\n",
    "yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "xVal=xTrain[42000:]\n",
    "xTrain=xTrain[:42000]\n",
    "yVal=yTrain[42000:]\n",
    "yTrain=yTrain[:42000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#모델 구성\n",
    "model=Sequential()\n",
    "model.add(Dense(units=64,input_dim=28*28,activation=\"relu\"))\n",
    "#Dense : 히든 레이어 추가, units:노드개수\n",
    "model.add(Dense(units=10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 0.9304 - accuracy: 0.7659 - val_loss: 0.4961 - val_accuracy: 0.8731\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 0.4394 - accuracy: 0.8837 - val_loss: 0.3825 - val_accuracy: 0.8952\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 0.3658 - accuracy: 0.8989 - val_loss: 0.3401 - val_accuracy: 0.9048\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.3301 - accuracy: 0.9078 - val_loss: 0.3150 - val_accuracy: 0.9107\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 1s 26us/step - loss: 0.3065 - accuracy: 0.9135 - val_loss: 0.2985 - val_accuracy: 0.9164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x24548471988>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습 환경 설정(compile)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"sgd\",metrics=[\"accuracy\"])\n",
    "#학습(fit)\n",
    "model.fit(xTrain,yTrain,epochs=5,batch_size=50,validation_data=(xVal,yVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 14us/step\n",
      "평가결과:[0.2872369504254311, 0.9189000129699707]\n"
     ]
    }
   ],
   "source": [
    "#모델 평가하기(test data)\n",
    "metrics=model.evaluate(xTest,yTest,batch_size=50)\n",
    "print(\"평가결과:\"+str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.random.choice(xTest.shape[0],5)\n",
    "xHat=xTest[idx]\n",
    "yHat=model.predict_classes(xHat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 9, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xHat  # 5,784\n",
    "yHat  # 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 : 1  실제값 : 9\n",
      "예측값 : 0  실제값 : 0\n",
      "예측값 : 9  실제값 : 9\n",
      "예측값 : 1  실제값 : 1\n",
      "예측값 : 2  실제값 : 2\n"
     ]
    }
   ],
   "source": [
    "#print(\"예측값:\",yHat)#예측값\n",
    "for i in range(5):\n",
    "    print(\"예측값 : \"+str(yHat[i])+\"  실제값 : \"+str(np.argmax(yTest[idx[i]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "모델 : 모델 아키텍처와 모델 가중치로 구성\n",
    "모델 아키텍처 : 모델이 어떤 층으로 구성\n",
    "모델 가중치 : weight, bias\n",
    "\n",
    "save():케라스 모델 저장 함수(아키텍처+가중치)\n",
    "파일형식 : \"h5\"로 저장\n",
    "\"\"\"\n",
    "model.save(\"mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #모델 아키텍쳐 확인\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "# from IPython.display import SVG\n",
    "# SVG(model_to_dot(model,show_shapes=True).create(prog=\"dot\",format=\"svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\student\\anaconda3\\lib\\site-packages (from pydot) (2.4.2)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 : 1  실제값 : 1\n",
      "예측값 : 9  실제값 : 9\n",
      "예측값 : 7  실제값 : 7\n",
      "예측값 : 1  실제값 : 2\n",
      "예측값 : 1  실제값 : 1\n",
      "예측값 : 6  실제값 : 6\n",
      "예측값 : 0  실제값 : 0\n",
      "예측값 : 8  실제값 : 8\n",
      "예측값 : 8  실제값 : 8\n",
      "예측값 : 0  실제값 : 0\n"
     ]
    }
   ],
   "source": [
    "# 실제 데이터 사용\n",
    "(xTrain,yTrain),(xTest,yTest)=mnist.load_data()\n",
    "xTest=xTest.reshape(10000,784).astype('float32')\n",
    "yTest=np_utils.to_categorical(yTest)\n",
    "idx=np.random.choice(xTest.shape[0],10)\n",
    "xhat=xTest[idx]\n",
    "\n",
    "# 모델 불러오기\n",
    "from keras.models import load_model\n",
    "model=load_model(\"mnist_model.h5\")\n",
    "yhat=model.predict_classes(xhat)#시퀀설 api에서만 사용되는 함수\n",
    "for i in range(10):\n",
    "    print(\"예측값 : \"+str(yhat[i])+\"  실제값 : \"+str(np.argmax(yTest[idx[i]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata=xy[:,0:-1]\n",
    "ydata=xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,shape=[None,4])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tf.Variable(tf.random_normal([4,1]))\n",
    "b=tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf=tf.matmul(x,w)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=tf.reduce_mean(tf.square(hf-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=tf.train.GradientDescentOptimizer(1e-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 1.8146178 \n",
      "Prediction: [[-0.6963668 ]\n",
      " [-0.9691154 ]\n",
      " [-0.8520859 ]\n",
      " [-0.7320697 ]\n",
      " [-0.7734653 ]\n",
      " [-0.78456485]\n",
      " [-0.7523502 ]\n",
      " [-0.87549746]]\n",
      "1 cost: 1.8144796 \n",
      "Prediction: [[-0.6962987 ]\n",
      " [-0.969049  ]\n",
      " [-0.85203046]\n",
      " [-0.73202664]\n",
      " [-0.7734145 ]\n",
      " [-0.78451574]\n",
      " [-0.752317  ]\n",
      " [-0.8754646 ]]\n",
      "2 cost: 1.8143411 \n",
      "Prediction: [[-0.6962307 ]\n",
      " [-0.9689825 ]\n",
      " [-0.851975  ]\n",
      " [-0.73198366]\n",
      " [-0.77336365]\n",
      " [-0.7844666 ]\n",
      " [-0.7522838 ]\n",
      " [-0.87543184]]\n",
      "3 cost: 1.8142029 \n",
      "Prediction: [[-0.6961627 ]\n",
      " [-0.96891606]\n",
      " [-0.8519196 ]\n",
      " [-0.7319407 ]\n",
      " [-0.77331287]\n",
      " [-0.7844175 ]\n",
      " [-0.75225055]\n",
      " [-0.875399  ]]\n",
      "4 cost: 1.8140645 \n",
      "Prediction: [[-0.6960947 ]\n",
      " [-0.9688496 ]\n",
      " [-0.85186416]\n",
      " [-0.7318977 ]\n",
      " [-0.773262  ]\n",
      " [-0.7843684 ]\n",
      " [-0.75221735]\n",
      " [-0.8753662 ]]\n",
      "5 cost: 1.8139262 \n",
      "Prediction: [[-0.6960267 ]\n",
      " [-0.96878314]\n",
      " [-0.8518088 ]\n",
      " [-0.73185474]\n",
      " [-0.77321124]\n",
      " [-0.7843193 ]\n",
      " [-0.7521841 ]\n",
      " [-0.8753334 ]]\n",
      "6 cost: 1.8137879 \n",
      "Prediction: [[-0.6959587 ]\n",
      " [-0.9687167 ]\n",
      " [-0.85175335]\n",
      " [-0.73181176]\n",
      " [-0.7731604 ]\n",
      " [-0.78427017]\n",
      " [-0.7521509 ]\n",
      " [-0.8753006 ]]\n",
      "7 cost: 1.8136499 \n",
      "Prediction: [[-0.69589067]\n",
      " [-0.9686502 ]\n",
      " [-0.8516979 ]\n",
      " [-0.7317688 ]\n",
      " [-0.7731096 ]\n",
      " [-0.78422105]\n",
      " [-0.7521177 ]\n",
      " [-0.87526774]]\n",
      "8 cost: 1.8135116 \n",
      "Prediction: [[-0.69582266]\n",
      " [-0.9685838 ]\n",
      " [-0.8516425 ]\n",
      " [-0.7317258 ]\n",
      " [-0.77305883]\n",
      " [-0.78417194]\n",
      " [-0.75208443]\n",
      " [-0.87523496]]\n",
      "9 cost: 1.8133733 \n",
      "Prediction: [[-0.69575465]\n",
      " [-0.96851736]\n",
      " [-0.8515871 ]\n",
      " [-0.7316829 ]\n",
      " [-0.773008  ]\n",
      " [-0.7841228 ]\n",
      " [-0.75205123]\n",
      " [-0.8752021 ]]\n",
      "10 cost: 1.8132352 \n",
      "Prediction: [[-0.6956867 ]\n",
      " [-0.9684509 ]\n",
      " [-0.8515317 ]\n",
      " [-0.73163986]\n",
      " [-0.7729572 ]\n",
      " [-0.7840737 ]\n",
      " [-0.75201803]\n",
      " [-0.87516934]]\n",
      "11 cost: 1.813097 \n",
      "Prediction: [[-0.6956187 ]\n",
      " [-0.9683845 ]\n",
      " [-0.8514763 ]\n",
      " [-0.73159695]\n",
      " [-0.77290636]\n",
      " [-0.7840246 ]\n",
      " [-0.7519848 ]\n",
      " [-0.8751365 ]]\n",
      "12 cost: 1.8129587 \n",
      "Prediction: [[-0.6955507 ]\n",
      " [-0.96831805]\n",
      " [-0.8514209 ]\n",
      " [-0.731554  ]\n",
      " [-0.7728556 ]\n",
      " [-0.7839755 ]\n",
      " [-0.7519516 ]\n",
      " [-0.8751037 ]]\n",
      "13 cost: 1.8128204 \n",
      "Prediction: [[-0.6954827 ]\n",
      " [-0.9682516 ]\n",
      " [-0.85136545]\n",
      " [-0.731511  ]\n",
      " [-0.7728048 ]\n",
      " [-0.78392637]\n",
      " [-0.7519183 ]\n",
      " [-0.87507087]]\n",
      "14 cost: 1.8126822 \n",
      "Prediction: [[-0.69541466]\n",
      " [-0.9681851 ]\n",
      " [-0.85131   ]\n",
      " [-0.731468  ]\n",
      " [-0.772754  ]\n",
      " [-0.78387725]\n",
      " [-0.7518851 ]\n",
      " [-0.8750381 ]]\n",
      "15 cost: 1.8125441 \n",
      "Prediction: [[-0.6953467 ]\n",
      " [-0.9681187 ]\n",
      " [-0.8512546 ]\n",
      " [-0.73142505]\n",
      " [-0.7727032 ]\n",
      " [-0.78382814]\n",
      " [-0.7518519 ]\n",
      " [-0.87500525]]\n",
      "16 cost: 1.812406 \n",
      "Prediction: [[-0.6952787 ]\n",
      " [-0.96805227]\n",
      " [-0.8511992 ]\n",
      " [-0.7313821 ]\n",
      " [-0.7726524 ]\n",
      " [-0.7837791 ]\n",
      " [-0.75181866]\n",
      " [-0.87497246]]\n",
      "17 cost: 1.8122678 \n",
      "Prediction: [[-0.6952107 ]\n",
      " [-0.9679858 ]\n",
      " [-0.85114384]\n",
      " [-0.7313391 ]\n",
      " [-0.7726016 ]\n",
      " [-0.78373   ]\n",
      " [-0.75178546]\n",
      " [-0.8749397 ]]\n",
      "18 cost: 1.8121297 \n",
      "Prediction: [[-0.6951427 ]\n",
      " [-0.9679194 ]\n",
      " [-0.8510884 ]\n",
      " [-0.7312961 ]\n",
      " [-0.77255076]\n",
      " [-0.78368086]\n",
      " [-0.75175226]\n",
      " [-0.87490684]]\n",
      "19 cost: 1.8119916 \n",
      "Prediction: [[-0.69507474]\n",
      " [-0.96785295]\n",
      " [-0.851033  ]\n",
      " [-0.73125315]\n",
      " [-0.7725    ]\n",
      " [-0.78363174]\n",
      " [-0.751719  ]\n",
      " [-0.874874  ]]\n",
      "20 cost: 1.8118533 \n",
      "Prediction: [[-0.6950067 ]\n",
      " [-0.9677865 ]\n",
      " [-0.85097754]\n",
      " [-0.73121023]\n",
      " [-0.7724492 ]\n",
      " [-0.7835826 ]\n",
      " [-0.7516858 ]\n",
      " [-0.8748412 ]]\n",
      "21 cost: 1.8117152 \n",
      "Prediction: [[-0.6949388 ]\n",
      " [-0.9677201 ]\n",
      " [-0.85092217]\n",
      " [-0.73116726]\n",
      " [-0.7723984 ]\n",
      " [-0.7835336 ]\n",
      " [-0.7516526 ]\n",
      " [-0.87480843]]\n",
      "22 cost: 1.8115771 \n",
      "Prediction: [[-0.69487077]\n",
      " [-0.96765363]\n",
      " [-0.8508668 ]\n",
      " [-0.7311243 ]\n",
      " [-0.77234757]\n",
      " [-0.78348446]\n",
      " [-0.75161934]\n",
      " [-0.8747756 ]]\n",
      "23 cost: 1.8114389 \n",
      "Prediction: [[-0.69480276]\n",
      " [-0.96758723]\n",
      " [-0.85081136]\n",
      " [-0.7310813 ]\n",
      " [-0.7722968 ]\n",
      " [-0.78343534]\n",
      " [-0.75158614]\n",
      " [-0.87474275]]\n",
      "24 cost: 1.8113008 \n",
      "Prediction: [[-0.6947348 ]\n",
      " [-0.9675208 ]\n",
      " [-0.85075593]\n",
      " [-0.73103833]\n",
      " [-0.772246  ]\n",
      " [-0.78338623]\n",
      " [-0.75155294]\n",
      " [-0.87470996]]\n",
      "25 cost: 1.8111627 \n",
      "Prediction: [[-0.6946668 ]\n",
      " [-0.9674543 ]\n",
      " [-0.8507005 ]\n",
      " [-0.73099536]\n",
      " [-0.7721952 ]\n",
      " [-0.7833371 ]\n",
      " [-0.7515197 ]\n",
      " [-0.8746772 ]]\n",
      "26 cost: 1.8110245 \n",
      "Prediction: [[-0.69459885]\n",
      " [-0.9673879 ]\n",
      " [-0.8506451 ]\n",
      " [-0.73095244]\n",
      " [-0.77214444]\n",
      " [-0.783288  ]\n",
      " [-0.7514865 ]\n",
      " [-0.87464434]]\n",
      "27 cost: 1.8108864 \n",
      "Prediction: [[-0.69453084]\n",
      " [-0.9673215 ]\n",
      " [-0.85058975]\n",
      " [-0.73090947]\n",
      " [-0.77209365]\n",
      " [-0.78323895]\n",
      " [-0.7514533 ]\n",
      " [-0.8746115 ]]\n",
      "28 cost: 1.8107483 \n",
      "Prediction: [[-0.6944629 ]\n",
      " [-0.96725506]\n",
      " [-0.8505343 ]\n",
      " [-0.7308665 ]\n",
      " [-0.7720428 ]\n",
      " [-0.78318983]\n",
      " [-0.75142   ]\n",
      " [-0.8745787 ]]\n",
      "29 cost: 1.8106102 \n",
      "Prediction: [[-0.6943949 ]\n",
      " [-0.9671886 ]\n",
      " [-0.8504789 ]\n",
      " [-0.7308235 ]\n",
      " [-0.771992  ]\n",
      " [-0.7831407 ]\n",
      " [-0.7513868 ]\n",
      " [-0.87454593]]\n",
      "30 cost: 1.8104722 \n",
      "Prediction: [[-0.6943269 ]\n",
      " [-0.9671222 ]\n",
      " [-0.8504235 ]\n",
      " [-0.73078054]\n",
      " [-0.77194124]\n",
      " [-0.7830916 ]\n",
      " [-0.75135356]\n",
      " [-0.8745131 ]]\n",
      "31 cost: 1.8103342 \n",
      "Prediction: [[-0.6942589 ]\n",
      " [-0.9670558 ]\n",
      " [-0.85036814]\n",
      " [-0.7307376 ]\n",
      " [-0.77189046]\n",
      " [-0.78304255]\n",
      " [-0.75132036]\n",
      " [-0.8744803 ]]\n",
      "32 cost: 1.8101962 \n",
      "Prediction: [[-0.694191  ]\n",
      " [-0.96698934]\n",
      " [-0.8503127 ]\n",
      " [-0.73069465]\n",
      " [-0.7718397 ]\n",
      " [-0.78299344]\n",
      " [-0.75128716]\n",
      " [-0.87444746]]\n",
      "33 cost: 1.8100579 \n",
      "Prediction: [[-0.69412297]\n",
      " [-0.96692294]\n",
      " [-0.8502573 ]\n",
      " [-0.7306517 ]\n",
      " [-0.77178884]\n",
      " [-0.7829443 ]\n",
      " [-0.75125396]\n",
      " [-0.8744147 ]]\n",
      "34 cost: 1.8099198 \n",
      "Prediction: [[-0.694055  ]\n",
      " [-0.9668565 ]\n",
      " [-0.8502019 ]\n",
      " [-0.7306087 ]\n",
      " [-0.77173805]\n",
      " [-0.7828952 ]\n",
      " [-0.7512207 ]\n",
      " [-0.87438184]]\n",
      "35 cost: 1.8097819 \n",
      "Prediction: [[-0.6939871 ]\n",
      " [-0.9667901 ]\n",
      " [-0.85014653]\n",
      " [-0.7305658 ]\n",
      " [-0.77168727]\n",
      " [-0.78284615]\n",
      " [-0.7511875 ]\n",
      " [-0.87434906]]\n",
      "36 cost: 1.809644 \n",
      "Prediction: [[-0.6939191 ]\n",
      " [-0.9667237 ]\n",
      " [-0.8500911 ]\n",
      " [-0.7305228 ]\n",
      " [-0.7716365 ]\n",
      " [-0.78279704]\n",
      " [-0.7511543 ]\n",
      " [-0.8743162 ]]\n",
      "37 cost: 1.8095059 \n",
      "Prediction: [[-0.6938512 ]\n",
      " [-0.9666573 ]\n",
      " [-0.8500358 ]\n",
      " [-0.73047984]\n",
      " [-0.7715857 ]\n",
      " [-0.782748  ]\n",
      " [-0.75112104]\n",
      " [-0.87428343]]\n",
      "38 cost: 1.8093679 \n",
      "Prediction: [[-0.6937832 ]\n",
      " [-0.9665909 ]\n",
      " [-0.84998035]\n",
      " [-0.7304369 ]\n",
      " [-0.7715349 ]\n",
      " [-0.78269887]\n",
      " [-0.75108784]\n",
      " [-0.87425065]]\n",
      "39 cost: 1.8092299 \n",
      "Prediction: [[-0.6937152 ]\n",
      " [-0.9665245 ]\n",
      " [-0.8499249 ]\n",
      " [-0.73039395]\n",
      " [-0.77148414]\n",
      " [-0.7826498 ]\n",
      " [-0.75105464]\n",
      " [-0.8742178 ]]\n",
      "40 cost: 1.8090918 \n",
      "Prediction: [[-0.69364727]\n",
      " [-0.966458  ]\n",
      " [-0.8498696 ]\n",
      " [-0.730351  ]\n",
      " [-0.77143335]\n",
      " [-0.7826007 ]\n",
      " [-0.7510214 ]\n",
      " [-0.87418497]]\n",
      "41 cost: 1.8089538 \n",
      "Prediction: [[-0.6935793 ]\n",
      " [-0.9663916 ]\n",
      " [-0.8498142 ]\n",
      " [-0.73030806]\n",
      " [-0.7713826 ]\n",
      " [-0.78255165]\n",
      " [-0.7509882 ]\n",
      " [-0.8741522 ]]\n",
      "42 cost: 1.808816 \n",
      "Prediction: [[-0.69351137]\n",
      " [-0.96632516]\n",
      " [-0.8497588 ]\n",
      " [-0.7302651 ]\n",
      " [-0.77133185]\n",
      " [-0.78250253]\n",
      " [-0.750955  ]\n",
      " [-0.8741194 ]]\n",
      "43 cost: 1.8086779 \n",
      "Prediction: [[-0.6934434 ]\n",
      " [-0.9662588 ]\n",
      " [-0.84970343]\n",
      " [-0.7302221 ]\n",
      " [-0.77128106]\n",
      " [-0.7824534 ]\n",
      " [-0.7509218 ]\n",
      " [-0.87408656]]\n",
      "44 cost: 1.8085399 \n",
      "Prediction: [[-0.69337547]\n",
      " [-0.96619236]\n",
      " [-0.849648  ]\n",
      " [-0.7301792 ]\n",
      " [-0.7712303 ]\n",
      " [-0.78240436]\n",
      " [-0.7508885 ]\n",
      " [-0.8740538 ]]\n",
      "45 cost: 1.8084021 \n",
      "Prediction: [[-0.6933075 ]\n",
      " [-0.966126  ]\n",
      " [-0.8495927 ]\n",
      " [-0.7301362 ]\n",
      " [-0.7711795 ]\n",
      " [-0.78235525]\n",
      " [-0.7508553 ]\n",
      " [-0.87402093]]\n",
      "46 cost: 1.808264 \n",
      "Prediction: [[-0.6932396 ]\n",
      " [-0.96605957]\n",
      " [-0.84953725]\n",
      " [-0.7300933 ]\n",
      " [-0.7711287 ]\n",
      " [-0.7823062 ]\n",
      " [-0.7508221 ]\n",
      " [-0.87398815]]\n",
      "47 cost: 1.8081261 \n",
      "Prediction: [[-0.6931717 ]\n",
      " [-0.9659932 ]\n",
      " [-0.8494819 ]\n",
      " [-0.7300503 ]\n",
      " [-0.77107793]\n",
      " [-0.7822571 ]\n",
      " [-0.7507889 ]\n",
      " [-0.8739553 ]]\n",
      "48 cost: 1.8079882 \n",
      "Prediction: [[-0.69310373]\n",
      " [-0.9659268 ]\n",
      " [-0.8494265 ]\n",
      " [-0.7300074 ]\n",
      " [-0.7710272 ]\n",
      " [-0.782208  ]\n",
      " [-0.75075567]\n",
      " [-0.8739225 ]]\n",
      "49 cost: 1.8078504 \n",
      "Prediction: [[-0.6930358 ]\n",
      " [-0.9658605 ]\n",
      " [-0.8493712 ]\n",
      " [-0.72996444]\n",
      " [-0.7709764 ]\n",
      " [-0.782159  ]\n",
      " [-0.75072247]\n",
      " [-0.87388974]]\n",
      "50 cost: 1.8077124 \n",
      "Prediction: [[-0.69296783]\n",
      " [-0.9657941 ]\n",
      " [-0.84931576]\n",
      " [-0.7299215 ]\n",
      " [-0.77092564]\n",
      " [-0.78210986]\n",
      " [-0.75068927]\n",
      " [-0.87385696]]\n",
      "51 cost: 1.8075746 \n",
      "Prediction: [[-0.6928999 ]\n",
      " [-0.96572775]\n",
      " [-0.84926045]\n",
      " [-0.72987854]\n",
      " [-0.77087486]\n",
      " [-0.7820608 ]\n",
      " [-0.75065607]\n",
      " [-0.8738242 ]]\n",
      "52 cost: 1.8074367 \n",
      "Prediction: [[-0.692832  ]\n",
      " [-0.96566135]\n",
      " [-0.8492051 ]\n",
      " [-0.7298356 ]\n",
      " [-0.77082413]\n",
      " [-0.78201175]\n",
      " [-0.75062287]\n",
      " [-0.87379134]]\n",
      "53 cost: 1.8072988 \n",
      "Prediction: [[-0.69276404]\n",
      " [-0.965595  ]\n",
      " [-0.8491497 ]\n",
      " [-0.72979265]\n",
      " [-0.77077335]\n",
      " [-0.7819627 ]\n",
      " [-0.75058967]\n",
      " [-0.87375855]]\n",
      "54 cost: 1.807161 \n",
      "Prediction: [[-0.6926961 ]\n",
      " [-0.9655286 ]\n",
      " [-0.84909433]\n",
      " [-0.72974974]\n",
      " [-0.7707226 ]\n",
      " [-0.78191364]\n",
      " [-0.75055647]\n",
      " [-0.8737258 ]]\n",
      "55 cost: 1.807023 \n",
      "Prediction: [[-0.69262815]\n",
      " [-0.96546227]\n",
      " [-0.84903896]\n",
      " [-0.72970676]\n",
      " [-0.77067184]\n",
      " [-0.7818645 ]\n",
      " [-0.7505232 ]\n",
      " [-0.873693  ]]\n",
      "56 cost: 1.8068851 \n",
      "Prediction: [[-0.6925602 ]\n",
      " [-0.96539587]\n",
      " [-0.84898365]\n",
      " [-0.72966385]\n",
      " [-0.77062106]\n",
      " [-0.78181547]\n",
      " [-0.75049   ]\n",
      " [-0.8736602 ]]\n",
      "57 cost: 1.8067474 \n",
      "Prediction: [[-0.69249237]\n",
      " [-0.9653295 ]\n",
      " [-0.84892833]\n",
      " [-0.72962093]\n",
      " [-0.7705704 ]\n",
      " [-0.7817665 ]\n",
      " [-0.75045687]\n",
      " [-0.8736274 ]]\n",
      "58 cost: 1.8066099 \n",
      "Prediction: [[-0.6924245 ]\n",
      " [-0.96526325]\n",
      " [-0.848873  ]\n",
      " [-0.7295781 ]\n",
      " [-0.7705197 ]\n",
      " [-0.7817174 ]\n",
      " [-0.7504237 ]\n",
      " [-0.8735947 ]]\n",
      "59 cost: 1.8064721 \n",
      "Prediction: [[-0.6923566 ]\n",
      " [-0.96519697]\n",
      " [-0.8488177 ]\n",
      " [-0.72953516]\n",
      " [-0.77046895]\n",
      " [-0.7816684 ]\n",
      " [-0.7503906 ]\n",
      " [-0.873562  ]]\n",
      "60 cost: 1.8063345 \n",
      "Prediction: [[-0.69228876]\n",
      " [-0.9651307 ]\n",
      " [-0.8487624 ]\n",
      " [-0.7294923 ]\n",
      " [-0.7704183 ]\n",
      " [-0.7816194 ]\n",
      " [-0.75035745]\n",
      " [-0.87352926]]\n",
      "61 cost: 1.8061969 \n",
      "Prediction: [[-0.69222087]\n",
      " [-0.96506435]\n",
      " [-0.84870714]\n",
      " [-0.72944945]\n",
      " [-0.77036756]\n",
      " [-0.78157043]\n",
      " [-0.7503243 ]\n",
      " [-0.87349653]]\n",
      "62 cost: 1.8060591 \n",
      "Prediction: [[-0.692153  ]\n",
      " [-0.96499807]\n",
      " [-0.8486518 ]\n",
      " [-0.72940654]\n",
      " [-0.7703169 ]\n",
      " [-0.78152144]\n",
      " [-0.75029117]\n",
      " [-0.87346375]]\n",
      "63 cost: 1.8059214 \n",
      "Prediction: [[-0.69208515]\n",
      " [-0.9649317 ]\n",
      " [-0.8485965 ]\n",
      " [-0.7293637 ]\n",
      " [-0.7702662 ]\n",
      " [-0.7814724 ]\n",
      " [-0.75025797]\n",
      " [-0.873431  ]]\n",
      "64 cost: 1.8057839 \n",
      "Prediction: [[-0.69201726]\n",
      " [-0.96486545]\n",
      " [-0.84854126]\n",
      " [-0.72932076]\n",
      " [-0.7702155 ]\n",
      " [-0.7814234 ]\n",
      " [-0.7502248 ]\n",
      " [-0.8733983 ]]\n",
      "65 cost: 1.8056462 \n",
      "Prediction: [[-0.6919494 ]\n",
      " [-0.96479917]\n",
      " [-0.84848595]\n",
      " [-0.7292779 ]\n",
      " [-0.7701648 ]\n",
      " [-0.7813744 ]\n",
      " [-0.7501917 ]\n",
      " [-0.8733656 ]]\n",
      "66 cost: 1.8055086 \n",
      "Prediction: [[-0.6918816 ]\n",
      " [-0.9647329 ]\n",
      " [-0.84843063]\n",
      " [-0.72923505]\n",
      " [-0.7701141 ]\n",
      " [-0.7813254 ]\n",
      " [-0.75015855]\n",
      " [-0.87333286]]\n",
      "67 cost: 1.805371 \n",
      "Prediction: [[-0.6918137 ]\n",
      " [-0.9646666 ]\n",
      " [-0.8483754 ]\n",
      " [-0.7291922 ]\n",
      " [-0.7700634 ]\n",
      " [-0.7812764 ]\n",
      " [-0.7501254 ]\n",
      " [-0.87330014]]\n",
      "68 cost: 1.8052335 \n",
      "Prediction: [[-0.6917459 ]\n",
      " [-0.9646003 ]\n",
      " [-0.8483201 ]\n",
      " [-0.7291493 ]\n",
      " [-0.77001274]\n",
      " [-0.7812274 ]\n",
      " [-0.75009227]\n",
      " [-0.87326735]]\n",
      "69 cost: 1.8050959 \n",
      "Prediction: [[-0.69167805]\n",
      " [-0.96453404]\n",
      " [-0.8482648 ]\n",
      " [-0.7291064 ]\n",
      " [-0.7699621 ]\n",
      " [-0.7811784 ]\n",
      " [-0.7500591 ]\n",
      " [-0.8732346 ]]\n",
      "70 cost: 1.8049582 \n",
      "Prediction: [[-0.6916102 ]\n",
      " [-0.96446776]\n",
      " [-0.8482095 ]\n",
      " [-0.7290636 ]\n",
      " [-0.76991135]\n",
      " [-0.7811294 ]\n",
      " [-0.750026  ]\n",
      " [-0.8732019 ]]\n",
      "71 cost: 1.8048207 \n",
      "Prediction: [[-0.6915423 ]\n",
      " [-0.9644014 ]\n",
      " [-0.84815425]\n",
      " [-0.72902066]\n",
      " [-0.7698607 ]\n",
      " [-0.7810804 ]\n",
      " [-0.74999285]\n",
      " [-0.8731692 ]]\n",
      "72 cost: 1.804683 \n",
      "Prediction: [[-0.6914745 ]\n",
      " [-0.96433514]\n",
      " [-0.84809893]\n",
      " [-0.7289778 ]\n",
      " [-0.76980996]\n",
      " [-0.7810314 ]\n",
      " [-0.7499597 ]\n",
      " [-0.8731364 ]]\n",
      "73 cost: 1.8045456 \n",
      "Prediction: [[-0.69140667]\n",
      " [-0.96426886]\n",
      " [-0.8480437 ]\n",
      " [-0.72893494]\n",
      " [-0.7697593 ]\n",
      " [-0.78098243]\n",
      " [-0.7499265 ]\n",
      " [-0.87310374]]\n",
      "74 cost: 1.8044081 \n",
      "Prediction: [[-0.69133884]\n",
      " [-0.96420264]\n",
      " [-0.84798837]\n",
      " [-0.7288921 ]\n",
      " [-0.76970863]\n",
      " [-0.78093344]\n",
      " [-0.74989337]\n",
      " [-0.87307096]]\n",
      "75 cost: 1.8042705 \n",
      "Prediction: [[-0.691271  ]\n",
      " [-0.9641363 ]\n",
      " [-0.8479331 ]\n",
      " [-0.7288492 ]\n",
      " [-0.76965797]\n",
      " [-0.78088444]\n",
      " [-0.7498602 ]\n",
      " [-0.87303823]]\n",
      "76 cost: 1.8041329 \n",
      "Prediction: [[-0.6912032 ]\n",
      " [-0.96407   ]\n",
      " [-0.8478778 ]\n",
      " [-0.7288063 ]\n",
      " [-0.76960725]\n",
      " [-0.78083545]\n",
      " [-0.7498271 ]\n",
      " [-0.8730055 ]]\n",
      "77 cost: 1.8039954 \n",
      "Prediction: [[-0.69113535]\n",
      " [-0.96400374]\n",
      " [-0.84782255]\n",
      " [-0.72876346]\n",
      " [-0.7695566 ]\n",
      " [-0.78078645]\n",
      " [-0.74979395]\n",
      " [-0.8729728 ]]\n",
      "78 cost: 1.8038578 \n",
      "Prediction: [[-0.6910675 ]\n",
      " [-0.96393746]\n",
      " [-0.84776723]\n",
      " [-0.7287206 ]\n",
      " [-0.7695059 ]\n",
      " [-0.78073746]\n",
      " [-0.7497608 ]\n",
      " [-0.87294006]]\n",
      "79 cost: 1.8037204 \n",
      "Prediction: [[-0.6909997 ]\n",
      " [-0.9638712 ]\n",
      " [-0.847712  ]\n",
      " [-0.7286777 ]\n",
      " [-0.7694552 ]\n",
      " [-0.78068846]\n",
      " [-0.74972767]\n",
      " [-0.8729073 ]]\n",
      "80 cost: 1.8035829 \n",
      "Prediction: [[-0.6909318 ]\n",
      " [-0.96380496]\n",
      " [-0.8476567 ]\n",
      " [-0.72863483]\n",
      " [-0.76940453]\n",
      " [-0.7806395 ]\n",
      " [-0.7496945 ]\n",
      " [-0.87287456]]\n",
      "81 cost: 1.8034453 \n",
      "Prediction: [[-0.69086397]\n",
      " [-0.9637387 ]\n",
      " [-0.8476014 ]\n",
      " [-0.728592  ]\n",
      " [-0.76935387]\n",
      " [-0.78059053]\n",
      " [-0.7496614 ]\n",
      " [-0.87284184]]\n",
      "82 cost: 1.8033078 \n",
      "Prediction: [[-0.69079614]\n",
      " [-0.9636724 ]\n",
      " [-0.84754616]\n",
      " [-0.7285491 ]\n",
      " [-0.7693032 ]\n",
      " [-0.78054154]\n",
      " [-0.74962825]\n",
      " [-0.8728091 ]]\n",
      "83 cost: 1.8031702 \n",
      "Prediction: [[-0.6907283 ]\n",
      " [-0.96360606]\n",
      " [-0.8474909 ]\n",
      " [-0.72850627]\n",
      " [-0.7692525 ]\n",
      " [-0.78049254]\n",
      " [-0.7495951 ]\n",
      " [-0.8727764 ]]\n",
      "84 cost: 1.8030328 \n",
      "Prediction: [[-0.6906605 ]\n",
      " [-0.9635398 ]\n",
      " [-0.8474356 ]\n",
      " [-0.72846335]\n",
      " [-0.7692018 ]\n",
      " [-0.78044355]\n",
      " [-0.74956197]\n",
      " [-0.8727436 ]]\n",
      "85 cost: 1.8028953 \n",
      "Prediction: [[-0.69059265]\n",
      " [-0.9634735 ]\n",
      " [-0.84738034]\n",
      " [-0.7284205 ]\n",
      " [-0.76915115]\n",
      " [-0.78039455]\n",
      " [-0.7495288 ]\n",
      " [-0.8727109 ]]\n",
      "86 cost: 1.802758 \n",
      "Prediction: [[-0.6905248 ]\n",
      " [-0.9634073 ]\n",
      " [-0.847325  ]\n",
      " [-0.72837764]\n",
      " [-0.7691004 ]\n",
      " [-0.78034556]\n",
      " [-0.7494957 ]\n",
      " [-0.87267816]]\n",
      "87 cost: 1.8026204 \n",
      "Prediction: [[-0.69045705]\n",
      " [-0.963341  ]\n",
      " [-0.8472698 ]\n",
      " [-0.7283348 ]\n",
      " [-0.76904976]\n",
      " [-0.78029656]\n",
      " [-0.74946254]\n",
      " [-0.87264544]]\n",
      "88 cost: 1.802483 \n",
      "Prediction: [[-0.6903892 ]\n",
      " [-0.9632747 ]\n",
      " [-0.84721446]\n",
      " [-0.7282919 ]\n",
      " [-0.7689991 ]\n",
      " [-0.78024757]\n",
      " [-0.7494294 ]\n",
      " [-0.8726127 ]]\n",
      "89 cost: 1.8023455 \n",
      "Prediction: [[-0.6903214 ]\n",
      " [-0.96320844]\n",
      " [-0.84715927]\n",
      " [-0.7282491 ]\n",
      " [-0.76894844]\n",
      " [-0.7801986 ]\n",
      " [-0.74939626]\n",
      " [-0.87258   ]]\n",
      "90 cost: 1.8022081 \n",
      "Prediction: [[-0.69025356]\n",
      " [-0.96314216]\n",
      " [-0.84710395]\n",
      " [-0.7282062 ]\n",
      " [-0.7688978 ]\n",
      " [-0.7801496 ]\n",
      " [-0.7493631 ]\n",
      " [-0.87254727]]\n",
      "91 cost: 1.8020707 \n",
      "Prediction: [[-0.6901857 ]\n",
      " [-0.9630759 ]\n",
      " [-0.8470487 ]\n",
      " [-0.72816336]\n",
      " [-0.7688471 ]\n",
      " [-0.78010064]\n",
      " [-0.74933   ]\n",
      " [-0.8725145 ]]\n",
      "92 cost: 1.8019333 \n",
      "Prediction: [[-0.6901179 ]\n",
      " [-0.96300966]\n",
      " [-0.84699345]\n",
      " [-0.72812045]\n",
      " [-0.7687964 ]\n",
      " [-0.78005165]\n",
      " [-0.74929684]\n",
      " [-0.87248176]]\n",
      "93 cost: 1.8017958 \n",
      "Prediction: [[-0.6900501 ]\n",
      " [-0.9629434 ]\n",
      " [-0.84693813]\n",
      " [-0.7280776 ]\n",
      " [-0.7687457 ]\n",
      " [-0.78000265]\n",
      " [-0.74926364]\n",
      " [-0.87244904]]\n",
      "94 cost: 1.8016584 \n",
      "Prediction: [[-0.6899823 ]\n",
      " [-0.9628771 ]\n",
      " [-0.8468829 ]\n",
      " [-0.72803473]\n",
      " [-0.76869506]\n",
      " [-0.7799537 ]\n",
      " [-0.7492305 ]\n",
      " [-0.8724163 ]]\n",
      "95 cost: 1.8015211 \n",
      "Prediction: [[-0.6899145 ]\n",
      " [-0.9628109 ]\n",
      " [-0.8468276 ]\n",
      " [-0.7279919 ]\n",
      " [-0.7686444 ]\n",
      " [-0.7799047 ]\n",
      " [-0.74919736]\n",
      " [-0.8723836 ]]\n",
      "96 cost: 1.8013835 \n",
      "Prediction: [[-0.6898467]\n",
      " [-0.9627446]\n",
      " [-0.8467723]\n",
      " [-0.727949 ]\n",
      " [-0.7685937]\n",
      " [-0.7798557]\n",
      " [-0.7491642]\n",
      " [-0.8723508]]\n",
      "97 cost: 1.8012462 \n",
      "Prediction: [[-0.6897789 ]\n",
      " [-0.9626783 ]\n",
      " [-0.8467171 ]\n",
      " [-0.72790617]\n",
      " [-0.76854306]\n",
      " [-0.77980673]\n",
      " [-0.7491311 ]\n",
      " [-0.8723181 ]]\n",
      "98 cost: 1.8011087 \n",
      "Prediction: [[-0.6897111 ]\n",
      " [-0.9626121 ]\n",
      " [-0.84666187]\n",
      " [-0.7278633 ]\n",
      " [-0.7684924 ]\n",
      " [-0.7797578 ]\n",
      " [-0.74909794]\n",
      " [-0.87228537]]\n",
      "99 cost: 1.8009715 \n",
      "Prediction: [[-0.6896433 ]\n",
      " [-0.9625459 ]\n",
      " [-0.84660655]\n",
      " [-0.72782046]\n",
      " [-0.76844174]\n",
      " [-0.7797088 ]\n",
      " [-0.7490648 ]\n",
      " [-0.87225264]]\n",
      "100 cost: 1.8008341 \n",
      "Prediction: [[-0.6895755 ]\n",
      " [-0.9624796 ]\n",
      " [-0.8465513 ]\n",
      " [-0.7277776 ]\n",
      " [-0.7683911 ]\n",
      " [-0.7796598 ]\n",
      " [-0.74903166]\n",
      " [-0.8722199 ]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(101):\n",
    "    cv,hv,_=sess.run([cost,hf,train],feed_dict={x:xdata,y:ydata})\n",
    "    print(step,\"cost:\",cv,\"\\nPrediction:\",hv)\n",
    "# nan이 나옴 발산 이유: 스케일링 안했음, 러닝레이트 조절 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy.shape #8,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[828.349976 821.655029 818.97998  815.48999  818.469971 816.\n",
      " 809.780029 804.539978]\n",
      "[8.09510010e+02 8.15250000e+02 9.08100000e+05 8.04539978e+02\n",
      " 8.09559998e+02]\n",
      "[[1.         1.         0.         1.         1.        ]\n",
      " [0.70548491 0.70439552 1.         0.71881783 0.83755792]\n",
      " [0.54412549 0.50274824 0.57608696 0.60646801 0.6606331 ]\n",
      " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
      " [0.51436    0.4258239  0.30434783 0.58504805 0.42624401]\n",
      " [0.49556179 0.4258239  0.31521739 0.48131134 0.49276137]\n",
      " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
      " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
      "[828.349976 821.655029 818.97998  815.48999  818.469971 816.\n",
      " 809.780029 804.539978]\n",
      "[8.09510010e+02 8.15250000e+02 9.08100000e+05 8.04539978e+02\n",
      " 8.09559998e+02]\n"
     ]
    }
   ],
   "source": [
    "def myMinMax(data):#스케일링\n",
    "    #print(np.min(data))#전체에서 최소값\n",
    "    print(np.min(data,axis=1))#행 단위로 최소값\n",
    "    print(np.min(data,axis=0))#열 단위로 최소값\n",
    "    bj=data-np.min(data,0)\n",
    "    bm=np.max(data,0)-np.min(data,0)\n",
    "    \n",
    "    return bj/bm\n",
    "\n",
    "print(myMinMax(xy))\n",
    "xy=myMinMax(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata=xy[:,0:-1]\n",
    "ydata=xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 1.090435 \n",
      "Prediction: [[ 0.17870349]\n",
      " [-0.44503957]\n",
      " [-0.55049753]\n",
      " [-0.6674424 ]\n",
      " [-0.5253503 ]\n",
      " [-0.40271533]\n",
      " [-0.92844045]\n",
      " [-0.8750486 ]]\n",
      "1 cost: 1.0903575 \n",
      "Prediction: [[ 0.17875296]\n",
      " [-0.4449901 ]\n",
      " [-0.550456  ]\n",
      " [-0.66741   ]\n",
      " [-0.5253124 ]\n",
      " [-0.40267843]\n",
      " [-0.9284147 ]\n",
      " [-0.87502277]]\n",
      "2 cost: 1.0902798 \n",
      "Prediction: [[ 0.17880243]\n",
      " [-0.4449405 ]\n",
      " [-0.55041456]\n",
      " [-0.66737765]\n",
      " [-0.5252742 ]\n",
      " [-0.40264153]\n",
      " [-0.9283889 ]\n",
      " [-0.874997  ]]\n",
      "3 cost: 1.0902021 \n",
      "Prediction: [[ 0.1788519 ]\n",
      " [-0.44489092]\n",
      " [-0.55037296]\n",
      " [-0.6673453 ]\n",
      " [-0.52523637]\n",
      " [-0.40260482]\n",
      " [-0.92836314]\n",
      " [-0.87497115]]\n",
      "4 cost: 1.0901245 \n",
      "Prediction: [[ 0.17890137]\n",
      " [-0.44484156]\n",
      " [-0.55033165]\n",
      " [-0.667313  ]\n",
      " [-0.5251983 ]\n",
      " [-0.40256792]\n",
      " [-0.92833734]\n",
      " [-0.8749454 ]]\n",
      "5 cost: 1.0900469 \n",
      "Prediction: [[ 0.17895085]\n",
      " [-0.44479185]\n",
      " [-0.5502901 ]\n",
      " [-0.66728055]\n",
      " [-0.5251603 ]\n",
      " [-0.40253115]\n",
      " [-0.92831165]\n",
      " [-0.8749196 ]]\n",
      "6 cost: 1.0899693 \n",
      "Prediction: [[ 0.17900032]\n",
      " [-0.44474238]\n",
      " [-0.5502487 ]\n",
      " [-0.66724825]\n",
      " [-0.52512234]\n",
      " [-0.4024943 ]\n",
      " [-0.92828584]\n",
      " [-0.8748938 ]]\n",
      "7 cost: 1.0898917 \n",
      "Prediction: [[ 0.17904979]\n",
      " [-0.4446928 ]\n",
      " [-0.5502072 ]\n",
      " [-0.66721594]\n",
      " [-0.5250844 ]\n",
      " [-0.40245765]\n",
      " [-0.9282601 ]\n",
      " [-0.874868  ]]\n",
      "8 cost: 1.089814 \n",
      "Prediction: [[ 0.17909926]\n",
      " [-0.44464332]\n",
      " [-0.5501658 ]\n",
      " [-0.6671835 ]\n",
      " [-0.5250464 ]\n",
      " [-0.40242064]\n",
      " [-0.92823434]\n",
      " [-0.87484217]]\n",
      "9 cost: 1.0897363 \n",
      "Prediction: [[ 0.17914873]\n",
      " [-0.44459373]\n",
      " [-0.5501242 ]\n",
      " [-0.6671512 ]\n",
      " [-0.5250083 ]\n",
      " [-0.40238386]\n",
      " [-0.9282086 ]\n",
      " [-0.8748164 ]]\n",
      "10 cost: 1.0896587 \n",
      "Prediction: [[ 0.1791982 ]\n",
      " [-0.44454426]\n",
      " [-0.5500828 ]\n",
      " [-0.6671188 ]\n",
      " [-0.52497035]\n",
      " [-0.40234715]\n",
      " [-0.9281828 ]\n",
      " [-0.8747906 ]]\n",
      "11 cost: 1.0895813 \n",
      "Prediction: [[ 0.17924768]\n",
      " [-0.44449478]\n",
      " [-0.55004144]\n",
      " [-0.6670864 ]\n",
      " [-0.52493227]\n",
      " [-0.40231025]\n",
      " [-0.9281571 ]\n",
      " [-0.87476486]]\n",
      "12 cost: 1.0895038 \n",
      "Prediction: [[ 0.17929715]\n",
      " [-0.4444453 ]\n",
      " [-0.55      ]\n",
      " [-0.66705406]\n",
      " [-0.5248944 ]\n",
      " [-0.4022736 ]\n",
      " [-0.92813134]\n",
      " [-0.87473905]]\n",
      "13 cost: 1.089426 \n",
      "Prediction: [[ 0.17934662]\n",
      " [-0.44439572]\n",
      " [-0.54995847]\n",
      " [-0.66702175]\n",
      " [-0.52485657]\n",
      " [-0.40223664]\n",
      " [-0.92810553]\n",
      " [-0.8747133 ]]\n",
      "14 cost: 1.0893486 \n",
      "Prediction: [[ 0.1793961 ]\n",
      " [-0.44434625]\n",
      " [-0.5499171 ]\n",
      " [-0.6669894 ]\n",
      " [-0.5248185 ]\n",
      " [-0.40219986]\n",
      " [-0.9280798 ]\n",
      " [-0.8746875 ]]\n",
      "15 cost: 1.089271 \n",
      "Prediction: [[ 0.17944556]\n",
      " [-0.44429678]\n",
      " [-0.54987556]\n",
      " [-0.66695696]\n",
      " [-0.5247805 ]\n",
      " [-0.4021631 ]\n",
      " [-0.92805403]\n",
      " [-0.8746617 ]]\n",
      "16 cost: 1.0891935 \n",
      "Prediction: [[ 0.17949504]\n",
      " [-0.44424707]\n",
      " [-0.54983425]\n",
      " [-0.66692466]\n",
      " [-0.5247424 ]\n",
      " [-0.4021263 ]\n",
      " [-0.9280283 ]\n",
      " [-0.87463593]]\n",
      "17 cost: 1.0891157 \n",
      "Prediction: [[ 0.17954451]\n",
      " [-0.4441976 ]\n",
      " [-0.5497927 ]\n",
      " [-0.66689223]\n",
      " [-0.52470446]\n",
      " [-0.40208948]\n",
      " [-0.9280025 ]\n",
      " [-0.8746101 ]]\n",
      "18 cost: 1.0890383 \n",
      "Prediction: [[ 0.17959398]\n",
      " [-0.44414824]\n",
      " [-0.5497512 ]\n",
      " [-0.6668599 ]\n",
      " [-0.5246665 ]\n",
      " [-0.40205258]\n",
      " [-0.9279767 ]\n",
      " [-0.8745844 ]]\n",
      "19 cost: 1.0889606 \n",
      "Prediction: [[ 0.17964345]\n",
      " [-0.44409865]\n",
      " [-0.5497098 ]\n",
      " [-0.66682756]\n",
      " [-0.5246285 ]\n",
      " [-0.4020158 ]\n",
      " [-0.927951  ]\n",
      " [-0.87455857]]\n",
      "20 cost: 1.0888832 \n",
      "Prediction: [[ 0.17969292]\n",
      " [-0.4440493 ]\n",
      " [-0.54966825]\n",
      " [-0.66679513]\n",
      " [-0.52459055]\n",
      " [-0.4019791 ]\n",
      " [-0.9279252 ]\n",
      " [-0.8745328 ]]\n",
      "21 cost: 1.0888056 \n",
      "Prediction: [[ 0.1797424 ]\n",
      " [-0.4439996 ]\n",
      " [-0.5496268 ]\n",
      " [-0.66676277]\n",
      " [-0.5245526 ]\n",
      " [-0.4019423 ]\n",
      " [-0.9278995 ]\n",
      " [-0.874507  ]]\n",
      "22 cost: 1.0887281 \n",
      "Prediction: [[ 0.17979187]\n",
      " [-0.44395024]\n",
      " [-0.54958546]\n",
      " [-0.66673046]\n",
      " [-0.5245147 ]\n",
      " [-0.40190542]\n",
      " [-0.92787373]\n",
      " [-0.8744812 ]]\n",
      "23 cost: 1.0886505 \n",
      "Prediction: [[ 0.17984134]\n",
      " [-0.44390053]\n",
      " [-0.5495439 ]\n",
      " [-0.66669816]\n",
      " [-0.5244766 ]\n",
      " [-0.40186864]\n",
      " [-0.9278479 ]\n",
      " [-0.87445545]]\n",
      "24 cost: 1.088573 \n",
      "Prediction: [[ 0.17989081]\n",
      " [-0.44385105]\n",
      " [-0.5495025 ]\n",
      " [-0.66666573]\n",
      " [-0.52443874]\n",
      " [-0.40183192]\n",
      " [-0.92782223]\n",
      " [-0.8744297 ]]\n",
      "25 cost: 1.0884954 \n",
      "Prediction: [[ 0.17994028]\n",
      " [-0.44380158]\n",
      " [-0.54946107]\n",
      " [-0.6666334 ]\n",
      " [-0.52440065]\n",
      " [-0.40179503]\n",
      " [-0.9277964 ]\n",
      " [-0.8744039 ]]\n",
      "26 cost: 1.0884178 \n",
      "Prediction: [[ 0.17998976]\n",
      " [-0.443752  ]\n",
      " [-0.5494196 ]\n",
      " [-0.66660106]\n",
      " [-0.5243628 ]\n",
      " [-0.40175813]\n",
      " [-0.9277707 ]\n",
      " [-0.8743781 ]]\n",
      "27 cost: 1.0883403 \n",
      "Prediction: [[ 0.18003923]\n",
      " [-0.44370264]\n",
      " [-0.5493783 ]\n",
      " [-0.6665687 ]\n",
      " [-0.5243247 ]\n",
      " [-0.40172142]\n",
      " [-0.9277449 ]\n",
      " [-0.87435234]]\n",
      "28 cost: 1.0882627 \n",
      "Prediction: [[ 0.1800887 ]\n",
      " [-0.44365305]\n",
      " [-0.5493366 ]\n",
      " [-0.66653633]\n",
      " [-0.52428687]\n",
      " [-0.40168464]\n",
      " [-0.9277191 ]\n",
      " [-0.8743265 ]]\n",
      "29 cost: 1.0881852 \n",
      "Prediction: [[ 0.18013817]\n",
      " [-0.44360358]\n",
      " [-0.5492953 ]\n",
      " [-0.6665039 ]\n",
      " [-0.52424866]\n",
      " [-0.40164787]\n",
      " [-0.9276934 ]\n",
      " [-0.8743007 ]]\n",
      "30 cost: 1.0881077 \n",
      "Prediction: [[ 0.18018764]\n",
      " [-0.44355398]\n",
      " [-0.5492538 ]\n",
      " [-0.6664716 ]\n",
      " [-0.5242108 ]\n",
      " [-0.4016111 ]\n",
      " [-0.9276676 ]\n",
      " [-0.87427497]]\n",
      "31 cost: 1.0880301 \n",
      "Prediction: [[ 0.18023711]\n",
      " [-0.4435045 ]\n",
      " [-0.5492124 ]\n",
      " [-0.66643924]\n",
      " [-0.5241727 ]\n",
      " [-0.40157425]\n",
      " [-0.92764187]\n",
      " [-0.8742492 ]]\n",
      "32 cost: 1.0879526 \n",
      "Prediction: [[ 0.18028659]\n",
      " [-0.44345504]\n",
      " [-0.549171  ]\n",
      " [-0.66640687]\n",
      " [-0.5241349 ]\n",
      " [-0.40153736]\n",
      " [-0.9276161 ]\n",
      " [-0.8742234 ]]\n",
      "33 cost: 1.0878751 \n",
      "Prediction: [[ 0.18033606]\n",
      " [-0.44340545]\n",
      " [-0.5491296 ]\n",
      " [-0.66637444]\n",
      " [-0.5240968 ]\n",
      " [-0.40150058]\n",
      " [-0.92759037]\n",
      " [-0.8741976 ]]\n",
      "34 cost: 1.0877976 \n",
      "Prediction: [[ 0.18038553]\n",
      " [-0.44335598]\n",
      " [-0.54908794]\n",
      " [-0.66634214]\n",
      " [-0.52405894]\n",
      " [-0.40146387]\n",
      " [-0.9275646 ]\n",
      " [-0.87417185]]\n",
      "35 cost: 1.08772 \n",
      "Prediction: [[ 0.180435  ]\n",
      " [-0.4433065 ]\n",
      " [-0.5490465 ]\n",
      " [-0.6663098 ]\n",
      " [-0.52402097]\n",
      " [-0.40142697]\n",
      " [-0.9275389 ]\n",
      " [-0.87414604]]\n",
      "36 cost: 1.0876424 \n",
      "Prediction: [[ 0.18048447]\n",
      " [-0.44325703]\n",
      " [-0.5490051 ]\n",
      " [-0.6662774 ]\n",
      " [-0.5239829 ]\n",
      " [-0.4013902 ]\n",
      " [-0.9275131 ]\n",
      " [-0.87412024]]\n",
      "37 cost: 1.0875651 \n",
      "Prediction: [[ 0.18053395]\n",
      " [-0.44320744]\n",
      " [-0.5489637 ]\n",
      " [-0.66624504]\n",
      " [-0.5239449 ]\n",
      " [-0.40135348]\n",
      " [-0.9274874 ]\n",
      " [-0.8740945 ]]\n",
      "38 cost: 1.0874876 \n",
      "Prediction: [[ 0.18058342]\n",
      " [-0.44315797]\n",
      " [-0.5489223 ]\n",
      " [-0.6662126 ]\n",
      " [-0.52390695]\n",
      " [-0.4013167 ]\n",
      " [-0.92746156]\n",
      " [-0.87406874]]\n",
      "39 cost: 1.08741 \n",
      "Prediction: [[ 0.18063289]\n",
      " [-0.4431085 ]\n",
      " [-0.54888064]\n",
      " [-0.6661803 ]\n",
      " [-0.523869  ]\n",
      " [-0.4012797 ]\n",
      " [-0.9274358 ]\n",
      " [-0.8740429 ]]\n",
      "40 cost: 1.0873326 \n",
      "Prediction: [[ 0.18068236]\n",
      " [-0.44305903]\n",
      " [-0.54883933]\n",
      " [-0.666148  ]\n",
      " [-0.523831  ]\n",
      " [-0.4012429 ]\n",
      " [-0.92741007]\n",
      " [-0.8740171 ]]\n",
      "41 cost: 1.087255 \n",
      "Prediction: [[ 0.18073183]\n",
      " [-0.44300944]\n",
      " [-0.54879785]\n",
      " [-0.6661156 ]\n",
      " [-0.52379304]\n",
      " [-0.4012062 ]\n",
      " [-0.9273843 ]\n",
      " [-0.8739914 ]]\n",
      "42 cost: 1.0871775 \n",
      "Prediction: [[ 0.1807813 ]\n",
      " [-0.44295996]\n",
      " [-0.5487564 ]\n",
      " [-0.6660832 ]\n",
      " [-0.5237551 ]\n",
      " [-0.40116942]\n",
      " [-0.9273585 ]\n",
      " [-0.87396556]]\n",
      "43 cost: 1.0871 \n",
      "Prediction: [[ 0.18083078]\n",
      " [-0.4429105 ]\n",
      " [-0.548715  ]\n",
      " [-0.6660509 ]\n",
      " [-0.523717  ]\n",
      " [-0.40113264]\n",
      " [-0.92733276]\n",
      " [-0.87393975]]\n",
      "44 cost: 1.0870225 \n",
      "Prediction: [[ 0.18088025]\n",
      " [-0.44286102]\n",
      " [-0.54867345]\n",
      " [-0.6660186 ]\n",
      " [-0.523679  ]\n",
      " [-0.4010958 ]\n",
      " [-0.927307  ]\n",
      " [-0.873914  ]]\n",
      "45 cost: 1.086945 \n",
      "Prediction: [[ 0.18092972]\n",
      " [-0.44281143]\n",
      " [-0.5486321 ]\n",
      " [-0.6659862 ]\n",
      " [-0.52364105]\n",
      " [-0.40105903]\n",
      " [-0.92728126]\n",
      " [-0.87388825]]\n",
      "46 cost: 1.0868676 \n",
      "Prediction: [[ 0.18097919]\n",
      " [-0.44276196]\n",
      " [-0.54859066]\n",
      " [-0.6659538 ]\n",
      " [-0.5236032 ]\n",
      " [-0.40102214]\n",
      " [-0.9272555 ]\n",
      " [-0.87386245]]\n",
      "47 cost: 1.0867901 \n",
      "Prediction: [[ 0.18102866]\n",
      " [-0.4427125 ]\n",
      " [-0.548549  ]\n",
      " [-0.6659215 ]\n",
      " [-0.5235651 ]\n",
      " [-0.40098536]\n",
      " [-0.92722976]\n",
      " [-0.87383664]]\n",
      "48 cost: 1.0867126 \n",
      "Prediction: [[ 0.18107814]\n",
      " [-0.44266266]\n",
      " [-0.5485077 ]\n",
      " [-0.6658891 ]\n",
      " [-0.52352726]\n",
      " [-0.40094852]\n",
      " [-0.927204  ]\n",
      " [-0.8738109 ]]\n",
      "49 cost: 1.0866351 \n",
      "Prediction: [[ 0.18112761]\n",
      " [-0.4426133 ]\n",
      " [-0.5484662 ]\n",
      " [-0.6658568 ]\n",
      " [-0.52348906]\n",
      " [-0.40091163]\n",
      " [-0.92717826]\n",
      " [-0.8737851 ]]\n",
      "50 cost: 1.0865576 \n",
      "Prediction: [[ 0.18117708]\n",
      " [-0.44256395]\n",
      " [-0.5484249 ]\n",
      " [-0.6658243 ]\n",
      " [-0.5234511 ]\n",
      " [-0.40087497]\n",
      " [-0.9271525 ]\n",
      " [-0.87375927]]\n",
      "51 cost: 1.0864801 \n",
      "Prediction: [[ 0.18122655]\n",
      " [-0.44251436]\n",
      " [-0.54838336]\n",
      " [-0.665792  ]\n",
      " [-0.5234131 ]\n",
      " [-0.40083814]\n",
      " [-0.9271267 ]\n",
      " [-0.8737335 ]]\n",
      "52 cost: 1.0864028 \n",
      "Prediction: [[ 0.18127602]\n",
      " [-0.4424649 ]\n",
      " [-0.5483417 ]\n",
      " [-0.6657596 ]\n",
      " [-0.5233753 ]\n",
      " [-0.40080136]\n",
      " [-0.92710096]\n",
      " [-0.8737078 ]]\n",
      "53 cost: 1.0863253 \n",
      "Prediction: [[ 0.1813255 ]\n",
      " [-0.4424153 ]\n",
      " [-0.54830045]\n",
      " [-0.6657273 ]\n",
      " [-0.5233372 ]\n",
      " [-0.40076447]\n",
      " [-0.9270752 ]\n",
      " [-0.87368196]]\n",
      "54 cost: 1.0862479 \n",
      "Prediction: [[ 0.18137497]\n",
      " [-0.44236594]\n",
      " [-0.5482589 ]\n",
      " [-0.66569495]\n",
      " [-0.5232993 ]\n",
      " [-0.4007277 ]\n",
      " [-0.92704946]\n",
      " [-0.87365615]]\n",
      "55 cost: 1.0861702 \n",
      "Prediction: [[ 0.18142444]\n",
      " [-0.44231623]\n",
      " [-0.5482176 ]\n",
      " [-0.6656625 ]\n",
      " [-0.5232613 ]\n",
      " [-0.40069097]\n",
      " [-0.92702365]\n",
      " [-0.8736304 ]]\n",
      "56 cost: 1.0860927 \n",
      "Prediction: [[ 0.18147391]\n",
      " [-0.44226664]\n",
      " [-0.5481761 ]\n",
      " [-0.6656302 ]\n",
      " [-0.5232232 ]\n",
      " [-0.40065408]\n",
      " [-0.9269979 ]\n",
      " [-0.8736046 ]]\n",
      "57 cost: 1.0860155 \n",
      "Prediction: [[ 0.18152338]\n",
      " [-0.44221717]\n",
      " [-0.5481347 ]\n",
      " [-0.66559786]\n",
      " [-0.5231854 ]\n",
      " [-0.4006173 ]\n",
      " [-0.92697215]\n",
      " [-0.87357885]]\n",
      "58 cost: 1.085938 \n",
      "Prediction: [[ 0.18157285]\n",
      " [-0.4421677 ]\n",
      " [-0.54809314]\n",
      " [-0.66556555]\n",
      " [-0.5231474 ]\n",
      " [-0.40058047]\n",
      " [-0.9269464 ]\n",
      " [-0.87355304]]\n",
      "59 cost: 1.0858605 \n",
      "Prediction: [[ 0.18162233]\n",
      " [-0.44211835]\n",
      " [-0.5480517 ]\n",
      " [-0.6655332 ]\n",
      " [-0.52310944]\n",
      " [-0.4005437 ]\n",
      " [-0.92692065]\n",
      " [-0.8735273 ]]\n",
      "60 cost: 1.085783 \n",
      "Prediction: [[ 0.1816718 ]\n",
      " [-0.44206864]\n",
      " [-0.54801035]\n",
      " [-0.66550076]\n",
      " [-0.52307135]\n",
      " [-0.4005069 ]\n",
      " [-0.9268949 ]\n",
      " [-0.8735015 ]]\n",
      "61 cost: 1.0857058 \n",
      "Prediction: [[ 0.18172127]\n",
      " [-0.44201928]\n",
      " [-0.5479689 ]\n",
      " [-0.6654684 ]\n",
      " [-0.5230335 ]\n",
      " [-0.40047014]\n",
      " [-0.92686915]\n",
      " [-0.8734757 ]]\n",
      "62 cost: 1.0856283 \n",
      "Prediction: [[ 0.18177074]\n",
      " [-0.4419697 ]\n",
      " [-0.5479274 ]\n",
      " [-0.6654361 ]\n",
      " [-0.5229954 ]\n",
      " [-0.4004333 ]\n",
      " [-0.9268434 ]\n",
      " [-0.8734499 ]]\n",
      "63 cost: 1.0855508 \n",
      "Prediction: [[ 0.18182021]\n",
      " [-0.44192022]\n",
      " [-0.54788595]\n",
      " [-0.6654037 ]\n",
      " [-0.52295744]\n",
      " [-0.4003964 ]\n",
      " [-0.92681766]\n",
      " [-0.8734241 ]]\n",
      "64 cost: 1.0854732 \n",
      "Prediction: [[ 0.18186969]\n",
      " [-0.44187063]\n",
      " [-0.54784447]\n",
      " [-0.6653713 ]\n",
      " [-0.52291936]\n",
      " [-0.40035963]\n",
      " [-0.9267919 ]\n",
      " [-0.87339836]]\n",
      "65 cost: 1.0853959 \n",
      "Prediction: [[ 0.18191916]\n",
      " [-0.44182116]\n",
      " [-0.54780304]\n",
      " [-0.665339  ]\n",
      " [-0.5228815 ]\n",
      " [-0.4003229 ]\n",
      " [-0.9267661 ]\n",
      " [-0.87337255]]\n",
      "66 cost: 1.0853186 \n",
      "Prediction: [[ 0.18196863]\n",
      " [-0.4417717 ]\n",
      " [-0.5477616 ]\n",
      " [-0.6653066 ]\n",
      " [-0.5228434 ]\n",
      " [-0.40028614]\n",
      " [-0.92674035]\n",
      " [-0.8733468 ]]\n",
      "67 cost: 1.0852413 \n",
      "Prediction: [[ 0.18201804]\n",
      " [-0.44172227]\n",
      " [-0.54772013]\n",
      " [-0.6652743 ]\n",
      " [-0.52280563]\n",
      " [-0.4002493 ]\n",
      " [-0.92671466]\n",
      " [-0.87332106]]\n",
      "68 cost: 1.0851638 \n",
      "Prediction: [[ 0.18206745]\n",
      " [-0.44167274]\n",
      " [-0.5476788 ]\n",
      " [-0.665242  ]\n",
      " [-0.5227676 ]\n",
      " [-0.4002126 ]\n",
      " [-0.9266889 ]\n",
      " [-0.8732953 ]]\n",
      "69 cost: 1.0850866 \n",
      "Prediction: [[ 0.18211687]\n",
      " [-0.44162333]\n",
      " [-0.54763734]\n",
      " [-0.66520965]\n",
      " [-0.5227298 ]\n",
      " [-0.40017593]\n",
      " [-0.9266633 ]\n",
      " [-0.8732696 ]]\n",
      "70 cost: 1.0850093 \n",
      "Prediction: [[ 0.18216628]\n",
      " [-0.44157392]\n",
      " [-0.547596  ]\n",
      " [-0.6651774 ]\n",
      " [-0.5226918 ]\n",
      " [-0.4001391 ]\n",
      " [-0.92663753]\n",
      " [-0.8732439 ]]\n",
      "71 cost: 1.0849321 \n",
      "Prediction: [[ 0.18221569]\n",
      " [-0.4415245 ]\n",
      " [-0.5475546 ]\n",
      " [-0.6651451 ]\n",
      " [-0.5226539 ]\n",
      " [-0.40010226]\n",
      " [-0.92661184]\n",
      " [-0.8732182 ]]\n",
      "72 cost: 1.0848548 \n",
      "Prediction: [[ 0.1822651 ]\n",
      " [-0.44147497]\n",
      " [-0.5475132 ]\n",
      " [-0.6651128 ]\n",
      " [-0.52261597]\n",
      " [-0.4000656 ]\n",
      " [-0.92658615]\n",
      " [-0.8731924 ]]\n",
      "73 cost: 1.0847774 \n",
      "Prediction: [[ 0.18231452]\n",
      " [-0.44142544]\n",
      " [-0.5474718 ]\n",
      " [-0.6650805 ]\n",
      " [-0.52257806]\n",
      " [-0.40002888]\n",
      " [-0.92656046]\n",
      " [-0.8731667 ]]\n",
      "74 cost: 1.0847002 \n",
      "Prediction: [[ 0.18236393]\n",
      " [-0.44137615]\n",
      " [-0.54743046]\n",
      " [-0.66504824]\n",
      " [-0.52254015]\n",
      " [-0.39999217]\n",
      " [-0.9265348 ]\n",
      " [-0.873141  ]]\n",
      "75 cost: 1.084623 \n",
      "Prediction: [[ 0.18241334]\n",
      " [-0.44132674]\n",
      " [-0.547389  ]\n",
      " [-0.66501594]\n",
      " [-0.52250224]\n",
      " [-0.3999555 ]\n",
      " [-0.9265091 ]\n",
      " [-0.8731153 ]]\n",
      "76 cost: 1.0845456 \n",
      "Prediction: [[ 0.18246275]\n",
      " [-0.4412772 ]\n",
      " [-0.5473478 ]\n",
      " [-0.66498363]\n",
      " [-0.5224642 ]\n",
      " [-0.39991868]\n",
      " [-0.9264834 ]\n",
      " [-0.87308955]]\n",
      "77 cost: 1.0844682 \n",
      "Prediction: [[ 0.18251216]\n",
      " [-0.4412278 ]\n",
      " [-0.5473062 ]\n",
      " [-0.6649513 ]\n",
      " [-0.5224263 ]\n",
      " [-0.39988184]\n",
      " [-0.92645764]\n",
      " [-0.8730638 ]]\n",
      "78 cost: 1.0843911 \n",
      "Prediction: [[ 0.18256158]\n",
      " [-0.44117838]\n",
      " [-0.54726493]\n",
      " [-0.66491896]\n",
      " [-0.5223884 ]\n",
      " [-0.39984512]\n",
      " [-0.926432  ]\n",
      " [-0.8730381 ]]\n",
      "79 cost: 1.0843139 \n",
      "Prediction: [[ 0.18261099]\n",
      " [-0.44112897]\n",
      " [-0.5472235 ]\n",
      " [-0.6648867 ]\n",
      " [-0.5223506 ]\n",
      " [-0.39980847]\n",
      " [-0.92640626]\n",
      " [-0.87301236]]\n",
      "80 cost: 1.0842365 \n",
      "Prediction: [[ 0.1826604 ]\n",
      " [-0.4410792 ]\n",
      " [-0.54718214]\n",
      " [-0.6648544 ]\n",
      " [-0.5223126 ]\n",
      " [-0.39977163]\n",
      " [-0.9263806 ]\n",
      " [-0.8729867 ]]\n",
      "81 cost: 1.0841594 \n",
      "Prediction: [[ 0.18270981]\n",
      " [-0.4410299 ]\n",
      " [-0.5471408 ]\n",
      " [-0.6648221 ]\n",
      " [-0.5222748 ]\n",
      " [-0.3997349 ]\n",
      " [-0.9263549 ]\n",
      " [-0.8729609 ]]\n",
      "82 cost: 1.0840821 \n",
      "Prediction: [[ 0.18275923]\n",
      " [-0.4409806 ]\n",
      " [-0.5470994 ]\n",
      " [-0.6647898 ]\n",
      " [-0.52223676]\n",
      " [-0.39969826]\n",
      " [-0.92632914]\n",
      " [-0.8729352 ]]\n",
      "83 cost: 1.0840048 \n",
      "Prediction: [[ 0.18280864]\n",
      " [-0.44093108]\n",
      " [-0.54705787]\n",
      " [-0.6647575 ]\n",
      " [-0.52219886]\n",
      " [-0.39966142]\n",
      " [-0.92630345]\n",
      " [-0.8729095 ]]\n",
      "84 cost: 1.0839275 \n",
      "Prediction: [[ 0.18285805]\n",
      " [-0.44088167]\n",
      " [-0.5470166 ]\n",
      " [-0.6647252 ]\n",
      " [-0.5221608 ]\n",
      " [-0.3996246 ]\n",
      " [-0.92627776]\n",
      " [-0.8728838 ]]\n",
      "85 cost: 1.0838504 \n",
      "Prediction: [[ 0.18290746]\n",
      " [-0.44083214]\n",
      " [-0.54697514]\n",
      " [-0.6646929 ]\n",
      " [-0.52212304]\n",
      " [-0.39958787]\n",
      " [-0.92625207]\n",
      " [-0.87285805]]\n",
      "86 cost: 1.083773 \n",
      "Prediction: [[ 0.18295687]\n",
      " [-0.44078285]\n",
      " [-0.54693365]\n",
      " [-0.6646606 ]\n",
      " [-0.5220851 ]\n",
      " [-0.3995512 ]\n",
      " [-0.9262264 ]\n",
      " [-0.8728323 ]]\n",
      "87 cost: 1.0836958 \n",
      "Prediction: [[ 0.18300629]\n",
      " [-0.44073308]\n",
      " [-0.54689246]\n",
      " [-0.66462827]\n",
      " [-0.5220473 ]\n",
      " [-0.3995145 ]\n",
      " [-0.9262006 ]\n",
      " [-0.8728066 ]]\n",
      "88 cost: 1.0836186 \n",
      "Prediction: [[ 0.1830557 ]\n",
      " [-0.44068366]\n",
      " [-0.54685086]\n",
      " [-0.66459596]\n",
      " [-0.52200925]\n",
      " [-0.39947778]\n",
      " [-0.926175  ]\n",
      " [-0.8727809 ]]\n",
      "89 cost: 1.0835414 \n",
      "Prediction: [[ 0.18310511]\n",
      " [-0.44063425]\n",
      " [-0.5468096 ]\n",
      " [-0.6645637 ]\n",
      " [-0.52197146]\n",
      " [-0.399441  ]\n",
      " [-0.9261493 ]\n",
      " [-0.87275517]]\n",
      "90 cost: 1.083464 \n",
      "Prediction: [[ 0.18315452]\n",
      " [-0.44058484]\n",
      " [-0.5467681 ]\n",
      " [-0.6645314 ]\n",
      " [-0.5219333 ]\n",
      " [-0.39940417]\n",
      " [-0.9261236 ]\n",
      " [-0.8727294 ]]\n",
      "91 cost: 1.0833869 \n",
      "Prediction: [[ 0.18320394]\n",
      " [-0.44053543]\n",
      " [-0.5467268 ]\n",
      " [-0.6644991 ]\n",
      " [-0.5218955 ]\n",
      " [-0.39936745]\n",
      " [-0.92609787]\n",
      " [-0.8727037 ]]\n",
      "92 cost: 1.0833097 \n",
      "Prediction: [[ 0.18325335]\n",
      " [-0.4404859 ]\n",
      " [-0.54668546]\n",
      " [-0.6644668 ]\n",
      " [-0.5218576 ]\n",
      " [-0.39933074]\n",
      " [-0.9260722 ]\n",
      " [-0.872678  ]]\n",
      "93 cost: 1.0832325 \n",
      "Prediction: [[ 0.18330276]\n",
      " [-0.4404366 ]\n",
      " [-0.546644  ]\n",
      " [-0.6644345 ]\n",
      " [-0.5218197 ]\n",
      " [-0.39929396]\n",
      " [-0.9260465 ]\n",
      " [-0.8726523 ]]\n",
      "94 cost: 1.0831553 \n",
      "Prediction: [[ 0.18335217]\n",
      " [-0.44038707]\n",
      " [-0.5466026 ]\n",
      " [-0.66440225]\n",
      " [-0.5217818 ]\n",
      " [-0.39925712]\n",
      " [-0.9260208 ]\n",
      " [-0.87262654]]\n",
      "95 cost: 1.083078 \n",
      "Prediction: [[ 0.18340158]\n",
      " [-0.44033754]\n",
      " [-0.5465613 ]\n",
      " [-0.6643699 ]\n",
      " [-0.5217439 ]\n",
      " [-0.39922053]\n",
      " [-0.9259951 ]\n",
      " [-0.8726008 ]]\n",
      "96 cost: 1.0830008 \n",
      "Prediction: [[ 0.183451  ]\n",
      " [-0.44028813]\n",
      " [-0.5465198 ]\n",
      " [-0.6643376 ]\n",
      " [-0.521706  ]\n",
      " [-0.39918375]\n",
      " [-0.92596936]\n",
      " [-0.87257504]]\n",
      "97 cost: 1.0829237 \n",
      "Prediction: [[ 0.18350041]\n",
      " [-0.4402387 ]\n",
      " [-0.54647845]\n",
      " [-0.66430527]\n",
      " [-0.52166796]\n",
      " [-0.39914703]\n",
      " [-0.92594373]\n",
      " [-0.87254936]]\n",
      "98 cost: 1.0828463 \n",
      "Prediction: [[ 0.18354982]\n",
      " [-0.4401893 ]\n",
      " [-0.546437  ]\n",
      " [-0.664273  ]\n",
      " [-0.52163005]\n",
      " [-0.3991102 ]\n",
      " [-0.925918  ]\n",
      " [-0.87252367]]\n",
      "99 cost: 1.0827692 \n",
      "Prediction: [[ 0.18359923]\n",
      " [-0.44013977]\n",
      " [-0.5463958 ]\n",
      " [-0.6642407 ]\n",
      " [-0.521592  ]\n",
      " [-0.39907348]\n",
      " [-0.9258923 ]\n",
      " [-0.8724979 ]]\n",
      "100 cost: 1.0826919 \n",
      "Prediction: [[ 0.18364865]\n",
      " [-0.44009036]\n",
      " [-0.5463543 ]\n",
      " [-0.66420835]\n",
      " [-0.52155423]\n",
      " [-0.39903682]\n",
      " [-0.9258666 ]\n",
      " [-0.87247217]]\n"
     ]
    }
   ],
   "source": [
    "x=tf.placeholder(tf.float32,shape=[None,4])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "w=tf.Variable(tf.random_normal([4,1]))\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "hf=tf.matmul(x,w)+b\n",
    "cost=tf.reduce_mean(tf.square(hf-y))\n",
    "train=tf.train.GradientDescentOptimizer(1e-5).minimize(cost)\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(101):\n",
    "    cv,hv,_=sess.run([cost,hf,train],feed_dict={x:xdata,y:ydata})\n",
    "    print(step,\"cost:\",cv,\"\\nPrediction:\",hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 역정규화를 하여 예측 종가를 출력\n",
    "# 1.874 => xxxx???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xor 문제를 텐서플로우로 구현\n",
    "#단일, 멀티 퍼셉트론 각각 구현\n",
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "ydata=np.array([[0],[1],[1],[0]])\n",
    "# 트레이닝 횟수:10000번, lr=0.1\n",
    "# 예측값 출력\n",
    "# 0 0 => 0\n",
    "# 0 1 => 1\n",
    "# 1 0 => 1\n",
    "# 1 1 => 0\n",
    "# 정확도 : 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.73524857 [[ 0.32425666]\n",
      " [-1.1088713 ]]\n",
      "100 0.7074283 [[ 0.12265294]\n",
      " [-0.65509087]]\n",
      "200 0.698089 [[ 0.02840341]\n",
      " [-0.38907412]]\n",
      "300 0.69493634 [[-0.01022039]\n",
      " [-0.23356162]]\n",
      "400 0.6938289 [[-0.02263622]\n",
      " [-0.1419994 ]]\n",
      "500 0.6934196 [[-0.02368738]\n",
      " [-0.08746116]]\n",
      "600 0.6932603 [[-0.02047918]\n",
      " [-0.05454937]]\n",
      "700 0.6931956 [[-0.01622137]\n",
      " [-0.03442234]]\n",
      "800 0.69316834 [[-0.01223005]\n",
      " [-0.02195329]]\n",
      "900 0.6931566 [[-0.00893921]\n",
      " [-0.0141335 ]]\n",
      "1000 0.6931514 [[-0.00639923]\n",
      " [-0.00917408]]\n",
      "1100 0.6931491 [[-0.00451455]\n",
      " [-0.00599691]]\n",
      "1200 0.69314814 [[-0.00315148]\n",
      " [-0.00394337]]\n",
      "1300 0.6931476 [[-0.00218287]\n",
      " [-0.00260591]]\n",
      "1400 0.6931474 [[-0.00150312]\n",
      " [-0.00172913]]\n",
      "1500 0.6931473 [[-0.00103045]\n",
      " [-0.0011512 ]]\n",
      "1600 0.69314724 [[-0.00070403]\n",
      " [-0.00076855]]\n",
      "1700 0.6931472 [[-0.00047973]\n",
      " [-0.0005142 ]]\n",
      "1800 0.6931471 [[-0.00032619]\n",
      " [-0.00034461]]\n",
      "1900 0.6931472 [[-0.00022149]\n",
      " [-0.00023133]]\n",
      "2000 0.6931472 [[-0.00015019]\n",
      " [-0.00015545]]\n",
      "2100 0.6931471 [[-0.00010174]\n",
      " [-0.00010455]]\n",
      "2200 0.69314724 [[-6.8863585e-05]\n",
      " [-7.0367940e-05]]\n",
      "2300 0.6931472 [[-4.658187e-05]\n",
      " [-4.738438e-05]]\n",
      "2400 0.6931472 [[-3.1492949e-05]\n",
      " [-3.1921452e-05]]\n",
      "2500 0.6931472 [[-2.1278196e-05]\n",
      " [-2.1508520e-05]]\n",
      "2600 0.6931471 [[-1.4374488e-05]\n",
      " [-1.4496032e-05]]\n",
      "2700 0.6931471 [[-9.704465e-06]\n",
      " [-9.775350e-06]]\n",
      "2800 0.69314724 [[-6.5498948e-06]\n",
      " [-6.5850154e-06]]\n",
      "2900 0.6931472 [[-4.4279645e-06]\n",
      " [-4.4377553e-06]]\n",
      "3000 0.69314724 [[-2.9855316e-06]\n",
      " [-2.9893622e-06]]\n",
      "3100 0.6931472 [[-2.0184409e-06]\n",
      " [-2.0222715e-06]]\n",
      "3200 0.6931472 [[-1.3568277e-06]\n",
      " [-1.3561877e-06]]\n",
      "3300 0.6931472 [[-9.1574930e-07]\n",
      " [-9.1510924e-07]]\n",
      "3400 0.69314724 [[-6.2517614e-07]\n",
      " [-6.2453609e-07]]\n",
      "3500 0.6931471 [[-3.9718807e-07]\n",
      " [-3.9654802e-07]]\n",
      "3600 0.6931472 [[-2.5264626e-07]\n",
      " [-2.5200620e-07]]\n",
      "3700 0.6931472 [[-2.0347224e-07]\n",
      " [-2.0283218e-07]]\n",
      "3800 0.6931472 [[-1.5280810e-07]\n",
      " [-1.5216804e-07]]\n",
      "3900 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "4000 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "4100 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "4200 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "4300 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "4400 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "4500 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "4600 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "4700 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "4800 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "4900 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "5000 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "5100 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "5200 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "5300 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "5400 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "5500 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "5600 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "5700 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "5800 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "5900 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "6000 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "6100 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "6200 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "6300 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "6400 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "6500 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "6600 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "6700 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "6800 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "6900 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "7000 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "7100 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "7200 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "7300 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "7400 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "7500 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "7600 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "7700 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "7800 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "7900 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "8000 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "8100 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "8200 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "8300 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "8400 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "8500 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "8600 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "8700 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "8800 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "8900 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "9000 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "9100 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "9200 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "9300 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "9400 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "9500 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "9600 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "9700 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "9800 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "9900 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "10000 0.6931472 [[-1.3343652e-07]\n",
      " [-1.3279646e-07]]\n",
      "\n",
      "Hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([2, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hf= tf.sigmoid(tf.matmul(x, w) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hf) + (1 - y) * tf.log(1 - hf))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hf > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cv, wv = sess.run(\n",
    "                  [train, cost, w], feed_dict={x: xdata, y: ydata}\n",
    "        )\n",
    "        if step % 100 == 0:\n",
    "            print(step, cv, wv)\n",
    "\n",
    "    h, c, a = sess.run([hf, predicted, accuracy], feed_dict={x: xdata, y: ydata})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.76505166 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "100 0.6899203 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "200 0.68658674 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "300 0.6828558 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "400 0.678461 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "500 0.6731149 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "600 0.66649354 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "700 0.65819484 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "800 0.64765024 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "900 0.6339992 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1000 0.6159308 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1100 0.5914483 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1200 0.5573642 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1300 0.50799274 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1400 0.43348467 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1500 0.32723364 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1600 0.21200585 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1700 0.12805331 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1800 0.08026823 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1900 0.05415555 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2000 0.039114125 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2100 0.029817112 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2200 0.023690432 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2300 0.019432386 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2400 0.016342128 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2500 0.014018958 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2600 0.012221115 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2700 0.010795929 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2800 0.009643041 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2900 0.008694274 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3000 0.007901812 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3100 0.007231451 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3200 0.0066579496 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3300 0.006162514 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3400 0.005730711 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3500 0.0053514605 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3600 0.0050160144 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3700 0.004717456 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3800 0.004450182 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3900 0.004209724 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4000 0.003992335 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4100 0.0037949039 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4200 0.003614996 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4300 0.003450314 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4400 0.0032991453 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4500 0.0031598993 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4600 0.0030313008 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4700 0.002912149 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4800 0.0028015 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4900 0.0026985286 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5000 0.0026024256 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5100 0.0025125467 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5200 0.0024283824 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5300 0.0023493934 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5400 0.0022750557 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5500 0.0022050696 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5600 0.0021390612 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5700 0.0020767155 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5800 0.0020176584 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5900 0.0019617407 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6000 0.0019087074 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6100 0.0018582898 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6200 0.0018103677 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6300 0.0017646872 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6400 0.0017212032 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6500 0.0016796915 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6600 0.0016400171 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6700 0.0016021357 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6800 0.0015658676 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6900 0.001531123 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7000 0.0014978123 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7100 0.0014658908 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7200 0.0014352237 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7300 0.0014057214 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7400 0.001377399 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7500 0.0013501218 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7600 0.0013238752 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7700 0.001298569 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7800 0.0012742035 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7900 0.0012506593 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8000 0.0012279662 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8100 0.0012060194 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8200 0.0011848339 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8300 0.0011643204 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8400 0.0011445084 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8500 0.0011253086 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8600 0.0011067356 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8700 0.0010887446 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8800 0.0010712763 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8900 0.0010543303 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9000 0.0010379363 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9100 0.0010220053 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9200 0.0010065667 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9300 0.0009915311 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9400 0.0009768686 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9500 0.0009626985 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9600 0.0009489164 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9700 0.00093547767 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9800 0.00092241185 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9900 0.0009096595 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "10000 0.0008972951 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "\n",
      "hf:  [[7.2974630e-04]\n",
      " [9.9903238e-01]\n",
      " [9.9914336e-01]\n",
      " [1.0330471e-03]] \n",
      "Predicted:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#멀티레이어 퍼셉트론 기반 신경망\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# 1 히든 레이어\n",
    "w1 = tf.Variable(tf.random_normal([2, 10]))\n",
    "b1 = tf.Variable(tf.random_normal([10]))\n",
    "layer1=tf.sigmoid(tf.matmul(x, w1) + b1)\n",
    "#tf.nn.relu\n",
    "# 1 히든 레이어\n",
    "w2 = tf.Variable(tf.random_normal([10, 10]))\n",
    "b2 = tf.Variable(tf.random_normal([10]))\n",
    "layer2=tf.sigmoid(tf.matmul(layer1, w2) + b2)\n",
    "# 1 히든 레이어\n",
    "w3 = tf.Variable(tf.random_normal([10, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "layer3=tf.sigmoid(tf.matmul(layer2, w3) + b3)\n",
    "# 1 히든 레이어\n",
    "w4 = tf.Variable(tf.random_normal([10, 1]))\n",
    "b4 = tf.Variable(tf.random_normal([1]))\n",
    "hf=tf.sigmoid(tf.matmul(layer3, w4) + b4)\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hf) + (1 - y) * tf.log(1 - hf))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hf > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cv, wv = sess.run(\n",
    "                  [train, cost, w], feed_dict={x: xdata, y: ydata}\n",
    "        )\n",
    "        if step % 100 == 0:\n",
    "            print(step, cv, wv)\n",
    "\n",
    "    h, p, a = sess.run([hf, predicted, accuracy], feed_dict={x: xdata, y: ydata})\n",
    "    print(\"\\nhf: \", h, \"\\nPredicted: \", p, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.568432 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "100 0.010287397 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "200 0.0047109667 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "300 0.0030572098 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "400 0.0022226328 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "500 0.0017310028 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "600 0.0014210853 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "700 0.0012017702 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "800 0.0010399966 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "900 0.00091098447 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1000 0.000813481 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1100 0.00072869554 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1200 0.0006614788 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1300 0.0006058608 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1400 0.0005593161 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1500 0.000517088 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1600 0.00048147002 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1700 0.00044952217 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1800 0.00042202085 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "1900 0.00039745853 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2000 0.00037568592 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2100 0.00035567395 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2200 0.00033742236 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2300 0.00032124377 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2400 0.00030633312 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2500 0.00029292871 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2600 0.00028024046 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2700 0.0002686259 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2800 0.00025796576 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "2900 0.00024812587 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3000 0.00023904639 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3100 0.00023039951 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3200 0.00022249814 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3300 0.00021529748 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3400 0.0002078437 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3500 0.00020129923 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3600 0.00019503817 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3700 0.00018919451 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3800 0.0001836193 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "3900 0.00017852109 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4000 0.00017348264 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4100 0.0001689808 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4200 0.0001642853 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4300 0.00016011152 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4400 0.00015605701 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4500 0.00015234537 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4600 0.00014849968 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4700 0.00014496698 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4800 0.00014153868 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "4900 0.00013837864 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5000 0.00013526337 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5100 0.00013252074 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5200 0.00012952478 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5300 0.00012682693 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5400 0.0001241887 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5500 0.00012168462 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5600 0.0001192849 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5700 0.000116959716 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5800 0.00011479849 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "5900 0.00011266709 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6000 0.00011046119 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6100 0.00010840434 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6200 0.00010646674 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6300 0.00010463345 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6400 0.00010291942 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6500 0.000101086174 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6600 9.937216e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6700 9.780719e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6800 9.619752e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "6900 9.455807e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7000 9.306763e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7100 9.1651724e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7200 9.022092e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7300 8.8864654e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7400 8.755308e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7500 8.624153e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7600 8.50045e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7700 8.3707855e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7800 8.2604965e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "7900 8.136794e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8000 8.025015e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8100 7.9162164e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8200 7.8104e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8300 7.7001125e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8400 7.601748e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8500 7.503384e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8600 7.4035284e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8700 7.3126175e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8800 7.215743e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "8900 7.1307935e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9000 7.041371e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9100 6.953441e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9200 6.869982e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9300 6.789503e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9400 6.712005e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9500 6.631526e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9600 6.555519e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9700 6.4810025e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9800 6.407976e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "9900 6.33644e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "10000 6.264904e-05 [[ 0.3270217]\n",
      " [-1.1147352]]\n",
      "\n",
      "hf:  [[1.2960596e-05]\n",
      " [9.9998021e-01]\n",
      " [9.9981302e-01]\n",
      " [3.0783991e-05]] \n",
      "Predicted:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "## sigmoid 대신 relu로 성능 더욱 높임\n",
    "\n",
    "#멀티레이어 퍼셉트론 기반 신경망\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# 1 히든 레이어\n",
    "w1 = tf.Variable(tf.random_normal([2, 10]))\n",
    "b1 = tf.Variable(tf.random_normal([10]))\n",
    "layer1=tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "#tf.nn.relu\n",
    "# 1 히든 레이어\n",
    "w2 = tf.Variable(tf.random_normal([10, 10]))\n",
    "b2 = tf.Variable(tf.random_normal([10]))\n",
    "layer2=tf.nn.relu(tf.matmul(layer1, w2) + b2)\n",
    "# 1 히든 레이어\n",
    "w3 = tf.Variable(tf.random_normal([10, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "layer3=tf.nn.relu(tf.matmul(layer2, w3) + b3)\n",
    "# 1 히든 레이어\n",
    "w4 = tf.Variable(tf.random_normal([10, 1]))\n",
    "b4 = tf.Variable(tf.random_normal([1]))\n",
    "hf=tf.sigmoid(tf.matmul(layer3, w4) + b4)\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hf) + (1 - y) * tf.log(1 - hf))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hf > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cv, wv = sess.run(\n",
    "                  [train, cost, w], feed_dict={x: xdata, y: ydata}\n",
    "        )\n",
    "        if step % 100 == 0:\n",
    "            print(step, cv, wv)\n",
    "\n",
    "    h, p, a = sess.run([hf, predicted, accuracy], feed_dict={x: xdata, y: ydata})\n",
    "    print(\"\\nhf: \", h, \"\\nPredicted: \", p, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.io\n",
    "# Dense검색\n",
    "#Dense(8, input_dim=4, init='uniform', activation='relu')\n",
    "#Dense(1, input_dim=3, activation='sigmoid')\n",
    "#Dense(10,input_dim=4, activation='softmax')\n",
    "#...\n",
    "\n",
    "# model=Sequential()\n",
    "# model.add(Dense(8, input_dim=4, init='uniform', activation='relu'))\n",
    "# model.add(Dense(1, input_dim=3, activation='sigmoid'))\n",
    "# model.add(Dense(10,input_dim=4, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Tensorflow를 사용해서 MNist 정확도 90%이상 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:0001,cost:18.617336909\n",
      "EPOCH:0011,cost:7.075876077\n",
      "EPOCH:0021,cost:6.163471540\n",
      "EPOCH:0031,cost:4.183385372\n",
      "EPOCH:0041,cost:3.779868046\n",
      "EPOCH:0051,cost:3.673891822\n",
      "EPOCH:0061,cost:3.504134178\n",
      "EPOCH:0071,cost:3.496534824\n",
      "EPOCH:0081,cost:3.250040968\n",
      "EPOCH:0091,cost:3.215356549\n",
      "EPOCH:0101,cost:3.142929633\n",
      "EPOCH:0111,cost:3.084005674\n",
      "EPOCH:0121,cost:3.138709903\n",
      "EPOCH:0131,cost:3.024947762\n",
      "EPOCH:0141,cost:1.042013347\n",
      "EPOCH:0151,cost:0.498396819\n",
      "EPOCH:0161,cost:0.637709295\n",
      "EPOCH:0171,cost:0.409083565\n",
      "EPOCH:0181,cost:0.367154737\n",
      "EPOCH:0191,cost:0.364909614\n",
      "EPOCH:0201,cost:0.324875096\n",
      "EPOCH:0211,cost:0.303006788\n",
      "EPOCH:0221,cost:0.286211438\n",
      "EPOCH:0231,cost:0.275888279\n",
      "EPOCH:0241,cost:0.254481989\n",
      "EPOCH:0251,cost:0.239760265\n",
      "EPOCH:0261,cost:1.310800006\n",
      "EPOCH:0271,cost:0.226105176\n",
      "EPOCH:0281,cost:0.208027733\n",
      "EPOCH:0291,cost:0.198665502\n",
      "EPOCH:0301,cost:0.196900720\n",
      "EPOCH:0311,cost:0.181967713\n",
      "EPOCH:0321,cost:0.174427892\n",
      "EPOCH:0331,cost:0.248184932\n",
      "EPOCH:0341,cost:0.177090307\n",
      "EPOCH:0351,cost:0.163207422\n",
      "EPOCH:0361,cost:0.154897983\n",
      "EPOCH:0371,cost:0.148669342\n",
      "EPOCH:0381,cost:0.147432367\n",
      "EPOCH:0391,cost:1.465536371\n",
      "EPOCH:0401,cost:0.150387933\n",
      "EPOCH:0411,cost:0.138811712\n",
      "EPOCH:0421,cost:0.132736538\n",
      "EPOCH:0431,cost:0.128430724\n",
      "EPOCH:0441,cost:0.125061831\n",
      "EPOCH:0451,cost:0.122907156\n",
      "EPOCH:0461,cost:0.122573151\n",
      "EPOCH:0471,cost:0.204752686\n",
      "EPOCH:0481,cost:0.128836329\n",
      "EPOCH:0491,cost:0.118981349\n",
      "정확도: 0.9483\n",
      "정확도: 0.9483\n",
      "레이블: [2]\n",
      "예측: [2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000,28*28).astype('float32')/255\n",
    "x_test=x_test.reshape(10000,28*28).astype('float32')/255\n",
    "\n",
    "oht = OneHotEncoder()\n",
    "y_train =oht.fit_transform(y_train.reshape(-1,1)).toarray()#-1은 알아서 사이즈 맞춰줌\n",
    "y_test=oht.transform(y_test.reshape(-1,1)).toarray()\n",
    "\n",
    "X=tf.placeholder(tf.float32,[None,28*28])\n",
    "Y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "W1=tf.Variable(tf.random_normal([28*28,100]))\n",
    "b1=tf.Variable(tf.random_normal([100]))\n",
    "layer1=tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "\n",
    "W2=tf.Variable(tf.random_normal([100,10]))\n",
    "b2=tf.Variable(tf.random_normal([10]))\n",
    "hf=tf.nn.softmax(tf.matmul(layer1,W2)+b2)\n",
    "\n",
    "cost=tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hf+1e-10),axis=1))\n",
    "train=tf.train.GradientDescentOptimizer(1).minimize(cost)\n",
    "isCorrect=tf.equal(tf.argmax(hf,axis=1),tf.argmax(Y,axis=1))\n",
    "accuracy=tf.reduce_mean(tf.cast(isCorrect,tf.float32))\n",
    "\n",
    "numEpochs=500\n",
    "batchSize=10000\n",
    "numIter=x_train.shape[0]//batchSize#6\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(numEpochs):\n",
    "        avgCv=0\n",
    "        for i in range(numIter):\n",
    "            batchX=x_train[batchSize*i:batchSize*(i+1)]\n",
    "            batchY=y_train[batchSize*i:batchSize*(i+1)]\n",
    "            _,hfv,cv=sess.run([train,hf,cost],feed_dict={X:batchX,Y:batchY})\n",
    "            avgCv+=cv/numIter\n",
    "        if epoch%10==0:\n",
    "            print(\"EPOCH:{:04d},cost:{:.9f}\".format(epoch+1,avgCv))\n",
    "    print(\"정확도:\",sess.run(accuracy,feed_dict={X:x_test,Y:y_test}))\n",
    "    print(\"정확도:\",accuracy.eval(session=sess,feed_dict={X:x_test,Y:y_test}))\n",
    "    r=np.random.randint(0,len(y_test)-1)\n",
    "    print(\"레이블:\",sess.run(tf.argmax(y_test[r:r+1],1)))\n",
    "    print(\"예측:\",sess.run(tf.argmax(hf,1),feed_dict={X:x_test[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(x_test[r:r+1].reshape(28,28),cmap='Greys')\n",
    "    plt.show()\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numIter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pima-indian 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\student\\Downloads\\Python_JP\\dataset (1)\"\n",
    "file_=\"\\pima-indians-diabetes.csv\"\n",
    "df=pd.read_csv(path+file_,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1   2   3    4     5      6   7  8\n",
       "0     6  148  72  35    0  33.6  0.627  50  1\n",
       "1     1   85  66  29    0  26.6  0.351  31  0\n",
       "2     8  183  64   0    0  23.3  0.672  32  1\n",
       "3     1   89  66  23   94  28.1  0.167  21  0\n",
       "4     0  137  40  35  168  43.1  2.288  33  1\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "763  10  101  76  48  180  32.9  0.171  63  0\n",
       "764   2  122  70  27    0  36.8  0.340  27  0\n",
       "765   5  121  72  23  112  26.2  0.245  30  0\n",
       "766   1  126  60   0    0  30.1  0.349  47  1\n",
       "767   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata=df.iloc[:,:-1]\n",
    "ydata=np.array(df.iloc[:,[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8) (768, 1)\n",
      "0 0.8638515898159572\n",
      "100 0.658131812300001\n",
      "200 0.6422078354018075\n",
      "300 0.6343628253255572\n",
      "400 0.633097767829895\n",
      "500 0.6327078597886222\n",
      "600 0.6325233493532454\n",
      "700 0.6324073416846139\n",
      "800 0.6323026248386927\n",
      "900 0.6317878620965139\n",
      "0.7994792\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "xdata=StandardScaler().fit_transform(xdata)\n",
    "print(xdata.shape,ydata.shape)#(768,8)(768,1)\n",
    "X=tf.placeholder(tf.float32, shape=[None,8])\n",
    "Y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "W1=tf.Variable(tf.random_normal(shape=[8,200]))\n",
    "b1=tf.Variable(tf.random_normal(shape=[200]))\n",
    "layer1=tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "\n",
    "W2=tf.Variable(tf.random_normal(shape=[200,1]))\n",
    "b2=tf.Variable(tf.random_normal(shape=[1]))\n",
    "hf=tf.sigmoid(tf.matmul(layer1,W2)+b2)\n",
    "\n",
    "loss=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=hf,labels=Y))\n",
    "train=tf.train.GradientDescentOptimizer(1).minimize(loss)\n",
    "pred=tf.cast(hf>0.5,dtype=tf.float32)\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(pred,Y),tf.float32))\n",
    "\n",
    "epochs= 1000\n",
    "batch_size=100\n",
    "iter_num=len(xdata)//batch_size # 7\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    idx=np.random.choice(xdata.shape[0],xdata.shape[0])\n",
    "    for epoch in range(epochs):\n",
    "        avg_lv=0\n",
    "        for i in range(iter_num):\n",
    "            _,hv,lv=sess.run([train,hf,loss],\n",
    "                            feed_dict={X:xdata[idx[:batch_size*(i+1)]],Y:ydata[idx[:batch_size*(i+1)]]})\n",
    "            avg_lv+=lv/iter_num\n",
    "        if epoch%100==0:\n",
    "            print(epoch,avg_lv)\n",
    "    pred_,acc_,hf_=sess.run([pred, accuracy, hf], feed_dict={X:xdata,Y:ydata})\n",
    "    print(acc_)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.random.choice(xdata.shape[0],xdata.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=list(idx[:batch_size*1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.82781311e+00, -6.22642036e-01,  8.73409251e-01,\n",
       "         1.03272605e+00, -6.92890572e-01,  1.72704372e+00,\n",
       "         2.00573238e+00,  4.04942367e-01],\n",
       "       [-8.44885053e-01,  2.13150675e+00, -4.70732246e-01,\n",
       "         1.54533192e-01,  6.65283938e+00, -2.40204587e-01,\n",
       "        -2.23115200e-01,  2.19178518e+00],\n",
       "       [-8.44885053e-01,  2.22380888e-01,  6.66618252e-01,\n",
       "        -2.21835174e-01,  8.96079382e-01, -5.70194625e-01,\n",
       "        -1.07780879e+00, -9.56461683e-01],\n",
       "       [ 3.42980797e-01,  9.71923068e-02,  2.53036252e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01,  2.54780469e-01,\n",
       "        -7.60696324e-01,  4.04942367e-01],\n",
       "       [-8.44885053e-01, -1.56155640e+00, -1.09110524e+00,\n",
       "        -1.59107113e-01, -3.29904822e-02, -1.47132127e+00,\n",
       "        -4.49624101e-01, -9.56461683e-01],\n",
       "       [-2.50952128e-01,  1.56815814e+00,  1.49640753e-01,\n",
       "         7.81813803e-01,  4.79300377e-01,  1.65936998e-01,\n",
       "        -8.24118817e-01, -7.86286177e-01],\n",
       "       [-8.44885053e-01,  2.25669533e+00, -9.87709745e-01,\n",
       "        -2.84563235e-01,  2.56319540e+00, -7.73265418e-01,\n",
       "         5.53055300e-01, -7.86286177e-01],\n",
       "       [-8.44885053e-01, -3.78365371e+00,  2.53036252e-01,\n",
       "        -3.36509911e-02, -4.93183966e-01, -5.44810776e-01,\n",
       "        -5.22106949e-01, -1.04154944e+00],\n",
       "       [-1.14185152e+00, -8.10424908e-01,  8.21711501e-01,\n",
       "         2.79989314e-01, -3.80306319e-01,  6.86305904e-01,\n",
       "        -6.79153120e-01, -7.86286177e-01],\n",
       "       [ 9.36913723e-01,  2.06891246e+00, -5.71502470e-02,\n",
       "         1.15818217e+00,  1.94670979e+00,  7.24381677e-01,\n",
       "        -6.58012289e-01,  6.60205626e-01],\n",
       "       [ 6.39947260e-01, -8.73019198e-01, -9.87709745e-01,\n",
       "         5.93629620e-01, -1.37185233e-01, -4.17891531e-01,\n",
       "        -3.49960184e-01, -8.71373930e-01],\n",
       "       [-8.44885053e-01,  1.34907812e+00,  6.66618252e-01,\n",
       "         1.40909441e+00, -1.11136545e-01,  1.02477375e-01,\n",
       "        -3.95261964e-01,  1.42599540e+00],\n",
       "       [-8.44885053e-01,  5.66649487e-01, -3.67336746e-01,\n",
       "         1.28363829e+00,  3.47489947e+00,  1.10513941e+00,\n",
       "         1.93661178e-01, -1.04154944e+00],\n",
       "       [-5.47918591e-01,  1.69334672e+00,  9.76804751e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01, -1.15402315e+00,\n",
       "        -4.40563745e-01, -9.56461683e-01],\n",
       "       [-2.50952128e-01,  1.84983245e+00, -2.63941247e-01,\n",
       "         2.79989314e-01, -8.50878577e-02,  2.54780469e-01,\n",
       "        -6.06670272e-01, -6.16110671e-01],\n",
       "       [-1.14185152e+00,  5.04055196e-01, -1.50468724e+00,\n",
       "         9.07269925e-01,  7.65835943e-01,  1.40974560e+00,\n",
       "         5.48490910e+00, -2.04963989e-02],\n",
       "       [ 9.36913723e-01,  6.60540923e-01, -4.70732246e-01,\n",
       "         7.81813803e-01,  9.56859653e-01, -4.05199606e-01,\n",
       "         6.49699098e-01,  2.36196069e+00],\n",
       "       [-5.47918591e-01, -4.03562018e-01, -3.67336746e-01,\n",
       "        -6.60931602e-01,  1.72095449e+00, -8.49416965e-01,\n",
       "         1.23560212e+00, -9.56461683e-01],\n",
       "       [-1.14185152e+00,  6.29243777e-01,  7.70013751e-01,\n",
       "         3.42717375e-01, -6.92890572e-01,  5.17096769e-02,\n",
       "        -1.17411046e-01, -9.56461683e-01],\n",
       "       [ 1.82781311e+00, -8.41722053e-01,  1.49640753e-01,\n",
       "        -1.59107113e-01, -6.92890572e-01, -1.12863930e+00,\n",
       "         3.71848180e-01,  1.93652192e+00],\n",
       "       [ 3.42980797e-01, -1.21887711e-01,  8.73409251e-01,\n",
       "         5.93629620e-01,  2.18813500e-01,  9.02068621e-01,\n",
       "        -6.67072645e-01,  7.45293379e-01],\n",
       "       [-8.44885053e-01,  2.35058677e+00,  3.56431752e-01,\n",
       "         9.69997986e-01,  1.46915051e+00,  5.72078583e-01,\n",
       "         1.21748141e+00, -3.60847411e-01],\n",
       "       [ 1.23388019e+00,  2.03761532e+00,  1.08020025e+00,\n",
       "         9.07269925e-01,  1.26076101e+00,  3.18240092e-01,\n",
       "        -1.47612233e-01,  3.19854614e-01],\n",
       "       [ 2.12477957e+00, -2.79962745e-02,  5.63222752e-01,\n",
       "         1.03272605e+00,  6.09543816e-01,  1.30821021e+00,\n",
       "         9.45670728e-01,  1.25581990e+00],\n",
       "       [-2.50952128e-01, -9.66910634e-01,  4.59827252e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01,  1.35897790e+00,\n",
       "         2.63123907e-01, -1.04154944e+00],\n",
       "       [-8.44885053e-01,  2.35058677e+00,  3.56431752e-01,\n",
       "         9.69997986e-01,  1.46915051e+00,  5.72078583e-01,\n",
       "         1.21748141e+00, -3.60847411e-01],\n",
       "       [ 1.23388019e+00,  9.42215231e-01,  4.59827252e-01,\n",
       "         7.19085742e-01,  1.13051757e+00,  1.38436175e+00,\n",
       "         1.33258804e-01,  2.34766861e-01],\n",
       "       [ 2.42174604e+00, -9.04316344e-01, -3.67336746e-01,\n",
       "        -8.49115785e-01,  1.54729658e+00, -5.57502701e-01,\n",
       "         1.37150746e+00,  9.15468886e-01],\n",
       "       [-8.44885053e-01,  1.88112959e+00, -2.63941247e-01,\n",
       "         5.93629620e-01,  8.70030694e-01,  2.67472394e-01,\n",
       "        -4.34523507e-01,  4.04942367e-01],\n",
       "       [ 2.12477957e+00,  5.35352341e-01,  2.53036252e-01,\n",
       "         3.42717375e-01,  5.57446441e-01,  5.21310885e-01,\n",
       "         2.57083670e-01,  1.42599540e+00],\n",
       "       [ 2.12477957e+00,  1.06740381e+00,  3.56431752e-01,\n",
       "         4.68173498e-01,  6.09543816e-01,  1.65936998e-01,\n",
       "         2.66109814e+00,  1.51108316e+00],\n",
       "       [-5.47918591e-01, -2.15779146e-01, -5.71502470e-02,\n",
       "         9.18051311e-02, -6.92890572e-01, -4.17891531e-01,\n",
       "        -1.14727152e+00, -7.01198424e-01],\n",
       "       [-1.14185152e+00,  3.16272324e-01, -3.57259724e+00,\n",
       "        -1.28821221e+00, -6.92890572e-01,  1.42243753e+00,\n",
       "        -6.09690390e-01, -6.16110671e-01],\n",
       "       [ 3.42980797e-01, -1.84482001e-01,  3.56431752e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01, -1.00593418e-01,\n",
       "        -3.89221727e-01,  9.15468886e-01],\n",
       "       [-8.44885053e-01,  5.66649487e-01, -3.67336746e-01,\n",
       "         1.28363829e+00,  3.47489947e+00,  1.10513941e+00,\n",
       "         1.93661178e-01, -1.04154944e+00],\n",
       "       [ 4.60143347e-02,  2.13150675e+00,  2.11415525e+00,\n",
       "         6.56357681e-01, -6.92890572e-01, -4.43275380e-01,\n",
       "         6.28558267e-01,  3.19854614e-01],\n",
       "       [-1.14185152e+00,  1.84983245e+00, -1.60545747e-01,\n",
       "         1.15818217e+00, -6.92890572e-01,  1.27013443e+00,\n",
       "         4.29196222e+00, -7.01198424e-01],\n",
       "       [ 9.36913723e-01,  1.81853530e+00,  1.33868900e+00,\n",
       "         6.56357681e-01, -6.92890572e-01,  2.80164319e-01,\n",
       "        -9.29822970e-01,  2.27687294e+00],\n",
       "       [-5.47918591e-01,  2.38188392e+00,  4.62452528e-02,\n",
       "         1.53455054e+00,  4.02192191e+00, -1.89436889e-01,\n",
       "        -9.47943682e-01,  1.68125866e+00],\n",
       "       [ 9.36913723e-01,  3.78866615e-01,  7.70013751e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01,  1.04167979e+00,\n",
       "         6.76880166e-01,  3.19854614e-01],\n",
       "       [-8.44885053e-01, -1.24858494e+00,  2.53036252e-01,\n",
       "         1.28363829e+00, -1.97965505e-01,  1.81588719e+00,\n",
       "         1.88492764e+00, -1.05584152e-01],\n",
       "       [-5.47918591e-01,  2.22380888e-01, -2.63941247e-01,\n",
       "         1.34636635e+00, -6.92890572e-01,  1.01629594e+00,\n",
       "         1.90002823e+00, -7.86286177e-01],\n",
       "       [-8.44885053e-01, -6.22642036e-01, -9.87709745e-01,\n",
       "        -3.47291297e-01, -3.80306319e-01, -9.89028135e-01,\n",
       "         1.63459991e-01, -6.16110671e-01],\n",
       "       [-5.47918591e-01,  2.53678033e-01,  7.70013751e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01, -5.06735003e-01,\n",
       "        -5.67408729e-01, -5.31022918e-01],\n",
       "       [-1.14185152e+00,  1.91083743e-01,  5.63222752e-01,\n",
       "         1.03272605e+00,  1.13051757e+00,  5.46694734e-01,\n",
       "         1.00305298e+00, -8.71373930e-01],\n",
       "       [ 1.53084665e+00,  2.84975179e-01,  4.62452528e-02,\n",
       "        -1.28821221e+00, -6.92890572e-01,  2.80164319e-01,\n",
       "         5.43994944e-01,  1.00055664e+00],\n",
       "       [ 3.42980797e-01, -8.10424908e-01,  1.49640753e-01,\n",
       "         7.81813803e-01, -6.92890572e-01,  7.24381677e-01,\n",
       "        -3.07678523e-01, -5.31022918e-01],\n",
       "       [ 9.36913723e-01,  1.81853530e+00,  1.33868900e+00,\n",
       "         6.56357681e-01, -6.92890572e-01,  2.80164319e-01,\n",
       "        -9.29822970e-01,  2.27687294e+00],\n",
       "       [-1.14185152e+00,  6.29243777e-01,  7.70013751e-01,\n",
       "         3.42717375e-01, -6.92890572e-01,  5.17096769e-02,\n",
       "        -1.17411046e-01, -9.56461683e-01],\n",
       "       [ 9.36913723e-01,  8.17026649e-01,  3.56431752e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01,  9.40144394e-01,\n",
       "        -6.48951933e-01,  8.30381132e-01],\n",
       "       [-1.14185152e+00, -1.68674498e+00,  3.56431752e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01,  1.68896794e+00,\n",
       "        -8.39219410e-01,  1.08564439e+00],\n",
       "       [-1.14185152e+00,  1.88112959e+00,  9.76804751e-01,\n",
       "         1.47182248e+00,  3.73538635e+00,  1.43512945e+00,\n",
       "        -7.54656087e-01, -6.16110671e-01],\n",
       "       [-1.14185152e+00,  5.66649487e-01, -3.67336746e-01,\n",
       "        -2.21835174e-01,  1.13051757e+00, -1.25555855e+00,\n",
       "        -7.99957867e-01, -1.04154944e+00],\n",
       "       [ 1.53084665e+00, -1.99971643e+00,  5.63222752e-01,\n",
       "         1.03272605e+00, -6.92890572e-01,  1.02477375e-01,\n",
       "        -1.13519104e+00,  6.60205626e-01],\n",
       "       [ 2.71871250e+00, -4.66156309e-01,  4.62452528e-02,\n",
       "        -1.28821221e+00, -6.92890572e-01,  2.80164319e-01,\n",
       "        -6.67072645e-01,  1.59617091e+00],\n",
       "       [-8.44885053e-01, -2.47076292e-01, -2.63941247e-01,\n",
       "         9.07269925e-01, -6.92890572e-01,  2.04012771e-01,\n",
       "         2.14802008e-01, -1.04154944e+00],\n",
       "       [-5.47918591e-01, -9.35613489e-01, -3.67336746e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01, -5.95578474e-01,\n",
       "         1.60439872e-01, -9.56461683e-01],\n",
       "       [ 3.42980797e-01, -6.85236326e-01, -7.80918745e-01,\n",
       "         4.68173498e-01,  2.77897893e-02,  2.54780469e-01,\n",
       "         8.19167867e-02, -2.75759658e-01],\n",
       "       [ 4.60143347e-02,  4.10163760e-01,  1.49640753e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01, -1.03979583e+00,\n",
       "        -5.88549560e-01,  2.27687294e+00],\n",
       "       [-5.47918591e-01, -4.03562018e-01,  5.63222752e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01, -6.33654248e-01,\n",
       "        -6.42911696e-01,  1.59617091e+00],\n",
       "       [-1.14185152e+00,  5.66649487e-01, -3.67336746e-01,\n",
       "        -2.21835174e-01,  1.13051757e+00, -1.25555855e+00,\n",
       "        -7.99957867e-01, -1.04154944e+00],\n",
       "       [ 6.39947260e-01,  1.28489452e-01, -5.71502470e-02,\n",
       "         5.93629620e-01,  3.49056938e-01, -2.52896512e-01,\n",
       "        -2.37873670e-02, -1.05584152e-01],\n",
       "       [ 4.60143347e-02, -6.85236326e-01,  3.56431752e-01,\n",
       "        -3.47291297e-01, -2.50062880e-01, -1.11594738e+00,\n",
       "        -7.51635968e-01, -1.04154944e+00],\n",
       "       [-5.47918591e-01,  7.85729504e-01,  3.56431752e-01,\n",
       "         9.07269925e-01,  9.91591237e-01,  7.87841300e-01,\n",
       "        -4.31503388e-01, -3.60847411e-01],\n",
       "       [-5.47918591e-01, -4.03562018e-01, -3.67336746e-01,\n",
       "         7.19085742e-01, -2.06648401e-01, -8.62108890e-01,\n",
       "        -1.03854724e+00, -1.04154944e+00],\n",
       "       [-8.44885053e-01,  1.84983245e+00, -3.57259724e+00,\n",
       "        -1.28821221e+00, -6.92890572e-01,  1.43512945e+00,\n",
       "        -5.73448966e-01,  6.60205626e-01],\n",
       "       [ 4.60143347e-02,  3.47569469e-01, -3.57259724e+00,\n",
       "        -1.28821221e+00, -6.92890572e-01,  1.15169300e-01,\n",
       "        -5.13046593e-01, -8.71373930e-01],\n",
       "       [-5.47918591e-01, -1.02950492e+00,  2.53036252e-01,\n",
       "        -9.63790522e-02, -2.32697088e-01, -3.79815757e-01,\n",
       "        -7.33515256e-01, -9.56461683e-01],\n",
       "       [ 2.71871250e+00,  1.00480952e+00,  9.76804751e-01,\n",
       "         1.03272605e+00,  5.22714857e-01,  1.09244749e+00,\n",
       "         2.12049689e+00,  4.90030120e-01],\n",
       "       [ 2.71871250e+00,  1.16129525e+00,  2.32094625e+00,\n",
       "        -1.28821221e+00, -6.92890572e-01,  1.30821021e+00,\n",
       "        -6.48951933e-01,  9.15468886e-01],\n",
       "       [-1.14185152e+00, -5.91344890e-01,  8.73409251e-01,\n",
       "        -2.21835174e-01,  2.18813500e-01, -3.41739984e-01,\n",
       "         6.73860047e-01, -5.31022918e-01],\n",
       "       [-2.50952128e-01, -6.85236326e-01, -7.80918745e-01,\n",
       "        -9.63790522e-02,  5.38384771e-02, -8.11341192e-01,\n",
       "        -9.60024157e-01, -7.86286177e-01],\n",
       "       [-8.44885053e-01, -5.92934199e-02,  8.73409251e-01,\n",
       "         1.15818217e+00,  1.21734653e+00,  1.72704372e+00,\n",
       "         1.01513346e+00, -3.60847411e-01],\n",
       "       [ 2.12477957e+00,  4.41460905e-01, -3.57259724e+00,\n",
       "        -1.28821221e+00, -6.92890572e-01,  2.57740266e+00,\n",
       "         3.20506162e-01,  5.75117873e-01],\n",
       "       [-2.50952128e-01,  5.66649487e-01, -7.80918745e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01, -8.11341192e-01,\n",
       "        -2.11034725e-01, -9.56461683e-01],\n",
       "       [ 3.42980797e-01,  7.23135213e-01,  6.66618252e-01,\n",
       "         3.42717375e-01,  1.78173477e+00,  9.41978774e-04,\n",
       "        -6.00287912e-02,  2.10669743e+00],\n",
       "       [-5.47918591e-01, -9.66910634e-01, -4.70732246e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01, -1.07787161e+00,\n",
       "        -8.48279766e-01, -7.01198424e-01],\n",
       "       [ 1.53084665e+00,  9.71923068e-02,  4.62452528e-02,\n",
       "         7.81813803e-01,  2.79763359e+00,  4.32467413e-01,\n",
       "        -5.73448966e-01,  6.45913543e-02],\n",
       "       [-5.47918591e-01, -8.10424908e-01, -7.80918745e-01,\n",
       "        -4.10019358e-01,  7.12042689e-02, -7.47881569e-01,\n",
       "         8.33926337e-01, -9.56461683e-01],\n",
       "       [ 1.23388019e+00, -3.72264873e-01,  3.56431752e-01,\n",
       "         1.15818217e+00,  2.96959563e-01, -5.19426927e-01,\n",
       "         5.07753520e-01, -1.90671905e-01],\n",
       "       [-5.47918591e-01, -6.22642036e-01, -5.74127746e-01,\n",
       "        -2.21835174e-01,  1.60807685e+00, -9.89028135e-01,\n",
       "         4.29230435e-01, -8.71373930e-01],\n",
       "       [ 9.36913723e-01, -2.15779146e-01,  3.56431752e-01,\n",
       "        -2.21835174e-01,  2.62227979e-01, -1.03979583e+00,\n",
       "        -1.77471297e-02, -1.90671905e-01],\n",
       "       [ 3.42980797e-01,  6.58951615e-02,  2.53036252e-01,\n",
       "         1.22091023e+00, -2.43075862e-02,  2.67472394e-01,\n",
       "        -6.12710509e-01, -4.45935165e-01],\n",
       "       [-5.47918591e-01, -2.78373437e-01,  8.73409251e-01,\n",
       "         1.34636635e+00,  6.96372775e-01,  8.13225149e-01,\n",
       "        -6.82173239e-01, -4.45935165e-01],\n",
       "       [ 3.42980797e-01, -3.72264873e-01,  3.04734002e-01,\n",
       "         3.42717375e-01, -6.92890572e-01,  5.08618960e-01,\n",
       "         2.23862365e-01,  2.27687294e+00],\n",
       "       [ 3.42980797e-01,  8.17026649e-01,  4.59827252e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01,  2.16704696e-01,\n",
       "        -7.66736562e-01,  2.70231170e+00],\n",
       "       [-8.44885053e-01,  7.23135213e-01,  6.66618252e-01,\n",
       "         1.59727860e+00,  8.70030694e-01,  1.79050334e+00,\n",
       "        -4.13382676e-01,  1.08564439e+00],\n",
       "       [-1.14185152e+00, -1.49896210e+00, -3.57259724e+00,\n",
       "        -1.28821221e+00, -6.92890572e-01, -1.38247780e+00,\n",
       "        -3.92241846e-01, -7.01198424e-01],\n",
       "       [ 6.39947260e-01,  2.31928962e+00,  4.62452528e-02,\n",
       "        -1.28821221e+00, -6.92890572e-01, -1.38669191e-01,\n",
       "        -4.34523507e-01, -1.90671905e-01],\n",
       "       [ 6.39947260e-01, -3.72264873e-01, -4.70732246e-01,\n",
       "         4.05445437e-01, -6.92890572e-01, -8.87492739e-01,\n",
       "        -8.02977986e-01, -5.31022918e-01],\n",
       "       [ 4.60143347e-02, -6.85236326e-01,  3.56431752e-01,\n",
       "        -3.47291297e-01, -2.50062880e-01, -1.11594738e+00,\n",
       "        -7.51635968e-01, -1.04154944e+00],\n",
       "       [-8.44885053e-01, -1.24858494e+00,  2.53036252e-01,\n",
       "         1.28363829e+00, -1.97965505e-01,  1.81588719e+00,\n",
       "         1.88492764e+00, -1.05584152e-01],\n",
       "       [-8.44885053e-01, -9.05905652e-02, -5.74127746e-01,\n",
       "         9.69997986e-01,  1.23301644e-01,  1.65936998e-01,\n",
       "        -6.36871459e-01, -8.71373930e-01],\n",
       "       [-5.47918591e-01, -1.65544783e+00,  4.62452528e-02,\n",
       "         7.19085742e-01, -1.19819441e-01, -8.87492739e-01,\n",
       "        -8.60360241e-01, -7.01198424e-01],\n",
       "       [ 9.36913723e-01,  1.28489452e-01,  8.73409251e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01,  7.11689753e-01,\n",
       "        -5.07006355e-01,  1.51108316e+00],\n",
       "       [ 3.42980797e-01, -1.37377352e+00,  6.66618252e-01,\n",
       "         1.28363829e+00, -3.28208944e-01,  4.83235111e-01,\n",
       "        -9.53983920e-01,  1.49679107e-01],\n",
       "       [-8.44885053e-01, -1.12339636e+00, -1.60545747e-01,\n",
       "         5.30901559e-01, -6.92890572e-01, -6.84421946e-01,\n",
       "        -3.65060778e-01, -1.90671905e-01],\n",
       "       [-5.47918591e-01, -6.22642036e-01, -5.74127746e-01,\n",
       "        -2.21835174e-01,  1.60807685e+00, -9.89028135e-01,\n",
       "         4.29230435e-01, -8.71373930e-01],\n",
       "       [-5.47918591e-01, -1.12339636e+00, -2.12243497e-01,\n",
       "        -1.28821221e+00, -6.92890572e-01,  9.65528243e-01,\n",
       "         1.38358794e+00, -5.31022918e-01],\n",
       "       [-2.50952128e-01, -1.02950492e+00, -5.74127746e-01,\n",
       "        -5.98203541e-01, -2.24014192e-01, -9.12876588e-01,\n",
       "        -6.18750746e-01, -9.56461683e-01]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata[tt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.44885053e-01, -3.09670582e-01,  1.28699125e+00, ...,\n",
       "         1.02477375e-01, -6.24790984e-01,  1.00055664e+00],\n",
       "       [ 4.60143347e-02, -8.10424908e-01, -2.63941247e-01, ...,\n",
       "         9.41978774e-04, -9.38883326e-01, -1.90671905e-01],\n",
       "       [-8.44885053e-01,  1.00480952e+00,  6.66618252e-01, ...,\n",
       "         1.09244749e+00,  6.49699098e-01, -8.71373930e-01],\n",
       "       ...,\n",
       "       [ 6.39947260e-01, -3.72264873e-01, -4.70732246e-01, ...,\n",
       "        -8.87492739e-01, -8.02977986e-01, -5.31022918e-01],\n",
       "       [ 4.60143347e-02,  8.17026649e-01,  2.53036252e-01, ...,\n",
       "         3.69007790e-01, -2.62376743e-01, -2.75759658e-01],\n",
       "       [ 3.42980797e-01, -4.66156309e-01,  6.66618252e-01, ...,\n",
       "         9.52836319e-01, -5.61368492e-01,  4.04942367e-01]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata[idx[:batch_size*i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydata[idx[:batch_size*i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
