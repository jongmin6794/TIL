{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#크롤링2 뷰티플숲?\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=\"\"\"\n",
    "<html><body>\n",
    "<h1>스크래핑</h1>\n",
    "<p>웹 페이지 분석</p>\n",
    "<p>원하는 부분 추출</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "soup=BeautifulSoup(html,'html.parser')#2번째 인자 : 분석기 종류(여러개)\n",
    "#html 문서 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<p>원하는 부분 추출</p>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "h1=soup.html.body.h1\n",
    "soup.html.body.p#가장 처음으로 만나는 p태그만\n",
    "soup.html.body.p#두번째 줄 p 태그 출력X\n",
    "p1=soup.html.body.p\n",
    "p2=p1.next_sibling.next_sibling\n",
    "print(p1.next_sibling)#p1의 옆에 엔터를 참조...;;\n",
    "print(p1.next_sibling.next_sibling)#따라서 두번 next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크래핑\n",
      "웹 페이지 분석\n",
      "원하는 부분 추출\n"
     ]
    }
   ],
   "source": [
    "print(h1.string)\n",
    "print(p1.string)\n",
    "print(p2.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find함수:id를 기반으로 이용하여 직접 접근\n",
    "html=\"\"\"\n",
    "<html><body>\n",
    "<h1 id=\"title\">스크래핑</h1>\n",
    "<p id=\"body\">웹 페이지 분석</p>\n",
    "<p>원하는 부분 추출</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "soup=BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"title\">스크래핑</h1>\n",
      "title=스크래핑\n",
      "body=웹 페이지 분석\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(id=\"title\"))\n",
    "title=soup.find(id=\"title\")\n",
    "body=soup.find(id=\"body\")\n",
    "print(\"title=\"+title.string)\n",
    "print(\"body=\"+body.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_all():여러 개의 태그를 한번에 추출\n",
    "html=\"\"\"\n",
    "<html><body>\n",
    "<ul>\n",
    "<li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "<li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "</ul>\n",
    "</body></html>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver -> http://www.naver.com\n",
      "daum -> http://www.daum.net\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "<html><body>\n",
       "<ul>\n",
       "<li><a href=\"http://www.naver.com\">naver</a></li>\n",
       "<li><a href=\"http://www.daum.net\">daum</a></li>\n",
       "</ul>\n",
       "</body></html>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find_all():여러 개의 태그를 한번에 추출\n",
    "soup=BeautifulSoup(html,\"html.parser\")\n",
    "links=soup.find_all(\"a\")\n",
    "for a in links:\n",
    "    #if 'href' i a.attrs:\n",
    "    href=a.attrs['href']\n",
    "    text=a.string\n",
    "    print(text,\"->\",href)\n",
    "    #print(href)\n",
    "    \n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기상예보에서 특정 내용 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'기압골의 영향으로 6일부터 8일 사이에 전국에 비 또는 눈이 오겠고, 제주도는 10~11일에도 비가 오겠습니다. <br />한편, 동풍의 영향으로 9일은 강원영동에 비 또는 눈이 오겠습니다. 그 밖의 날은 고기압의 가장자리에 들어 가끔 구름많겠습니다.<br />기온은 평년(최저기온: -12~0℃, 최고기온: 0~8℃)보다 높겠습니다.<br />강수량은 평년(0~3mm)보다 많겠습니다.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=req.urlopen(url)\n",
    "soup=BeautifulSoup(res,'html.parser')\n",
    "title=soup.find(\"title\").string\n",
    "#title 검색,<title>기상청 육상 중기예보</title>\n",
    "#이따 오후 과제 숫자, 특문, 영문 다 제외 한글만!\n",
    "#wf태그값 추출\n",
    "soup.find(\"wf\").string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#css 선택자(크롬->개발자도구->객체선택->copy selector) 사용하기\n",
    "#soup.select_one(선택자):선택자로 지정된 요소 하나를 추출\n",
    "#soup.select(선택자):선택자로 지정된 여러 개 요소를 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=\"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <div id=\"myid\">\n",
    "            <h1>2020년</h1>\n",
    "            <ul class='day'>\n",
    "                <li>월요일</li>\n",
    "                <li>화요일</li>\n",
    "                <li>수요일</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>2020년</h1>\n",
      "2020년\n",
      "월요일\n",
      "화요일\n",
      "수요일\n"
     ]
    }
   ],
   "source": [
    "soup=BeautifulSoup(html,'html.parser')\n",
    "print(soup.select_one(\"div#myid h1\"))\n",
    "print(soup.select_one(\"div#myid>h1\").string)\n",
    "myList= soup.select(\"div#myid > ul.day li\")\n",
    "for a in myList:\n",
    "    print(a.string)\n",
    "#finance.yahoo.com # 삼성 금액 추출 연습문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55,400.00\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"https://finance.yahoo.com/quote/005930.KS?p=005930.KS&.tsrc=fin-srch\"\n",
    "res=req.urlopen(url)\n",
    "soup=BeautifulSoup(res,'html.parser')\n",
    "p=soup.select_one(\"#quote-header-info > div.My\\(6px\\).Pos\\(r\\).smartphone_Mt\\(6px\\) > div span\").text\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-888d3aa12afa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msoup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#quote-header-info > div\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "#ko.wikisource.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서시\n",
      "자화상\n",
      "소년\n",
      "눈 오는 지도\n",
      "돌아와 보는 밤\n",
      "병원\n",
      "새로운 길\n",
      "간판 없는 거리\n",
      "태초의 아침\n",
      "또 태초의 아침\n",
      "새벽이 올 때까지\n",
      "무서운 시간\n",
      "십자가\n",
      "바람이 불어\n",
      "슬픈 족속\n",
      "눈감고 간다\n",
      "또 다른 고향\n",
      "길\n",
      "별 헤는 밤\n",
      "서시\n",
      "자화상\n",
      "소년\n",
      "눈 오는 지도\n",
      "돌아와 보는 밤\n",
      "병원\n",
      "새로운 길\n",
      "간판 없는 거리\n",
      "태초의 아침\n",
      "또 태초의 아침\n",
      "새벽이 올 때까지\n",
      "무서운 시간\n",
      "십자가\n",
      "바람이 불어\n",
      "슬픈 족속\n",
      "눈감고 간다\n",
      "또 다른 고향\n",
      "길\n",
      "별 헤는 밤\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res=req.urlopen(url)\n",
    "soup=BeautifulSoup(res,'html.parser')\n",
    "p=soup.select_one(\"#mw-content-text > div > ul:nth-child(6) > li > ul\").text\n",
    "l=soup.select(\"#mw-content-text > div > ul:nth-child(6) > li > ul > li >a\")\n",
    "print(p)\n",
    "#print(l)\n",
    "for a in l:\n",
    "     print(a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=\"\"\"\n",
    "<ul id=\"language\">\n",
    "    <li id=\"bas\">Basic</li>\n",
    "    <li id=\"cpp\">c++</li>\n",
    "    <li id=\"ja\">java</li>\n",
    "    <li id=\"py\">python</li>\n",
    "    <li id=\"sp\">spark</li>\n",
    "</ul>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "python\n"
     ]
    }
   ],
   "source": [
    "sel=BeautifulSoup(html,\"html.parser\")\n",
    "sel\n",
    "print(sel.select_one(\"#py\").string)\n",
    "\n",
    "myFunc=lambda arg:print(sel.select_one(arg).string)\n",
    "myFunc(\"#py\")\n",
    "myFunc(\"ul>li#py\")\n",
    "myFunc(\"#language #py\")\n",
    "myFunc(\"#language > #py\")\n",
    "myFunc(\"ul#language > li#py\")\n",
    "myFunc(\"li[id='py']\")#밖에 곁따옴표 따라서 안에는 홑따옴표\n",
    "myFunc(\"li:nth-of-type(4)\")\n",
    "print(sel.select(\"li\")[3].string)\n",
    "print(sel.find_all(\"li\")[3].string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp=open(\"fru-veg.html\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<title>Title</title>\n",
       "</head>\n",
       "<body>\n",
       "<div id=\"main-goods\" role=\"page\">\n",
       "<h1>과일과 야채</h1>\n",
       "<ul id=\"fr\">\n",
       "<li class=\"red green\" data-lo=\"ko\">사과</li>\n",
       "<li class=\"purple\" data-lo=\"us\">포도</li>\n",
       "<li class=\"yellow\" data-lo=\"us\">레몬</li>\n",
       "<li class=\"yellow\" data-lo=\"ko\">오렌지</li>\n",
       "</ul>\n",
       "<ul id=\"ve\">\n",
       "<li class=\"white green\" data-lo=\"ko\">무</li>\n",
       "<li class=\"red green\" data-lo=\"us\">파프리카</li>\n",
       "<li class=\"black\" data-lo=\"ko\">가지</li>\n",
       "<li class=\"black\" data-lo=\"us\">아보카도</li>\n",
       "<li class=\"white\" data-lo=\"cn\">연근</li>\n",
       "</ul>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup=BeautifulSoup(fp,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아보카도\n",
      "아보카도\n",
      "아보카도\n",
      "아보카도\n",
      "아보카도\n"
     ]
    }
   ],
   "source": [
    "#아보카도 추출하기\n",
    "#print(soup.select_one(\"li:nth-of-type(5)\").string)\n",
    "print(soup.select_one(\"#ve>li:nth-of-type(4)\").string)\n",
    "print(soup.select(\"#ve>li[data-lo='us']\")[1].string)\n",
    "print(soup.select(\"#ve>li.black\")[1].string)\n",
    "\n",
    "#find메서드\n",
    "cond={'data-lo':'us','class':'black'}\n",
    "print(soup.find(\"li\",cond).string)\n",
    "print(soup.find(id=\"ve\").find(\"li\",cond).string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규표현식과 함께 데이터 추출\n",
    "html=\"\"\"\n",
    "<li> <a href=\"test.html\">test</li>\n",
    "<li> <a href=\"https://test.html\">test2</li>\n",
    "<li> <a href=\"https://test.html\">test3</li>\n",
    "<li> <a href=\"http://test.html\">test4</li>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"https://test.html\">test2</a>, <a href=\"https://test.html\">test3</a>]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "soup=BeautifulSoup(html,\"html.parser\")\n",
    "li=soup.find_all(href=re.compile(\"https://\"))\n",
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 7)\n",
      "(5, 22)\n",
      "(7, 25)\n"
     ]
    }
   ],
   "source": [
    "#문제1~2\n",
    "class Point:\n",
    "    def __init__(self,x,y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "    def setX(self,x):\n",
    "        self.x=x\n",
    "    def setY(self,y):\n",
    "        self.y=y\n",
    "    def get(self):\n",
    "        return (self.x,self.y)\n",
    "    def move(self,dx,dy):\n",
    "        self.x=self.x+dx\n",
    "        self.y=self.y+dy\n",
    "\n",
    "p=Point(10,7)\n",
    "print(p.get())\n",
    "p.setX(5)\n",
    "p.setY(22)\n",
    "print(p.get())\n",
    "p.move(2,3)\n",
    "print(p.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#문제3\n",
    "f=open(\"c:/da/number.txt\",\"w\")\n",
    "for i in range(0,10):\n",
    "    data=input()\n",
    "    f.write(data+\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/da\n",
      "['c:/da\\\\flist.txt', 'c:/da\\\\newFile.txt', 'c:/da\\\\number.txt', 'c:/da\\\\test.txt']\n"
     ]
    }
   ],
   "source": [
    "#문제4\n",
    "import glob\n",
    "location=input()\n",
    "listR=glob.glob(location+\"/*\")\n",
    "print(listR)\n",
    "f=open(location+\"/flist.txt\",\"w\")\n",
    "for i in range(len(listR)):\n",
    "    f.write(listR[i]+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1984년 12월 22일', '1988년 3월 1일', '1995년 3월 11일', '2006년 7월 31일', '2006년 8월 7일', '2009년 8월 15일', '2011년 11월 4일', '2016년 3월 6일']\n"
     ]
    }
   ],
   "source": [
    "#문제5\n",
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"https://ko.wikipedia.org/wiki/%EC%9C%A4%EB%8F%99%EC%A3%BC#%EB%B0%A9%EC%86%A1\"\n",
    "res=req.urlopen(url)\n",
    "soup=BeautifulSoup(res,\"html.parser\")\n",
    "p=soup.select_one(\"#mw-content-text > div > ul:nth-child(71)\").text\n",
    "import re\n",
    "pat=re.findall(\"[1-2]+[0-9]+[0-9]+[0-9]+년+\\s+[1-9]*[0-9]+월+\\s[1-9]*[0-9]+일\",p)\n",
    "#print(p)\n",
    "print(pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기압골의 영향으로 일부터 일 사이에 전국에 비 또는 눈이 오겠고 제주도는 일에도 비가 오겠습니다  한편 동풍의 영향으로 일은 강원영동에 비 또는 눈이 오겠습니다 그 밖의 날은 고기압의 가장자리에 들어 가끔 구름많겠습니다 기온은 평년최저기온  최고기온 보다 높겠습니다 강수량은 평년보다 많겠습니다\n"
     ]
    }
   ],
   "source": [
    "#문제6\n",
    "import urllib.request as req\n",
    "import re\n",
    "url=\"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "res=req.urlopen(url)\n",
    "soup=BeautifulSoup(res,'html.parser')\n",
    "title=soup.find(\"title\").string\n",
    "#title 검색,<title>기상청 육상 중기예보</title>\n",
    "#이따 오후 과제 숫자, 특문, 영문 다 제외 한글만!\n",
    "#wf태그값 추출\n",
    "strList=soup.find(\"wf\").string\n",
    "parse=re.sub(\"[~,+,*,<,>,-,/,:,#,-℃,℃,),(,.,a-zA-Z0-9]\",\"\",strList)\n",
    "\n",
    "print(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
