{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain,yTrain),(xTest,yTest)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape #60000만개 파일, 각 사이즈 28*28 단위 픽셀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=xTrain.reshape(60000,784).astype('float32')/255.0\n",
    "xTest=xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain\n",
    "yTrain=np_utils.to_categorical(yTrain)#원 핫 인코딩 해줌\n",
    "yTest=np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#2. 모델 구성\n",
    "model=Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 모델 학습과정 설정\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.6830 - accuracy: 0.8223\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3438 - accuracy: 0.9043\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2924 - accuracy: 0.9182\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.2625 - accuracy: 0.9262\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.2402 - accuracy: 0.9321\n"
     ]
    }
   ],
   "source": [
    "#4. 모델 학습\n",
    "hist=model.fit(xTrain,yTrain,epochs=5,batch_size=32)\n",
    "#batch_size = 몇개의 샘플로 가중치를 갱신할 것인가\n",
    "#epoch = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6830015118837357, 0.3438101416528225, 0.2923886746366819, 0.26250409135421116, 0.2401547244568666]\n",
      "[0.82226664, 0.90425, 0.9182, 0.92623335, 0.9320833]\n"
     ]
    }
   ],
   "source": [
    "print(hist.history['loss'])\n",
    "print(hist.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 18us/step\n",
      "[0.2278937149345875, 0.935699999332428]\n"
     ]
    }
   ],
   "source": [
    "#6. 모델 평가\n",
    "res=model.evaluate(xTest,yTest,batch_size=32)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.6605280e-05 1.4807726e-07 7.5002777e-04 2.1302865e-03 3.0963324e-06\n",
      "  5.3110551e-05 1.7248244e-07 9.9616784e-01 4.5561930e-05 7.6311739e-04]]\n"
     ]
    }
   ],
   "source": [
    "#모델 예측\n",
    "xhat=xTest[0:1]\n",
    "yhat=model.predict(xhat)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.io 케라스 관련 api 설명 등 가장 좋은 책"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain,yTrain),(xTest,yTest)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xVal=xTrain[50000:]\n",
    "yVal=yTrain[50000:]\n",
    "xTrain=xTrain[:50000]\n",
    "yTrain=yTrain[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=xTrain.reshape(50000,784).astype('float32')/255.0\n",
    "xVal=xVal.reshape(10000,784).astype('float32')/255.0\n",
    "xTest=xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri=np.random.choice(50000,700)\n",
    "vri=np.random.choice(10000,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=xTrain[tri]#700건\n",
    "yTrain=yTrain[tri]\n",
    "xVal=xVal[vri]#300건\n",
    "yVal=yVal[vri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain=np_utils.to_categorical(yTrain)\n",
    "yVal=np_utils.to_categorical(yVal)\n",
    "yTest=np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(input_dim=28*28,units=2,activation='relu'))\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 2.2576 - accuracy: 0.1643 - val_loss: 2.2272 - val_accuracy: 0.1633\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 2.2072 - accuracy: 0.1657 - val_loss: 2.1908 - val_accuracy: 0.1800\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 2.1730 - accuracy: 0.1729 - val_loss: 2.1631 - val_accuracy: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 2.1441 - accuracy: 0.1786 - val_loss: 2.1372 - val_accuracy: 0.1867\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 2.1177 - accuracy: 0.1900 - val_loss: 2.1141 - val_accuracy: 0.1867\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 2.0940 - accuracy: 0.2029 - val_loss: 2.0931 - val_accuracy: 0.2033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 2.0721 - accuracy: 0.2071 - val_loss: 2.0727 - val_accuracy: 0.2067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 2.0520 - accuracy: 0.2129 - val_loss: 2.0564 - val_accuracy: 0.2067\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 2.0342 - accuracy: 0.2157 - val_loss: 2.0410 - val_accuracy: 0.2033\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 2.0190 - accuracy: 0.2143 - val_loss: 2.0269 - val_accuracy: 0.2067\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 2.0041 - accuracy: 0.2186 - val_loss: 2.0125 - val_accuracy: 0.2100\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.9911 - accuracy: 0.2200 - val_loss: 2.0037 - val_accuracy: 0.2100\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.9789 - accuracy: 0.2286 - val_loss: 1.9955 - val_accuracy: 0.2100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.9685 - accuracy: 0.2329 - val_loss: 1.9833 - val_accuracy: 0.2067\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.9582 - accuracy: 0.2214 - val_loss: 1.9753 - val_accuracy: 0.2100\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.9484 - accuracy: 0.2357 - val_loss: 1.9686 - val_accuracy: 0.2000\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.9393 - accuracy: 0.2343 - val_loss: 1.9612 - val_accuracy: 0.2033\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.9309 - accuracy: 0.2314 - val_loss: 1.9537 - val_accuracy: 0.2100\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.9232 - accuracy: 0.2286 - val_loss: 1.9452 - val_accuracy: 0.2100\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.9156 - accuracy: 0.2386 - val_loss: 1.9392 - val_accuracy: 0.2100\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.9085 - accuracy: 0.2343 - val_loss: 1.9363 - val_accuracy: 0.2100\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.9011 - accuracy: 0.2386 - val_loss: 1.9289 - val_accuracy: 0.2033\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8954 - accuracy: 0.2357 - val_loss: 1.9234 - val_accuracy: 0.2100\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.8895 - accuracy: 0.2314 - val_loss: 1.9201 - val_accuracy: 0.2067\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.8830 - accuracy: 0.2343 - val_loss: 1.9178 - val_accuracy: 0.2167\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.8769 - accuracy: 0.2300 - val_loss: 1.9105 - val_accuracy: 0.2167\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.8715 - accuracy: 0.2357 - val_loss: 1.9098 - val_accuracy: 0.2167\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.8662 - accuracy: 0.2400 - val_loss: 1.9094 - val_accuracy: 0.2000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.8615 - accuracy: 0.2400 - val_loss: 1.9041 - val_accuracy: 0.1900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8565 - accuracy: 0.2243 - val_loss: 1.8976 - val_accuracy: 0.2167\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8513 - accuracy: 0.2471 - val_loss: 1.8971 - val_accuracy: 0.1933\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8463 - accuracy: 0.2371 - val_loss: 1.8925 - val_accuracy: 0.1900\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.8423 - accuracy: 0.2229 - val_loss: 1.8874 - val_accuracy: 0.2067\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.8382 - accuracy: 0.2371 - val_loss: 1.8808 - val_accuracy: 0.1933\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.8335 - accuracy: 0.2471 - val_loss: 1.8836 - val_accuracy: 0.1900\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.8299 - accuracy: 0.2343 - val_loss: 1.8756 - val_accuracy: 0.1967\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8257 - accuracy: 0.2486 - val_loss: 1.8745 - val_accuracy: 0.1800\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.8220 - accuracy: 0.2371 - val_loss: 1.8700 - val_accuracy: 0.1933\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.8184 - accuracy: 0.2457 - val_loss: 1.8706 - val_accuracy: 0.1767\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.8144 - accuracy: 0.2314 - val_loss: 1.8677 - val_accuracy: 0.2000\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.8105 - accuracy: 0.2400 - val_loss: 1.8668 - val_accuracy: 0.1833\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8075 - accuracy: 0.2471 - val_loss: 1.8635 - val_accuracy: 0.1800\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.8046 - accuracy: 0.2429 - val_loss: 1.8611 - val_accuracy: 0.1700\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.8001 - accuracy: 0.2371 - val_loss: 1.8566 - val_accuracy: 0.1967\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7970 - accuracy: 0.2429 - val_loss: 1.8564 - val_accuracy: 0.1700\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7939 - accuracy: 0.2271 - val_loss: 1.8528 - val_accuracy: 0.1933\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7913 - accuracy: 0.2600 - val_loss: 1.8551 - val_accuracy: 0.1833\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7886 - accuracy: 0.2471 - val_loss: 1.8543 - val_accuracy: 0.1867\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7858 - accuracy: 0.2486 - val_loss: 1.8504 - val_accuracy: 0.1867\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7819 - accuracy: 0.2471 - val_loss: 1.8443 - val_accuracy: 0.2267\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7794 - accuracy: 0.2643 - val_loss: 1.8468 - val_accuracy: 0.1900\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7762 - accuracy: 0.2486 - val_loss: 1.8411 - val_accuracy: 0.1933\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7744 - accuracy: 0.2514 - val_loss: 1.8486 - val_accuracy: 0.2000\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7716 - accuracy: 0.2700 - val_loss: 1.8472 - val_accuracy: 0.1800\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7687 - accuracy: 0.2500 - val_loss: 1.8364 - val_accuracy: 0.2033\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7672 - accuracy: 0.2543 - val_loss: 1.8430 - val_accuracy: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.7641 - accuracy: 0.2714 - val_loss: 1.8390 - val_accuracy: 0.2167\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7616 - accuracy: 0.2557 - val_loss: 1.8347 - val_accuracy: 0.2267\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7590 - accuracy: 0.2671 - val_loss: 1.8329 - val_accuracy: 0.2233\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7552 - accuracy: 0.2614 - val_loss: 1.8256 - val_accuracy: 0.2500\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7566 - accuracy: 0.2814 - val_loss: 1.8336 - val_accuracy: 0.2400\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7531 - accuracy: 0.2729 - val_loss: 1.8312 - val_accuracy: 0.2267\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.7505 - accuracy: 0.2857 - val_loss: 1.8299 - val_accuracy: 0.2000\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7484 - accuracy: 0.2800 - val_loss: 1.8268 - val_accuracy: 0.2200\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7457 - accuracy: 0.2814 - val_loss: 1.8298 - val_accuracy: 0.2033\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7439 - accuracy: 0.2786 - val_loss: 1.8296 - val_accuracy: 0.2067\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7419 - accuracy: 0.2700 - val_loss: 1.8299 - val_accuracy: 0.2067\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7405 - accuracy: 0.2729 - val_loss: 1.8238 - val_accuracy: 0.2000\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7376 - accuracy: 0.2814 - val_loss: 1.8298 - val_accuracy: 0.2167\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7356 - accuracy: 0.2857 - val_loss: 1.8269 - val_accuracy: 0.2433\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7345 - accuracy: 0.2800 - val_loss: 1.8214 - val_accuracy: 0.2167\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7328 - accuracy: 0.2857 - val_loss: 1.8226 - val_accuracy: 0.2133\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7298 - accuracy: 0.2800 - val_loss: 1.8252 - val_accuracy: 0.2467\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7283 - accuracy: 0.2857 - val_loss: 1.8257 - val_accuracy: 0.1967\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7268 - accuracy: 0.2786 - val_loss: 1.8190 - val_accuracy: 0.2267\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7255 - accuracy: 0.2857 - val_loss: 1.8196 - val_accuracy: 0.2233\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7228 - accuracy: 0.3057 - val_loss: 1.8232 - val_accuracy: 0.2033\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7212 - accuracy: 0.2857 - val_loss: 1.8187 - val_accuracy: 0.1933\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7199 - accuracy: 0.2829 - val_loss: 1.8203 - val_accuracy: 0.2433\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7188 - accuracy: 0.2929 - val_loss: 1.8197 - val_accuracy: 0.2067\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7165 - accuracy: 0.2843 - val_loss: 1.8256 - val_accuracy: 0.2067\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7142 - accuracy: 0.2829 - val_loss: 1.8144 - val_accuracy: 0.2667\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7132 - accuracy: 0.2857 - val_loss: 1.8190 - val_accuracy: 0.2400\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7127 - accuracy: 0.2986 - val_loss: 1.8220 - val_accuracy: 0.2167\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7097 - accuracy: 0.2971 - val_loss: 1.8159 - val_accuracy: 0.2267\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7082 - accuracy: 0.2800 - val_loss: 1.8136 - val_accuracy: 0.2633\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7051 - accuracy: 0.3100 - val_loss: 1.8191 - val_accuracy: 0.2733\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7062 - accuracy: 0.3043 - val_loss: 1.8125 - val_accuracy: 0.2433\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7043 - accuracy: 0.3043 - val_loss: 1.8167 - val_accuracy: 0.2167\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7027 - accuracy: 0.2843 - val_loss: 1.8151 - val_accuracy: 0.2233\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.7017 - accuracy: 0.3086 - val_loss: 1.8185 - val_accuracy: 0.2167\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6987 - accuracy: 0.3129 - val_loss: 1.8215 - val_accuracy: 0.2067\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6980 - accuracy: 0.3071 - val_loss: 1.8173 - val_accuracy: 0.2767\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6970 - accuracy: 0.3157 - val_loss: 1.8176 - val_accuracy: 0.2100\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6943 - accuracy: 0.2986 - val_loss: 1.8194 - val_accuracy: 0.2833\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6948 - accuracy: 0.3014 - val_loss: 1.8095 - val_accuracy: 0.2233\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6930 - accuracy: 0.3057 - val_loss: 1.8228 - val_accuracy: 0.2300\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6921 - accuracy: 0.3043 - val_loss: 1.8117 - val_accuracy: 0.2200\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6901 - accuracy: 0.3129 - val_loss: 1.8252 - val_accuracy: 0.2233\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6890 - accuracy: 0.3129 - val_loss: 1.8210 - val_accuracy: 0.2267\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6878 - accuracy: 0.3143 - val_loss: 1.8190 - val_accuracy: 0.2200\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.6877 - accuracy: 0.3014 - val_loss: 1.8219 - val_accuracy: 0.2300\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6843 - accuracy: 0.3000 - val_loss: 1.8102 - val_accuracy: 0.2500\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6842 - accuracy: 0.3200 - val_loss: 1.8122 - val_accuracy: 0.2200\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6821 - accuracy: 0.3071 - val_loss: 1.8063 - val_accuracy: 0.2067\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6814 - accuracy: 0.3114 - val_loss: 1.8173 - val_accuracy: 0.2200\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.6805 - accuracy: 0.3071 - val_loss: 1.8228 - val_accuracy: 0.2367\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6784 - accuracy: 0.3071 - val_loss: 1.8167 - val_accuracy: 0.2767\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.6782 - accuracy: 0.3143 - val_loss: 1.8178 - val_accuracy: 0.2300\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6775 - accuracy: 0.3171 - val_loss: 1.8147 - val_accuracy: 0.2133\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6775 - accuracy: 0.3043 - val_loss: 1.8173 - val_accuracy: 0.2233\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.6745 - accuracy: 0.3129 - val_loss: 1.8193 - val_accuracy: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6737 - accuracy: 0.3100 - val_loss: 1.8196 - val_accuracy: 0.2300\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6724 - accuracy: 0.3014 - val_loss: 1.8221 - val_accuracy: 0.2300\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6711 - accuracy: 0.3071 - val_loss: 1.8128 - val_accuracy: 0.2333\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6703 - accuracy: 0.3157 - val_loss: 1.8255 - val_accuracy: 0.2300\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6694 - accuracy: 0.3100 - val_loss: 1.8228 - val_accuracy: 0.2333\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.6682 - accuracy: 0.3114 - val_loss: 1.8262 - val_accuracy: 0.2333\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6670 - accuracy: 0.3257 - val_loss: 1.8216 - val_accuracy: 0.2200\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6661 - accuracy: 0.3129 - val_loss: 1.8219 - val_accuracy: 0.2200\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6646 - accuracy: 0.3071 - val_loss: 1.8132 - val_accuracy: 0.2233\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6637 - accuracy: 0.3229 - val_loss: 1.8194 - val_accuracy: 0.2200\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6629 - accuracy: 0.3100 - val_loss: 1.8139 - val_accuracy: 0.2200\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6619 - accuracy: 0.3143 - val_loss: 1.8187 - val_accuracy: 0.2267\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6606 - accuracy: 0.3257 - val_loss: 1.8212 - val_accuracy: 0.2333\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6592 - accuracy: 0.3143 - val_loss: 1.8245 - val_accuracy: 0.2233\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6583 - accuracy: 0.3129 - val_loss: 1.8147 - val_accuracy: 0.2333\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6565 - accuracy: 0.3300 - val_loss: 1.8280 - val_accuracy: 0.2300\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6570 - accuracy: 0.3143 - val_loss: 1.8193 - val_accuracy: 0.2200\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6548 - accuracy: 0.3214 - val_loss: 1.8124 - val_accuracy: 0.2533\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6547 - accuracy: 0.3229 - val_loss: 1.8202 - val_accuracy: 0.2500\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6545 - accuracy: 0.3200 - val_loss: 1.8133 - val_accuracy: 0.2267\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6524 - accuracy: 0.3143 - val_loss: 1.8317 - val_accuracy: 0.2400\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6514 - accuracy: 0.3214 - val_loss: 1.8226 - val_accuracy: 0.2733\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6512 - accuracy: 0.3314 - val_loss: 1.8233 - val_accuracy: 0.2267\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6493 - accuracy: 0.3186 - val_loss: 1.8168 - val_accuracy: 0.2200\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6483 - accuracy: 0.3214 - val_loss: 1.8191 - val_accuracy: 0.2200\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6488 - accuracy: 0.3257 - val_loss: 1.8199 - val_accuracy: 0.2167\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6466 - accuracy: 0.3257 - val_loss: 1.8512 - val_accuracy: 0.2433\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6465 - accuracy: 0.3214 - val_loss: 1.8168 - val_accuracy: 0.2200\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6446 - accuracy: 0.3229 - val_loss: 1.8284 - val_accuracy: 0.2267\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6437 - accuracy: 0.3243 - val_loss: 1.8154 - val_accuracy: 0.2633\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.6437 - accuracy: 0.3329 - val_loss: 1.8292 - val_accuracy: 0.2433\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6431 - accuracy: 0.3329 - val_loss: 1.8273 - val_accuracy: 0.2300\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6419 - accuracy: 0.3271 - val_loss: 1.8197 - val_accuracy: 0.2200\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6392 - accuracy: 0.3343 - val_loss: 1.8324 - val_accuracy: 0.2233\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6412 - accuracy: 0.3100 - val_loss: 1.8328 - val_accuracy: 0.2333\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6390 - accuracy: 0.3243 - val_loss: 1.8306 - val_accuracy: 0.2500\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6375 - accuracy: 0.3271 - val_loss: 1.8189 - val_accuracy: 0.2133\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6367 - accuracy: 0.3229 - val_loss: 1.8276 - val_accuracy: 0.2233\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6364 - accuracy: 0.3257 - val_loss: 1.8245 - val_accuracy: 0.2267\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6350 - accuracy: 0.3214 - val_loss: 1.8290 - val_accuracy: 0.2233\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6340 - accuracy: 0.3400 - val_loss: 1.8270 - val_accuracy: 0.2300\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6319 - accuracy: 0.3457 - val_loss: 1.8343 - val_accuracy: 0.2233\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6316 - accuracy: 0.3243 - val_loss: 1.8183 - val_accuracy: 0.2367\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6326 - accuracy: 0.3329 - val_loss: 1.8309 - val_accuracy: 0.2200\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6308 - accuracy: 0.3300 - val_loss: 1.8241 - val_accuracy: 0.2200\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6308 - accuracy: 0.3343 - val_loss: 1.8329 - val_accuracy: 0.2300\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.6285 - accuracy: 0.3257 - val_loss: 1.8336 - val_accuracy: 0.2433\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6278 - accuracy: 0.3300 - val_loss: 1.8304 - val_accuracy: 0.2233\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.6271 - accuracy: 0.3257 - val_loss: 1.8406 - val_accuracy: 0.2300\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6265 - accuracy: 0.3271 - val_loss: 1.8350 - val_accuracy: 0.2267\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6254 - accuracy: 0.3371 - val_loss: 1.8365 - val_accuracy: 0.2300\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6239 - accuracy: 0.3314 - val_loss: 1.8264 - val_accuracy: 0.2100\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.6236 - accuracy: 0.3200 - val_loss: 1.8396 - val_accuracy: 0.2367\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6230 - accuracy: 0.3286 - val_loss: 1.8344 - val_accuracy: 0.2233\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.6221 - accuracy: 0.3314 - val_loss: 1.8389 - val_accuracy: 0.2633\n",
      "Epoch 168/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 110us/step - loss: 1.6208 - accuracy: 0.3386 - val_loss: 1.8444 - val_accuracy: 0.2200\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6198 - accuracy: 0.3386 - val_loss: 1.8525 - val_accuracy: 0.2233\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6191 - accuracy: 0.3371 - val_loss: 1.8369 - val_accuracy: 0.2233\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6170 - accuracy: 0.3271 - val_loss: 1.8517 - val_accuracy: 0.2600\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6164 - accuracy: 0.3386 - val_loss: 1.8397 - val_accuracy: 0.2133\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6182 - accuracy: 0.3386 - val_loss: 1.8392 - val_accuracy: 0.2367\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6167 - accuracy: 0.3300 - val_loss: 1.8420 - val_accuracy: 0.2200\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6166 - accuracy: 0.3357 - val_loss: 1.8406 - val_accuracy: 0.2200\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6143 - accuracy: 0.3229 - val_loss: 1.8437 - val_accuracy: 0.2600\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6134 - accuracy: 0.3371 - val_loss: 1.8384 - val_accuracy: 0.2167\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6139 - accuracy: 0.3371 - val_loss: 1.8446 - val_accuracy: 0.2267\n",
      "Epoch 179/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6134 - accuracy: 0.3400 - val_loss: 1.8376 - val_accuracy: 0.2233\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6110 - accuracy: 0.3371 - val_loss: 1.8415 - val_accuracy: 0.2667\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6115 - accuracy: 0.3457 - val_loss: 1.8339 - val_accuracy: 0.2567\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6106 - accuracy: 0.3471 - val_loss: 1.8365 - val_accuracy: 0.2167\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6115 - accuracy: 0.3300 - val_loss: 1.8411 - val_accuracy: 0.2333\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6093 - accuracy: 0.3443 - val_loss: 1.8453 - val_accuracy: 0.2267\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6076 - accuracy: 0.3386 - val_loss: 1.8641 - val_accuracy: 0.2200\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6086 - accuracy: 0.3443 - val_loss: 1.8449 - val_accuracy: 0.2233\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6065 - accuracy: 0.3543 - val_loss: 1.8442 - val_accuracy: 0.2167\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6075 - accuracy: 0.3386 - val_loss: 1.8412 - val_accuracy: 0.2133\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6045 - accuracy: 0.3529 - val_loss: 1.8517 - val_accuracy: 0.2233\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6065 - accuracy: 0.3314 - val_loss: 1.8401 - val_accuracy: 0.2300\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6042 - accuracy: 0.3529 - val_loss: 1.8564 - val_accuracy: 0.2233\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6044 - accuracy: 0.3500 - val_loss: 1.8503 - val_accuracy: 0.2200\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6029 - accuracy: 0.3357 - val_loss: 1.8539 - val_accuracy: 0.2267\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6025 - accuracy: 0.3414 - val_loss: 1.8470 - val_accuracy: 0.2267\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6019 - accuracy: 0.3457 - val_loss: 1.8453 - val_accuracy: 0.2467\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6016 - accuracy: 0.3514 - val_loss: 1.8472 - val_accuracy: 0.2167\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6002 - accuracy: 0.3443 - val_loss: 1.8488 - val_accuracy: 0.2300\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6005 - accuracy: 0.3386 - val_loss: 1.8591 - val_accuracy: 0.2200\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6003 - accuracy: 0.3429 - val_loss: 1.8558 - val_accuracy: 0.2200\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5975 - accuracy: 0.3457 - val_loss: 1.8604 - val_accuracy: 0.2633\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5986 - accuracy: 0.3457 - val_loss: 1.8469 - val_accuracy: 0.2167\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5979 - accuracy: 0.3414 - val_loss: 1.8478 - val_accuracy: 0.2100\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5965 - accuracy: 0.3343 - val_loss: 1.8562 - val_accuracy: 0.2267\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5953 - accuracy: 0.3557 - val_loss: 1.8461 - val_accuracy: 0.2067\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5953 - accuracy: 0.3429 - val_loss: 1.8508 - val_accuracy: 0.2200\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5946 - accuracy: 0.3500 - val_loss: 1.8463 - val_accuracy: 0.2133\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5947 - accuracy: 0.3543 - val_loss: 1.8537 - val_accuracy: 0.2233\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5920 - accuracy: 0.3414 - val_loss: 1.8557 - val_accuracy: 0.2233\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5919 - accuracy: 0.3514 - val_loss: 1.8521 - val_accuracy: 0.2300\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5915 - accuracy: 0.3443 - val_loss: 1.8523 - val_accuracy: 0.2267\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5903 - accuracy: 0.3371 - val_loss: 1.8456 - val_accuracy: 0.2567\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5913 - accuracy: 0.3471 - val_loss: 1.8593 - val_accuracy: 0.2200\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5894 - accuracy: 0.3500 - val_loss: 1.8519 - val_accuracy: 0.2233\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5905 - accuracy: 0.3457 - val_loss: 1.8541 - val_accuracy: 0.2267\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5886 - accuracy: 0.3514 - val_loss: 1.8602 - val_accuracy: 0.2667\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5895 - accuracy: 0.3486 - val_loss: 1.8624 - val_accuracy: 0.2267\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5881 - accuracy: 0.3471 - val_loss: 1.8638 - val_accuracy: 0.2300\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5876 - accuracy: 0.3486 - val_loss: 1.8600 - val_accuracy: 0.2300\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5865 - accuracy: 0.3500 - val_loss: 1.8659 - val_accuracy: 0.2267\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5855 - accuracy: 0.3514 - val_loss: 1.8581 - val_accuracy: 0.2267\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5855 - accuracy: 0.3471 - val_loss: 1.8621 - val_accuracy: 0.2267\n",
      "Epoch 222/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5845 - accuracy: 0.3514 - val_loss: 1.8751 - val_accuracy: 0.2500\n",
      "Epoch 223/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5844 - accuracy: 0.3443 - val_loss: 1.8615 - val_accuracy: 0.2600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5845 - accuracy: 0.3529 - val_loss: 1.8766 - val_accuracy: 0.2467\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5833 - accuracy: 0.3457 - val_loss: 1.8572 - val_accuracy: 0.2167\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5835 - accuracy: 0.3486 - val_loss: 1.8686 - val_accuracy: 0.2233\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5825 - accuracy: 0.3486 - val_loss: 1.8611 - val_accuracy: 0.2133\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5825 - accuracy: 0.3443 - val_loss: 1.8693 - val_accuracy: 0.2267\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5801 - accuracy: 0.3471 - val_loss: 1.8688 - val_accuracy: 0.2233\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.5818 - accuracy: 0.3471 - val_loss: 1.8635 - val_accuracy: 0.2133\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5797 - accuracy: 0.3529 - val_loss: 1.8605 - val_accuracy: 0.2200\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5809 - accuracy: 0.3514 - val_loss: 1.8730 - val_accuracy: 0.2133\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5796 - accuracy: 0.3486 - val_loss: 1.8781 - val_accuracy: 0.2200\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5791 - accuracy: 0.3457 - val_loss: 1.8666 - val_accuracy: 0.2133\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5777 - accuracy: 0.3571 - val_loss: 1.8693 - val_accuracy: 0.2100\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5778 - accuracy: 0.3443 - val_loss: 1.8664 - val_accuracy: 0.2133\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5770 - accuracy: 0.3429 - val_loss: 1.8718 - val_accuracy: 0.2300\n",
      "Epoch 238/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.5774 - accuracy: 0.3471 - val_loss: 1.8613 - val_accuracy: 0.2200\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5770 - accuracy: 0.3571 - val_loss: 1.8682 - val_accuracy: 0.2267\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5749 - accuracy: 0.3571 - val_loss: 1.8719 - val_accuracy: 0.2500\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5749 - accuracy: 0.3571 - val_loss: 1.8738 - val_accuracy: 0.2433\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5743 - accuracy: 0.3514 - val_loss: 1.8733 - val_accuracy: 0.2100\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5743 - accuracy: 0.3629 - val_loss: 1.8806 - val_accuracy: 0.2200\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5713 - accuracy: 0.3557 - val_loss: 1.8724 - val_accuracy: 0.2200\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5715 - accuracy: 0.3586 - val_loss: 1.8838 - val_accuracy: 0.2233\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5712 - accuracy: 0.3543 - val_loss: 1.8710 - val_accuracy: 0.2533\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5722 - accuracy: 0.3557 - val_loss: 1.8631 - val_accuracy: 0.2167\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5716 - accuracy: 0.3557 - val_loss: 1.8700 - val_accuracy: 0.2233\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5712 - accuracy: 0.3471 - val_loss: 1.8840 - val_accuracy: 0.2233\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5680 - accuracy: 0.3657 - val_loss: 1.8981 - val_accuracy: 0.2167\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5704 - accuracy: 0.3486 - val_loss: 1.8793 - val_accuracy: 0.2400\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.5682 - accuracy: 0.3643 - val_loss: 1.8744 - val_accuracy: 0.2200\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5689 - accuracy: 0.3586 - val_loss: 1.8820 - val_accuracy: 0.2133\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5677 - accuracy: 0.3571 - val_loss: 1.8835 - val_accuracy: 0.2267\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5681 - accuracy: 0.3457 - val_loss: 1.8713 - val_accuracy: 0.2267\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.5657 - accuracy: 0.3571 - val_loss: 1.8761 - val_accuracy: 0.2533\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5667 - accuracy: 0.3514 - val_loss: 1.8912 - val_accuracy: 0.2467\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5649 - accuracy: 0.3614 - val_loss: 1.8946 - val_accuracy: 0.2567\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5648 - accuracy: 0.3643 - val_loss: 1.8911 - val_accuracy: 0.2167\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5657 - accuracy: 0.3600 - val_loss: 1.8989 - val_accuracy: 0.2200\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5637 - accuracy: 0.3571 - val_loss: 1.8751 - val_accuracy: 0.2167\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5638 - accuracy: 0.3614 - val_loss: 1.8836 - val_accuracy: 0.2100\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5631 - accuracy: 0.3629 - val_loss: 1.8858 - val_accuracy: 0.2100\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5640 - accuracy: 0.3571 - val_loss: 1.8812 - val_accuracy: 0.2133\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5638 - accuracy: 0.3686 - val_loss: 1.8902 - val_accuracy: 0.2200\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5614 - accuracy: 0.3614 - val_loss: 1.8968 - val_accuracy: 0.2500\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5612 - accuracy: 0.3629 - val_loss: 1.8918 - val_accuracy: 0.2300\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5613 - accuracy: 0.3614 - val_loss: 1.8757 - val_accuracy: 0.2100\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5601 - accuracy: 0.3643 - val_loss: 1.8854 - val_accuracy: 0.2133\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5594 - accuracy: 0.3671 - val_loss: 1.8674 - val_accuracy: 0.2333\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5610 - accuracy: 0.3657 - val_loss: 1.8914 - val_accuracy: 0.2333\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5595 - accuracy: 0.3600 - val_loss: 1.9030 - val_accuracy: 0.2267\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5591 - accuracy: 0.3571 - val_loss: 1.8964 - val_accuracy: 0.2200\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5589 - accuracy: 0.3457 - val_loss: 1.8841 - val_accuracy: 0.2233\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5589 - accuracy: 0.3629 - val_loss: 1.8914 - val_accuracy: 0.2200\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5579 - accuracy: 0.3529 - val_loss: 1.8967 - val_accuracy: 0.2533\n",
      "Epoch 277/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5581 - accuracy: 0.3714 - val_loss: 1.8909 - val_accuracy: 0.2167\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5578 - accuracy: 0.3600 - val_loss: 1.9032 - val_accuracy: 0.2300\n",
      "Epoch 279/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 1.5559 - accuracy: 0.3571 - val_loss: 1.8859 - val_accuracy: 0.2167\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5559 - accuracy: 0.3700 - val_loss: 1.8876 - val_accuracy: 0.2167\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5541 - accuracy: 0.3586 - val_loss: 1.8906 - val_accuracy: 0.2333\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5553 - accuracy: 0.3671 - val_loss: 1.8840 - val_accuracy: 0.2133\n",
      "Epoch 283/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5543 - accuracy: 0.3557 - val_loss: 1.8927 - val_accuracy: 0.2167\n",
      "Epoch 284/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5542 - accuracy: 0.3614 - val_loss: 1.8936 - val_accuracy: 0.2567\n",
      "Epoch 285/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.5535 - accuracy: 0.3557 - val_loss: 1.8887 - val_accuracy: 0.2200\n",
      "Epoch 286/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5536 - accuracy: 0.3586 - val_loss: 1.8989 - val_accuracy: 0.2233\n",
      "Epoch 287/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5527 - accuracy: 0.3686 - val_loss: 1.9019 - val_accuracy: 0.2133\n",
      "Epoch 288/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.5525 - accuracy: 0.3600 - val_loss: 1.8930 - val_accuracy: 0.2133\n",
      "Epoch 289/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5519 - accuracy: 0.3600 - val_loss: 1.9014 - val_accuracy: 0.2167\n",
      "Epoch 290/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5514 - accuracy: 0.3657 - val_loss: 1.9032 - val_accuracy: 0.2200\n",
      "Epoch 291/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5513 - accuracy: 0.3586 - val_loss: 1.9037 - val_accuracy: 0.2167\n",
      "Epoch 292/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5509 - accuracy: 0.3543 - val_loss: 1.8995 - val_accuracy: 0.2433\n",
      "Epoch 293/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5507 - accuracy: 0.3543 - val_loss: 1.9011 - val_accuracy: 0.2300\n",
      "Epoch 294/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5497 - accuracy: 0.3543 - val_loss: 1.9002 - val_accuracy: 0.2567\n",
      "Epoch 295/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5499 - accuracy: 0.3657 - val_loss: 1.9120 - val_accuracy: 0.2200\n",
      "Epoch 296/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5495 - accuracy: 0.3571 - val_loss: 1.9104 - val_accuracy: 0.2133\n",
      "Epoch 297/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5479 - accuracy: 0.3571 - val_loss: 1.9128 - val_accuracy: 0.2167\n",
      "Epoch 298/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5477 - accuracy: 0.3486 - val_loss: 1.8958 - val_accuracy: 0.2267\n",
      "Epoch 299/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5485 - accuracy: 0.3686 - val_loss: 1.9145 - val_accuracy: 0.2267\n",
      "Epoch 300/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5472 - accuracy: 0.3629 - val_loss: 1.9031 - val_accuracy: 0.2300\n",
      "Epoch 301/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5469 - accuracy: 0.3629 - val_loss: 1.8934 - val_accuracy: 0.2200\n",
      "Epoch 302/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5479 - accuracy: 0.3657 - val_loss: 1.9081 - val_accuracy: 0.2167\n",
      "Epoch 303/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5464 - accuracy: 0.3529 - val_loss: 1.9016 - val_accuracy: 0.2333\n",
      "Epoch 304/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5452 - accuracy: 0.3671 - val_loss: 1.9066 - val_accuracy: 0.2200\n",
      "Epoch 305/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5432 - accuracy: 0.3643 - val_loss: 1.9140 - val_accuracy: 0.2267\n",
      "Epoch 306/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5458 - accuracy: 0.3600 - val_loss: 1.9100 - val_accuracy: 0.2233\n",
      "Epoch 307/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5436 - accuracy: 0.3671 - val_loss: 1.9064 - val_accuracy: 0.2267\n",
      "Epoch 308/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5453 - accuracy: 0.3600 - val_loss: 1.9129 - val_accuracy: 0.2333\n",
      "Epoch 309/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5435 - accuracy: 0.3643 - val_loss: 1.9120 - val_accuracy: 0.2367\n",
      "Epoch 310/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5448 - accuracy: 0.3671 - val_loss: 1.9110 - val_accuracy: 0.2167\n",
      "Epoch 311/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5426 - accuracy: 0.3586 - val_loss: 1.9058 - val_accuracy: 0.2300\n",
      "Epoch 312/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5423 - accuracy: 0.3729 - val_loss: 1.9273 - val_accuracy: 0.2367\n",
      "Epoch 313/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5387 - accuracy: 0.3657 - val_loss: 1.9056 - val_accuracy: 0.2633\n",
      "Epoch 314/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5433 - accuracy: 0.3686 - val_loss: 1.9131 - val_accuracy: 0.2300\n",
      "Epoch 315/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.5406 - accuracy: 0.3657 - val_loss: 1.9118 - val_accuracy: 0.2233\n",
      "Epoch 316/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5404 - accuracy: 0.3614 - val_loss: 1.9141 - val_accuracy: 0.2233\n",
      "Epoch 317/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5412 - accuracy: 0.3614 - val_loss: 1.9213 - val_accuracy: 0.2333\n",
      "Epoch 318/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5408 - accuracy: 0.3614 - val_loss: 1.9096 - val_accuracy: 0.2300\n",
      "Epoch 319/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5390 - accuracy: 0.3614 - val_loss: 1.9092 - val_accuracy: 0.2300\n",
      "Epoch 320/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5392 - accuracy: 0.3629 - val_loss: 1.9278 - val_accuracy: 0.2233\n",
      "Epoch 321/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5392 - accuracy: 0.3686 - val_loss: 1.9258 - val_accuracy: 0.2300\n",
      "Epoch 322/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5375 - accuracy: 0.3671 - val_loss: 1.9181 - val_accuracy: 0.2533\n",
      "Epoch 323/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5383 - accuracy: 0.3714 - val_loss: 1.9197 - val_accuracy: 0.2300\n",
      "Epoch 324/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5373 - accuracy: 0.3657 - val_loss: 1.9227 - val_accuracy: 0.2200\n",
      "Epoch 325/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5387 - accuracy: 0.3600 - val_loss: 1.9178 - val_accuracy: 0.2133\n",
      "Epoch 326/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5365 - accuracy: 0.3614 - val_loss: 1.9227 - val_accuracy: 0.2200\n",
      "Epoch 327/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5359 - accuracy: 0.3743 - val_loss: 1.9378 - val_accuracy: 0.2333\n",
      "Epoch 328/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5366 - accuracy: 0.3657 - val_loss: 1.9307 - val_accuracy: 0.2233\n",
      "Epoch 329/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5354 - accuracy: 0.3714 - val_loss: 1.9147 - val_accuracy: 0.2300\n",
      "Epoch 330/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5351 - accuracy: 0.3600 - val_loss: 1.9222 - val_accuracy: 0.2333\n",
      "Epoch 331/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.5338 - accuracy: 0.3714 - val_loss: 1.9155 - val_accuracy: 0.2200\n",
      "Epoch 332/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5346 - accuracy: 0.3571 - val_loss: 1.9340 - val_accuracy: 0.2500\n",
      "Epoch 333/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5358 - accuracy: 0.3671 - val_loss: 1.9234 - val_accuracy: 0.2233\n",
      "Epoch 334/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5349 - accuracy: 0.3629 - val_loss: 1.9289 - val_accuracy: 0.2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5327 - accuracy: 0.3757 - val_loss: 1.9246 - val_accuracy: 0.2567\n",
      "Epoch 336/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5335 - accuracy: 0.3786 - val_loss: 1.9184 - val_accuracy: 0.2300\n",
      "Epoch 337/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5330 - accuracy: 0.3757 - val_loss: 1.9324 - val_accuracy: 0.2300\n",
      "Epoch 338/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5320 - accuracy: 0.3743 - val_loss: 1.9238 - val_accuracy: 0.2133\n",
      "Epoch 339/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5314 - accuracy: 0.3700 - val_loss: 1.9157 - val_accuracy: 0.2167\n",
      "Epoch 340/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5328 - accuracy: 0.3729 - val_loss: 1.9403 - val_accuracy: 0.2267\n",
      "Epoch 341/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5317 - accuracy: 0.3757 - val_loss: 1.9258 - val_accuracy: 0.2267\n",
      "Epoch 342/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.5313 - accuracy: 0.3600 - val_loss: 1.9441 - val_accuracy: 0.2167\n",
      "Epoch 343/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5310 - accuracy: 0.3686 - val_loss: 1.9333 - val_accuracy: 0.2267\n",
      "Epoch 344/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5308 - accuracy: 0.3671 - val_loss: 1.9431 - val_accuracy: 0.2300\n",
      "Epoch 345/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5291 - accuracy: 0.3686 - val_loss: 1.9443 - val_accuracy: 0.2567\n",
      "Epoch 346/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5301 - accuracy: 0.3700 - val_loss: 1.9314 - val_accuracy: 0.2267\n",
      "Epoch 347/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5277 - accuracy: 0.3800 - val_loss: 1.9199 - val_accuracy: 0.2200\n",
      "Epoch 348/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5284 - accuracy: 0.3643 - val_loss: 1.9294 - val_accuracy: 0.2167\n",
      "Epoch 349/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5281 - accuracy: 0.3700 - val_loss: 1.9273 - val_accuracy: 0.2133\n",
      "Epoch 350/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5282 - accuracy: 0.3657 - val_loss: 1.9311 - val_accuracy: 0.2300\n",
      "Epoch 351/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5264 - accuracy: 0.3757 - val_loss: 1.9309 - val_accuracy: 0.2333\n",
      "Epoch 352/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5283 - accuracy: 0.3729 - val_loss: 1.9282 - val_accuracy: 0.2300\n",
      "Epoch 353/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5256 - accuracy: 0.3657 - val_loss: 1.9422 - val_accuracy: 0.2300\n",
      "Epoch 354/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5279 - accuracy: 0.3700 - val_loss: 1.9350 - val_accuracy: 0.2167\n",
      "Epoch 355/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5261 - accuracy: 0.3600 - val_loss: 1.9553 - val_accuracy: 0.2267\n",
      "Epoch 356/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5260 - accuracy: 0.3700 - val_loss: 1.9442 - val_accuracy: 0.2433\n",
      "Epoch 357/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5259 - accuracy: 0.3743 - val_loss: 1.9355 - val_accuracy: 0.2267\n",
      "Epoch 358/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5251 - accuracy: 0.3729 - val_loss: 1.9494 - val_accuracy: 0.2233\n",
      "Epoch 359/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5251 - accuracy: 0.3729 - val_loss: 1.9450 - val_accuracy: 0.2133\n",
      "Epoch 360/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5232 - accuracy: 0.3743 - val_loss: 1.9454 - val_accuracy: 0.2233\n",
      "Epoch 361/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5232 - accuracy: 0.3686 - val_loss: 1.9485 - val_accuracy: 0.2300\n",
      "Epoch 362/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5240 - accuracy: 0.3643 - val_loss: 1.9508 - val_accuracy: 0.2267\n",
      "Epoch 363/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5215 - accuracy: 0.3757 - val_loss: 1.9527 - val_accuracy: 0.2333\n",
      "Epoch 364/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5230 - accuracy: 0.3643 - val_loss: 1.9381 - val_accuracy: 0.2300\n",
      "Epoch 365/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5224 - accuracy: 0.3771 - val_loss: 1.9524 - val_accuracy: 0.2267\n",
      "Epoch 366/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5222 - accuracy: 0.3686 - val_loss: 1.9406 - val_accuracy: 0.2133\n",
      "Epoch 367/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5221 - accuracy: 0.3757 - val_loss: 1.9567 - val_accuracy: 0.2300\n",
      "Epoch 368/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5206 - accuracy: 0.3786 - val_loss: 1.9551 - val_accuracy: 0.2367\n",
      "Epoch 369/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5207 - accuracy: 0.3629 - val_loss: 1.9321 - val_accuracy: 0.2367\n",
      "Epoch 370/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5200 - accuracy: 0.3757 - val_loss: 1.9534 - val_accuracy: 0.2400\n",
      "Epoch 371/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5209 - accuracy: 0.3671 - val_loss: 1.9508 - val_accuracy: 0.2233\n",
      "Epoch 372/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5195 - accuracy: 0.3729 - val_loss: 1.9590 - val_accuracy: 0.2333\n",
      "Epoch 373/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.5205 - accuracy: 0.3757 - val_loss: 1.9453 - val_accuracy: 0.2133\n",
      "Epoch 374/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5197 - accuracy: 0.3686 - val_loss: 1.9514 - val_accuracy: 0.2267\n",
      "Epoch 375/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5181 - accuracy: 0.3843 - val_loss: 1.9386 - val_accuracy: 0.2267\n",
      "Epoch 376/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5182 - accuracy: 0.3800 - val_loss: 1.9487 - val_accuracy: 0.2167\n",
      "Epoch 377/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5170 - accuracy: 0.3743 - val_loss: 1.9760 - val_accuracy: 0.2267\n",
      "Epoch 378/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5182 - accuracy: 0.3743 - val_loss: 1.9761 - val_accuracy: 0.2367\n",
      "Epoch 379/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5188 - accuracy: 0.3700 - val_loss: 1.9516 - val_accuracy: 0.2367\n",
      "Epoch 380/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5166 - accuracy: 0.3671 - val_loss: 1.9602 - val_accuracy: 0.2567\n",
      "Epoch 381/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5180 - accuracy: 0.3786 - val_loss: 1.9711 - val_accuracy: 0.2167\n",
      "Epoch 382/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5161 - accuracy: 0.3743 - val_loss: 1.9585 - val_accuracy: 0.2267\n",
      "Epoch 383/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5155 - accuracy: 0.3700 - val_loss: 1.9714 - val_accuracy: 0.2433\n",
      "Epoch 384/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5164 - accuracy: 0.3771 - val_loss: 1.9509 - val_accuracy: 0.2233\n",
      "Epoch 385/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5163 - accuracy: 0.3743 - val_loss: 1.9579 - val_accuracy: 0.2267\n",
      "Epoch 386/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5156 - accuracy: 0.3714 - val_loss: 1.9502 - val_accuracy: 0.2333\n",
      "Epoch 387/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5153 - accuracy: 0.3743 - val_loss: 1.9578 - val_accuracy: 0.2300\n",
      "Epoch 388/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5143 - accuracy: 0.3714 - val_loss: 1.9668 - val_accuracy: 0.2467\n",
      "Epoch 389/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5158 - accuracy: 0.3800 - val_loss: 1.9490 - val_accuracy: 0.2267\n",
      "Epoch 390/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 1.5125 - accuracy: 0.3671 - val_loss: 1.9572 - val_accuracy: 0.2400\n",
      "Epoch 391/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5132 - accuracy: 0.3757 - val_loss: 1.9539 - val_accuracy: 0.2367\n",
      "Epoch 392/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5137 - accuracy: 0.3714 - val_loss: 1.9599 - val_accuracy: 0.2233\n",
      "Epoch 393/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5137 - accuracy: 0.3757 - val_loss: 1.9730 - val_accuracy: 0.2233\n",
      "Epoch 394/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5136 - accuracy: 0.3757 - val_loss: 1.9565 - val_accuracy: 0.2267\n",
      "Epoch 395/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5132 - accuracy: 0.3771 - val_loss: 1.9565 - val_accuracy: 0.2167\n",
      "Epoch 396/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5124 - accuracy: 0.3771 - val_loss: 1.9619 - val_accuracy: 0.2167\n",
      "Epoch 397/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5111 - accuracy: 0.3857 - val_loss: 1.9755 - val_accuracy: 0.2367\n",
      "Epoch 398/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5124 - accuracy: 0.3643 - val_loss: 1.9588 - val_accuracy: 0.2200\n",
      "Epoch 399/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5107 - accuracy: 0.3743 - val_loss: 1.9904 - val_accuracy: 0.2333\n",
      "Epoch 400/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5113 - accuracy: 0.3643 - val_loss: 1.9599 - val_accuracy: 0.2167\n",
      "Epoch 401/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5109 - accuracy: 0.3657 - val_loss: 1.9595 - val_accuracy: 0.2267\n",
      "Epoch 402/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5086 - accuracy: 0.3771 - val_loss: 1.9650 - val_accuracy: 0.2233\n",
      "Epoch 403/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5068 - accuracy: 0.3843 - val_loss: 1.9968 - val_accuracy: 0.2200\n",
      "Epoch 404/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5085 - accuracy: 0.3743 - val_loss: 1.9680 - val_accuracy: 0.2333\n",
      "Epoch 405/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.5074 - accuracy: 0.3800 - val_loss: 1.9833 - val_accuracy: 0.2300\n",
      "Epoch 406/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5085 - accuracy: 0.3771 - val_loss: 1.9756 - val_accuracy: 0.2200\n",
      "Epoch 407/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5080 - accuracy: 0.3714 - val_loss: 1.9815 - val_accuracy: 0.2267\n",
      "Epoch 408/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5077 - accuracy: 0.3757 - val_loss: 1.9711 - val_accuracy: 0.2267\n",
      "Epoch 409/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5040 - accuracy: 0.3700 - val_loss: 1.9807 - val_accuracy: 0.2367\n",
      "Epoch 410/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5058 - accuracy: 0.3771 - val_loss: 1.9611 - val_accuracy: 0.2267\n",
      "Epoch 411/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5056 - accuracy: 0.3714 - val_loss: 1.9846 - val_accuracy: 0.2300\n",
      "Epoch 412/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.5048 - accuracy: 0.3843 - val_loss: 1.9728 - val_accuracy: 0.2233\n",
      "Epoch 413/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5033 - accuracy: 0.3771 - val_loss: 1.9781 - val_accuracy: 0.2333\n",
      "Epoch 414/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5043 - accuracy: 0.3786 - val_loss: 1.9881 - val_accuracy: 0.2333\n",
      "Epoch 415/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5015 - accuracy: 0.3786 - val_loss: 1.9798 - val_accuracy: 0.2333\n",
      "Epoch 416/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5031 - accuracy: 0.3843 - val_loss: 1.9929 - val_accuracy: 0.2267\n",
      "Epoch 417/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5032 - accuracy: 0.3786 - val_loss: 1.9828 - val_accuracy: 0.2200\n",
      "Epoch 418/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5016 - accuracy: 0.3871 - val_loss: 1.9756 - val_accuracy: 0.2333\n",
      "Epoch 419/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5019 - accuracy: 0.3786 - val_loss: 1.9663 - val_accuracy: 0.2200\n",
      "Epoch 420/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5015 - accuracy: 0.3800 - val_loss: 1.9912 - val_accuracy: 0.2300\n",
      "Epoch 421/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5011 - accuracy: 0.3829 - val_loss: 1.9693 - val_accuracy: 0.2433\n",
      "Epoch 422/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5004 - accuracy: 0.3743 - val_loss: 1.9759 - val_accuracy: 0.2433\n",
      "Epoch 423/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5003 - accuracy: 0.3814 - val_loss: 1.9815 - val_accuracy: 0.2333\n",
      "Epoch 424/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5001 - accuracy: 0.3757 - val_loss: 1.9681 - val_accuracy: 0.2200\n",
      "Epoch 425/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4991 - accuracy: 0.3886 - val_loss: 1.9619 - val_accuracy: 0.2400\n",
      "Epoch 426/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4984 - accuracy: 0.3914 - val_loss: 1.9803 - val_accuracy: 0.2167\n",
      "Epoch 427/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4983 - accuracy: 0.3814 - val_loss: 1.9858 - val_accuracy: 0.2533\n",
      "Epoch 428/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4984 - accuracy: 0.3843 - val_loss: 2.0113 - val_accuracy: 0.2300\n",
      "Epoch 429/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4982 - accuracy: 0.3771 - val_loss: 1.9701 - val_accuracy: 0.2300\n",
      "Epoch 430/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4977 - accuracy: 0.3814 - val_loss: 1.9836 - val_accuracy: 0.2467\n",
      "Epoch 431/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4990 - accuracy: 0.3786 - val_loss: 1.9920 - val_accuracy: 0.2333\n",
      "Epoch 432/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4974 - accuracy: 0.3843 - val_loss: 1.9780 - val_accuracy: 0.2233\n",
      "Epoch 433/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4967 - accuracy: 0.3814 - val_loss: 1.9880 - val_accuracy: 0.2367\n",
      "Epoch 434/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4976 - accuracy: 0.3743 - val_loss: 1.9917 - val_accuracy: 0.2233\n",
      "Epoch 435/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4957 - accuracy: 0.3900 - val_loss: 1.9837 - val_accuracy: 0.2267\n",
      "Epoch 436/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4975 - accuracy: 0.3843 - val_loss: 1.9691 - val_accuracy: 0.2233\n",
      "Epoch 437/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4957 - accuracy: 0.3943 - val_loss: 1.9995 - val_accuracy: 0.2200\n",
      "Epoch 438/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4948 - accuracy: 0.3857 - val_loss: 1.9635 - val_accuracy: 0.2300\n",
      "Epoch 439/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4946 - accuracy: 0.3771 - val_loss: 1.9794 - val_accuracy: 0.2233\n",
      "Epoch 440/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4960 - accuracy: 0.3800 - val_loss: 1.9815 - val_accuracy: 0.2300\n",
      "Epoch 441/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4951 - accuracy: 0.3886 - val_loss: 1.9841 - val_accuracy: 0.2300\n",
      "Epoch 442/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4944 - accuracy: 0.3829 - val_loss: 1.9982 - val_accuracy: 0.2233\n",
      "Epoch 443/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4937 - accuracy: 0.3857 - val_loss: 1.9936 - val_accuracy: 0.2400\n",
      "Epoch 444/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4946 - accuracy: 0.3829 - val_loss: 1.9965 - val_accuracy: 0.2233\n",
      "Epoch 445/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4942 - accuracy: 0.3829 - val_loss: 2.0001 - val_accuracy: 0.2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4931 - accuracy: 0.3886 - val_loss: 2.0088 - val_accuracy: 0.2267\n",
      "Epoch 447/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4926 - accuracy: 0.3800 - val_loss: 2.0223 - val_accuracy: 0.2300\n",
      "Epoch 448/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4927 - accuracy: 0.3843 - val_loss: 1.9971 - val_accuracy: 0.2267\n",
      "Epoch 449/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4918 - accuracy: 0.3886 - val_loss: 2.0059 - val_accuracy: 0.2333\n",
      "Epoch 450/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4929 - accuracy: 0.3843 - val_loss: 1.9975 - val_accuracy: 0.2233\n",
      "Epoch 451/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4919 - accuracy: 0.3843 - val_loss: 2.0043 - val_accuracy: 0.2233\n",
      "Epoch 452/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4908 - accuracy: 0.3857 - val_loss: 1.9997 - val_accuracy: 0.2300\n",
      "Epoch 453/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4910 - accuracy: 0.3871 - val_loss: 1.9943 - val_accuracy: 0.2333\n",
      "Epoch 454/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4908 - accuracy: 0.3871 - val_loss: 2.0016 - val_accuracy: 0.2333\n",
      "Epoch 455/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4907 - accuracy: 0.3843 - val_loss: 1.9913 - val_accuracy: 0.2233\n",
      "Epoch 456/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4898 - accuracy: 0.3786 - val_loss: 1.9959 - val_accuracy: 0.2467\n",
      "Epoch 457/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4899 - accuracy: 0.3871 - val_loss: 2.0019 - val_accuracy: 0.2333\n",
      "Epoch 458/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4902 - accuracy: 0.3857 - val_loss: 1.9970 - val_accuracy: 0.2267\n",
      "Epoch 459/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4881 - accuracy: 0.3943 - val_loss: 1.9948 - val_accuracy: 0.2433\n",
      "Epoch 460/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4900 - accuracy: 0.3886 - val_loss: 2.0062 - val_accuracy: 0.2300\n",
      "Epoch 461/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4883 - accuracy: 0.3957 - val_loss: 2.0089 - val_accuracy: 0.2300\n",
      "Epoch 462/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4883 - accuracy: 0.3900 - val_loss: 1.9980 - val_accuracy: 0.2267\n",
      "Epoch 463/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4872 - accuracy: 0.3857 - val_loss: 2.0059 - val_accuracy: 0.2467\n",
      "Epoch 464/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4871 - accuracy: 0.3871 - val_loss: 1.9923 - val_accuracy: 0.2333\n",
      "Epoch 465/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4877 - accuracy: 0.3900 - val_loss: 2.0023 - val_accuracy: 0.2233\n",
      "Epoch 466/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4871 - accuracy: 0.3757 - val_loss: 2.0065 - val_accuracy: 0.2267\n",
      "Epoch 467/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4873 - accuracy: 0.3871 - val_loss: 2.0133 - val_accuracy: 0.2300\n",
      "Epoch 468/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4865 - accuracy: 0.3829 - val_loss: 1.9941 - val_accuracy: 0.2267\n",
      "Epoch 469/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4859 - accuracy: 0.3871 - val_loss: 2.0429 - val_accuracy: 0.2333\n",
      "Epoch 470/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4871 - accuracy: 0.3871 - val_loss: 2.0173 - val_accuracy: 0.2233\n",
      "Epoch 471/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4859 - accuracy: 0.3957 - val_loss: 2.0124 - val_accuracy: 0.2267\n",
      "Epoch 472/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4845 - accuracy: 0.3971 - val_loss: 2.0157 - val_accuracy: 0.2367\n",
      "Epoch 473/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4850 - accuracy: 0.3914 - val_loss: 2.0205 - val_accuracy: 0.2367\n",
      "Epoch 474/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4838 - accuracy: 0.3900 - val_loss: 2.0030 - val_accuracy: 0.2267\n",
      "Epoch 475/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4842 - accuracy: 0.3900 - val_loss: 2.0116 - val_accuracy: 0.2233\n",
      "Epoch 476/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4835 - accuracy: 0.3900 - val_loss: 2.0127 - val_accuracy: 0.2267\n",
      "Epoch 477/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4839 - accuracy: 0.3900 - val_loss: 2.0173 - val_accuracy: 0.2267\n",
      "Epoch 478/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4838 - accuracy: 0.3929 - val_loss: 2.0124 - val_accuracy: 0.2333\n",
      "Epoch 479/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4833 - accuracy: 0.3900 - val_loss: 2.0080 - val_accuracy: 0.2300\n",
      "Epoch 480/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4824 - accuracy: 0.3957 - val_loss: 2.0183 - val_accuracy: 0.2367\n",
      "Epoch 481/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4821 - accuracy: 0.3871 - val_loss: 2.0288 - val_accuracy: 0.2400\n",
      "Epoch 482/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4810 - accuracy: 0.3986 - val_loss: 2.0248 - val_accuracy: 0.2300\n",
      "Epoch 483/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4821 - accuracy: 0.4000 - val_loss: 2.0233 - val_accuracy: 0.2367\n",
      "Epoch 484/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4815 - accuracy: 0.3986 - val_loss: 2.0255 - val_accuracy: 0.2400\n",
      "Epoch 485/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4811 - accuracy: 0.4029 - val_loss: 2.0243 - val_accuracy: 0.2300\n",
      "Epoch 486/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4808 - accuracy: 0.3857 - val_loss: 2.0156 - val_accuracy: 0.2467\n",
      "Epoch 487/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4811 - accuracy: 0.3957 - val_loss: 2.0159 - val_accuracy: 0.2500\n",
      "Epoch 488/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4808 - accuracy: 0.3914 - val_loss: 2.0247 - val_accuracy: 0.2500\n",
      "Epoch 489/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4804 - accuracy: 0.3886 - val_loss: 2.0107 - val_accuracy: 0.2267\n",
      "Epoch 490/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4809 - accuracy: 0.3900 - val_loss: 2.0066 - val_accuracy: 0.2333\n",
      "Epoch 491/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4808 - accuracy: 0.3871 - val_loss: 2.0321 - val_accuracy: 0.2300\n",
      "Epoch 492/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4800 - accuracy: 0.3914 - val_loss: 2.0072 - val_accuracy: 0.2267\n",
      "Epoch 493/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4799 - accuracy: 0.4014 - val_loss: 2.0164 - val_accuracy: 0.2333\n",
      "Epoch 494/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4802 - accuracy: 0.3900 - val_loss: 2.0155 - val_accuracy: 0.2233\n",
      "Epoch 495/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4792 - accuracy: 0.4029 - val_loss: 2.0383 - val_accuracy: 0.2333\n",
      "Epoch 496/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4786 - accuracy: 0.3857 - val_loss: 2.0199 - val_accuracy: 0.2433\n",
      "Epoch 497/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4773 - accuracy: 0.3929 - val_loss: 2.0210 - val_accuracy: 0.2467\n",
      "Epoch 498/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4763 - accuracy: 0.3886 - val_loss: 2.0652 - val_accuracy: 0.2367\n",
      "Epoch 499/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4775 - accuracy: 0.4014 - val_loss: 2.0415 - val_accuracy: 0.2367\n",
      "Epoch 500/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4780 - accuracy: 0.3929 - val_loss: 2.0389 - val_accuracy: 0.2367\n",
      "Epoch 501/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 79us/step - loss: 1.4782 - accuracy: 0.4000 - val_loss: 2.0378 - val_accuracy: 0.2300\n",
      "Epoch 502/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4760 - accuracy: 0.3943 - val_loss: 2.0391 - val_accuracy: 0.2267\n",
      "Epoch 503/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4766 - accuracy: 0.3957 - val_loss: 2.0315 - val_accuracy: 0.2267\n",
      "Epoch 504/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4757 - accuracy: 0.3971 - val_loss: 2.0373 - val_accuracy: 0.2267\n",
      "Epoch 505/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4754 - accuracy: 0.3957 - val_loss: 2.0319 - val_accuracy: 0.2400\n",
      "Epoch 506/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4754 - accuracy: 0.3986 - val_loss: 2.0256 - val_accuracy: 0.2300\n",
      "Epoch 507/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4769 - accuracy: 0.3986 - val_loss: 2.0355 - val_accuracy: 0.2233\n",
      "Epoch 508/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4750 - accuracy: 0.3900 - val_loss: 2.0376 - val_accuracy: 0.2267\n",
      "Epoch 509/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4744 - accuracy: 0.3943 - val_loss: 2.0544 - val_accuracy: 0.2333\n",
      "Epoch 510/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4745 - accuracy: 0.3914 - val_loss: 2.0370 - val_accuracy: 0.2233\n",
      "Epoch 511/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4737 - accuracy: 0.4029 - val_loss: 2.0263 - val_accuracy: 0.2267\n",
      "Epoch 512/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4739 - accuracy: 0.3971 - val_loss: 2.0206 - val_accuracy: 0.2467\n",
      "Epoch 513/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4732 - accuracy: 0.3986 - val_loss: 2.0255 - val_accuracy: 0.2433\n",
      "Epoch 514/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4727 - accuracy: 0.4000 - val_loss: 2.0425 - val_accuracy: 0.2267\n",
      "Epoch 515/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4734 - accuracy: 0.4014 - val_loss: 2.0394 - val_accuracy: 0.2300\n",
      "Epoch 516/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4741 - accuracy: 0.3957 - val_loss: 2.0433 - val_accuracy: 0.2267\n",
      "Epoch 517/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4706 - accuracy: 0.3929 - val_loss: 2.0516 - val_accuracy: 0.2500\n",
      "Epoch 518/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4740 - accuracy: 0.4000 - val_loss: 2.0528 - val_accuracy: 0.2267\n",
      "Epoch 519/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4727 - accuracy: 0.4043 - val_loss: 2.0387 - val_accuracy: 0.2300\n",
      "Epoch 520/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4718 - accuracy: 0.3957 - val_loss: 2.0482 - val_accuracy: 0.2400\n",
      "Epoch 521/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4713 - accuracy: 0.4129 - val_loss: 2.0242 - val_accuracy: 0.2333\n",
      "Epoch 522/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4725 - accuracy: 0.3986 - val_loss: 2.0523 - val_accuracy: 0.2267\n",
      "Epoch 523/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4721 - accuracy: 0.3929 - val_loss: 2.0464 - val_accuracy: 0.2267\n",
      "Epoch 524/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4711 - accuracy: 0.3986 - val_loss: 2.0381 - val_accuracy: 0.2333\n",
      "Epoch 525/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4696 - accuracy: 0.4000 - val_loss: 2.0453 - val_accuracy: 0.2467\n",
      "Epoch 526/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4711 - accuracy: 0.4029 - val_loss: 2.0409 - val_accuracy: 0.2267\n",
      "Epoch 527/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4702 - accuracy: 0.3929 - val_loss: 2.0426 - val_accuracy: 0.2300\n",
      "Epoch 528/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4694 - accuracy: 0.4029 - val_loss: 2.0468 - val_accuracy: 0.2267\n",
      "Epoch 529/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4681 - accuracy: 0.3943 - val_loss: 2.0523 - val_accuracy: 0.2267\n",
      "Epoch 530/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4686 - accuracy: 0.4000 - val_loss: 2.0623 - val_accuracy: 0.2267\n",
      "Epoch 531/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4689 - accuracy: 0.3957 - val_loss: 2.0410 - val_accuracy: 0.2433\n",
      "Epoch 532/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4690 - accuracy: 0.4014 - val_loss: 2.0542 - val_accuracy: 0.2433\n",
      "Epoch 533/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4685 - accuracy: 0.4000 - val_loss: 2.0491 - val_accuracy: 0.2300\n",
      "Epoch 534/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4688 - accuracy: 0.3971 - val_loss: 2.0431 - val_accuracy: 0.2300\n",
      "Epoch 535/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4673 - accuracy: 0.4043 - val_loss: 2.0739 - val_accuracy: 0.2433\n",
      "Epoch 536/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4671 - accuracy: 0.4043 - val_loss: 2.0705 - val_accuracy: 0.2267\n",
      "Epoch 537/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4676 - accuracy: 0.4029 - val_loss: 2.0477 - val_accuracy: 0.2300\n",
      "Epoch 538/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4672 - accuracy: 0.3957 - val_loss: 2.0574 - val_accuracy: 0.2367\n",
      "Epoch 539/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4691 - accuracy: 0.3943 - val_loss: 2.0508 - val_accuracy: 0.2267\n",
      "Epoch 540/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4678 - accuracy: 0.4014 - val_loss: 2.0620 - val_accuracy: 0.2267\n",
      "Epoch 541/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4667 - accuracy: 0.4014 - val_loss: 2.0590 - val_accuracy: 0.2267\n",
      "Epoch 542/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4665 - accuracy: 0.4057 - val_loss: 2.0668 - val_accuracy: 0.2433\n",
      "Epoch 543/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4670 - accuracy: 0.4000 - val_loss: 2.0490 - val_accuracy: 0.2333\n",
      "Epoch 544/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4657 - accuracy: 0.3943 - val_loss: 2.0425 - val_accuracy: 0.2367\n",
      "Epoch 545/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4665 - accuracy: 0.4014 - val_loss: 2.0537 - val_accuracy: 0.2300\n",
      "Epoch 546/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4635 - accuracy: 0.4000 - val_loss: 2.0713 - val_accuracy: 0.2533\n",
      "Epoch 547/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4657 - accuracy: 0.4000 - val_loss: 2.0779 - val_accuracy: 0.2400\n",
      "Epoch 548/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4643 - accuracy: 0.3971 - val_loss: 2.0494 - val_accuracy: 0.2300\n",
      "Epoch 549/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4647 - accuracy: 0.4043 - val_loss: 2.0443 - val_accuracy: 0.2333\n",
      "Epoch 550/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4638 - accuracy: 0.4000 - val_loss: 2.0608 - val_accuracy: 0.2300\n",
      "Epoch 551/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4647 - accuracy: 0.4000 - val_loss: 2.0584 - val_accuracy: 0.2300\n",
      "Epoch 552/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4632 - accuracy: 0.4086 - val_loss: 2.0582 - val_accuracy: 0.2333\n",
      "Epoch 553/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4654 - accuracy: 0.4000 - val_loss: 2.0563 - val_accuracy: 0.2300\n",
      "Epoch 554/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4630 - accuracy: 0.3986 - val_loss: 2.0678 - val_accuracy: 0.2300\n",
      "Epoch 555/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4637 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2400\n",
      "Epoch 556/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4621 - accuracy: 0.4000 - val_loss: 2.0621 - val_accuracy: 0.2467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4614 - accuracy: 0.4114 - val_loss: 2.0831 - val_accuracy: 0.2500\n",
      "Epoch 558/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4631 - accuracy: 0.4029 - val_loss: 2.0614 - val_accuracy: 0.2333\n",
      "Epoch 559/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4614 - accuracy: 0.4029 - val_loss: 2.0657 - val_accuracy: 0.2533\n",
      "Epoch 560/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4612 - accuracy: 0.4014 - val_loss: 2.0698 - val_accuracy: 0.2567\n",
      "Epoch 561/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4623 - accuracy: 0.4100 - val_loss: 2.0637 - val_accuracy: 0.2267\n",
      "Epoch 562/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4619 - accuracy: 0.4029 - val_loss: 2.0546 - val_accuracy: 0.2300\n",
      "Epoch 563/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4613 - accuracy: 0.4000 - val_loss: 2.0600 - val_accuracy: 0.2267\n",
      "Epoch 564/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4611 - accuracy: 0.4071 - val_loss: 2.0795 - val_accuracy: 0.2300\n",
      "Epoch 565/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4603 - accuracy: 0.4043 - val_loss: 2.0619 - val_accuracy: 0.2333\n",
      "Epoch 566/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4620 - accuracy: 0.4100 - val_loss: 2.0743 - val_accuracy: 0.2300\n",
      "Epoch 567/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4599 - accuracy: 0.4171 - val_loss: 2.0782 - val_accuracy: 0.2300\n",
      "Epoch 568/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4598 - accuracy: 0.4057 - val_loss: 2.0765 - val_accuracy: 0.2433\n",
      "Epoch 569/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4594 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2533\n",
      "Epoch 570/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4586 - accuracy: 0.4114 - val_loss: 2.0794 - val_accuracy: 0.2333\n",
      "Epoch 571/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4588 - accuracy: 0.4043 - val_loss: 2.0763 - val_accuracy: 0.2300\n",
      "Epoch 572/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4580 - accuracy: 0.4014 - val_loss: 2.0652 - val_accuracy: 0.2333\n",
      "Epoch 573/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4573 - accuracy: 0.4114 - val_loss: 2.0851 - val_accuracy: 0.2533\n",
      "Epoch 574/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4597 - accuracy: 0.4043 - val_loss: 2.0670 - val_accuracy: 0.2500\n",
      "Epoch 575/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4597 - accuracy: 0.4114 - val_loss: 2.0723 - val_accuracy: 0.2267\n",
      "Epoch 576/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4586 - accuracy: 0.3957 - val_loss: 2.0748 - val_accuracy: 0.2300\n",
      "Epoch 577/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4583 - accuracy: 0.4014 - val_loss: 2.0725 - val_accuracy: 0.2300\n",
      "Epoch 578/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4577 - accuracy: 0.4071 - val_loss: 2.0727 - val_accuracy: 0.2367\n",
      "Epoch 579/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4584 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2267\n",
      "Epoch 580/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4574 - accuracy: 0.4086 - val_loss: 2.0834 - val_accuracy: 0.2367\n",
      "Epoch 581/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4570 - accuracy: 0.4071 - val_loss: 2.0783 - val_accuracy: 0.2567\n",
      "Epoch 582/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4569 - accuracy: 0.4071 - val_loss: 2.0819 - val_accuracy: 0.2267\n",
      "Epoch 583/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4563 - accuracy: 0.4014 - val_loss: 2.0840 - val_accuracy: 0.2267\n",
      "Epoch 584/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4571 - accuracy: 0.4071 - val_loss: 2.0817 - val_accuracy: 0.2267\n",
      "Epoch 585/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4558 - accuracy: 0.4100 - val_loss: 2.0865 - val_accuracy: 0.2300\n",
      "Epoch 586/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4549 - accuracy: 0.4043 - val_loss: 2.0878 - val_accuracy: 0.2500\n",
      "Epoch 587/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4573 - accuracy: 0.4114 - val_loss: 2.0871 - val_accuracy: 0.2333\n",
      "Epoch 588/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4560 - accuracy: 0.4043 - val_loss: 2.0902 - val_accuracy: 0.2300\n",
      "Epoch 589/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4553 - accuracy: 0.4057 - val_loss: 2.0906 - val_accuracy: 0.2267\n",
      "Epoch 590/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4553 - accuracy: 0.4014 - val_loss: 2.0836 - val_accuracy: 0.2300\n",
      "Epoch 591/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4554 - accuracy: 0.4086 - val_loss: 2.0946 - val_accuracy: 0.2267\n",
      "Epoch 592/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4544 - accuracy: 0.4086 - val_loss: 2.0885 - val_accuracy: 0.2333\n",
      "Epoch 593/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4546 - accuracy: 0.4057 - val_loss: 2.0817 - val_accuracy: 0.2267\n",
      "Epoch 594/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4540 - accuracy: 0.4129 - val_loss: 2.0828 - val_accuracy: 0.2333\n",
      "Epoch 595/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4543 - accuracy: 0.4057 - val_loss: 2.0905 - val_accuracy: 0.2433\n",
      "Epoch 596/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4537 - accuracy: 0.4129 - val_loss: 2.0782 - val_accuracy: 0.2300\n",
      "Epoch 597/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4525 - accuracy: 0.4143 - val_loss: 2.0808 - val_accuracy: 0.2500\n",
      "Epoch 598/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4537 - accuracy: 0.3986 - val_loss: 2.0903 - val_accuracy: 0.2267\n",
      "Epoch 599/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4541 - accuracy: 0.4043 - val_loss: 2.0796 - val_accuracy: 0.2333\n",
      "Epoch 600/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4525 - accuracy: 0.4143 - val_loss: 2.0989 - val_accuracy: 0.2300\n",
      "Epoch 601/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4523 - accuracy: 0.4129 - val_loss: 2.0981 - val_accuracy: 0.2433\n",
      "Epoch 602/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4526 - accuracy: 0.4029 - val_loss: 2.0933 - val_accuracy: 0.2333\n",
      "Epoch 603/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4527 - accuracy: 0.4114 - val_loss: 2.0824 - val_accuracy: 0.2400\n",
      "Epoch 604/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4525 - accuracy: 0.4029 - val_loss: 2.0809 - val_accuracy: 0.2433\n",
      "Epoch 605/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4516 - accuracy: 0.4057 - val_loss: 2.0888 - val_accuracy: 0.2367\n",
      "Epoch 606/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4517 - accuracy: 0.4100 - val_loss: 2.0793 - val_accuracy: 0.2333\n",
      "Epoch 607/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4518 - accuracy: 0.4100 - val_loss: 2.0931 - val_accuracy: 0.2300\n",
      "Epoch 608/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4515 - accuracy: 0.4071 - val_loss: 2.0832 - val_accuracy: 0.2367\n",
      "Epoch 609/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4500 - accuracy: 0.4157 - val_loss: 2.0998 - val_accuracy: 0.2567\n",
      "Epoch 610/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4507 - accuracy: 0.4129 - val_loss: 2.1012 - val_accuracy: 0.2333\n",
      "Epoch 611/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4508 - accuracy: 0.4129 - val_loss: 2.0975 - val_accuracy: 0.2367\n",
      "Epoch 612/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 100us/step - loss: 1.4506 - accuracy: 0.4086 - val_loss: 2.0951 - val_accuracy: 0.2433\n",
      "Epoch 613/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4505 - accuracy: 0.4086 - val_loss: 2.0964 - val_accuracy: 0.2300\n",
      "Epoch 614/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4496 - accuracy: 0.4129 - val_loss: 2.1080 - val_accuracy: 0.2500\n",
      "Epoch 615/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4502 - accuracy: 0.4129 - val_loss: 2.0887 - val_accuracy: 0.2533\n",
      "Epoch 616/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4495 - accuracy: 0.4129 - val_loss: 2.1144 - val_accuracy: 0.2333\n",
      "Epoch 617/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4480 - accuracy: 0.4157 - val_loss: 2.1039 - val_accuracy: 0.2533\n",
      "Epoch 618/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4491 - accuracy: 0.4014 - val_loss: 2.0963 - val_accuracy: 0.2400\n",
      "Epoch 619/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4479 - accuracy: 0.4114 - val_loss: 2.1056 - val_accuracy: 0.2333\n",
      "Epoch 620/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4488 - accuracy: 0.4171 - val_loss: 2.0924 - val_accuracy: 0.2300\n",
      "Epoch 621/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4487 - accuracy: 0.4129 - val_loss: 2.1158 - val_accuracy: 0.2333\n",
      "Epoch 622/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4476 - accuracy: 0.4114 - val_loss: 2.1155 - val_accuracy: 0.2367\n",
      "Epoch 623/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4471 - accuracy: 0.4186 - val_loss: 2.1097 - val_accuracy: 0.2267\n",
      "Epoch 624/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4480 - accuracy: 0.4171 - val_loss: 2.1088 - val_accuracy: 0.2367\n",
      "Epoch 625/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4479 - accuracy: 0.4029 - val_loss: 2.1142 - val_accuracy: 0.2367\n",
      "Epoch 626/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4471 - accuracy: 0.4086 - val_loss: 2.0894 - val_accuracy: 0.2367\n",
      "Epoch 627/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4478 - accuracy: 0.4257 - val_loss: 2.1022 - val_accuracy: 0.2333\n",
      "Epoch 628/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4459 - accuracy: 0.4157 - val_loss: 2.0855 - val_accuracy: 0.2400\n",
      "Epoch 629/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4475 - accuracy: 0.4100 - val_loss: 2.1012 - val_accuracy: 0.2333\n",
      "Epoch 630/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4460 - accuracy: 0.4114 - val_loss: 2.0909 - val_accuracy: 0.2333\n",
      "Epoch 631/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4468 - accuracy: 0.4114 - val_loss: 2.1271 - val_accuracy: 0.2400\n",
      "Epoch 632/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4467 - accuracy: 0.4086 - val_loss: 2.1177 - val_accuracy: 0.2400\n",
      "Epoch 633/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4455 - accuracy: 0.4143 - val_loss: 2.1269 - val_accuracy: 0.2367\n",
      "Epoch 634/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4457 - accuracy: 0.4129 - val_loss: 2.1139 - val_accuracy: 0.2333\n",
      "Epoch 635/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4444 - accuracy: 0.4071 - val_loss: 2.1061 - val_accuracy: 0.2567\n",
      "Epoch 636/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4463 - accuracy: 0.4129 - val_loss: 2.1088 - val_accuracy: 0.2333\n",
      "Epoch 637/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4451 - accuracy: 0.4114 - val_loss: 2.1212 - val_accuracy: 0.2367\n",
      "Epoch 638/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4452 - accuracy: 0.4114 - val_loss: 2.1277 - val_accuracy: 0.2300\n",
      "Epoch 639/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4449 - accuracy: 0.4086 - val_loss: 2.1286 - val_accuracy: 0.2233\n",
      "Epoch 640/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4441 - accuracy: 0.4157 - val_loss: 2.0973 - val_accuracy: 0.2367\n",
      "Epoch 641/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4437 - accuracy: 0.4143 - val_loss: 2.1183 - val_accuracy: 0.2467\n",
      "Epoch 642/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4448 - accuracy: 0.4100 - val_loss: 2.1281 - val_accuracy: 0.2433\n",
      "Epoch 643/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4439 - accuracy: 0.4129 - val_loss: 2.1331 - val_accuracy: 0.2300\n",
      "Epoch 644/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4440 - accuracy: 0.4129 - val_loss: 2.1148 - val_accuracy: 0.2367\n",
      "Epoch 645/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4432 - accuracy: 0.4186 - val_loss: 2.1250 - val_accuracy: 0.2333\n",
      "Epoch 646/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4414 - accuracy: 0.4114 - val_loss: 2.1179 - val_accuracy: 0.2567\n",
      "Epoch 647/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4423 - accuracy: 0.4114 - val_loss: 2.1133 - val_accuracy: 0.2367\n",
      "Epoch 648/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4431 - accuracy: 0.4100 - val_loss: 2.1343 - val_accuracy: 0.2333\n",
      "Epoch 649/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4415 - accuracy: 0.4057 - val_loss: 2.1301 - val_accuracy: 0.2333\n",
      "Epoch 650/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4432 - accuracy: 0.4143 - val_loss: 2.1169 - val_accuracy: 0.2333\n",
      "Epoch 651/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4418 - accuracy: 0.4157 - val_loss: 2.1391 - val_accuracy: 0.2400\n",
      "Epoch 652/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4430 - accuracy: 0.4114 - val_loss: 2.1186 - val_accuracy: 0.2333\n",
      "Epoch 653/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4415 - accuracy: 0.4171 - val_loss: 2.1247 - val_accuracy: 0.2433\n",
      "Epoch 654/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4414 - accuracy: 0.4143 - val_loss: 2.1066 - val_accuracy: 0.2467\n",
      "Epoch 655/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4406 - accuracy: 0.4100 - val_loss: 2.1201 - val_accuracy: 0.2533\n",
      "Epoch 656/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4426 - accuracy: 0.4086 - val_loss: 2.1340 - val_accuracy: 0.2433\n",
      "Epoch 657/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4409 - accuracy: 0.4186 - val_loss: 2.1286 - val_accuracy: 0.2300\n",
      "Epoch 658/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4409 - accuracy: 0.4143 - val_loss: 2.1242 - val_accuracy: 0.2367\n",
      "Epoch 659/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4404 - accuracy: 0.4186 - val_loss: 2.1269 - val_accuracy: 0.2467\n",
      "Epoch 660/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4409 - accuracy: 0.4100 - val_loss: 2.1270 - val_accuracy: 0.2367\n",
      "Epoch 661/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4418 - accuracy: 0.4086 - val_loss: 2.1221 - val_accuracy: 0.2367\n",
      "Epoch 662/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4410 - accuracy: 0.4000 - val_loss: 2.1275 - val_accuracy: 0.2367\n",
      "Epoch 663/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4402 - accuracy: 0.4157 - val_loss: 2.1482 - val_accuracy: 0.2400\n",
      "Epoch 664/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4394 - accuracy: 0.4186 - val_loss: 2.1317 - val_accuracy: 0.2400\n",
      "Epoch 665/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4396 - accuracy: 0.4114 - val_loss: 2.1400 - val_accuracy: 0.2333\n",
      "Epoch 666/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4390 - accuracy: 0.4200 - val_loss: 2.1294 - val_accuracy: 0.2533\n",
      "Epoch 667/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4406 - accuracy: 0.4114 - val_loss: 2.1217 - val_accuracy: 0.2367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4375 - accuracy: 0.4157 - val_loss: 2.1405 - val_accuracy: 0.2567\n",
      "Epoch 669/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4382 - accuracy: 0.4157 - val_loss: 2.1450 - val_accuracy: 0.2333\n",
      "Epoch 670/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4393 - accuracy: 0.4171 - val_loss: 2.1303 - val_accuracy: 0.2333\n",
      "Epoch 671/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4377 - accuracy: 0.4157 - val_loss: 2.1282 - val_accuracy: 0.2533\n",
      "Epoch 672/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4382 - accuracy: 0.4100 - val_loss: 2.1405 - val_accuracy: 0.2367\n",
      "Epoch 673/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4384 - accuracy: 0.4186 - val_loss: 2.1311 - val_accuracy: 0.2400\n",
      "Epoch 674/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4374 - accuracy: 0.4086 - val_loss: 2.1580 - val_accuracy: 0.2433\n",
      "Epoch 675/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4366 - accuracy: 0.4214 - val_loss: 2.1570 - val_accuracy: 0.2533\n",
      "Epoch 676/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4370 - accuracy: 0.4186 - val_loss: 2.1286 - val_accuracy: 0.2567\n",
      "Epoch 677/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4360 - accuracy: 0.4143 - val_loss: 2.1505 - val_accuracy: 0.2300\n",
      "Epoch 678/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4355 - accuracy: 0.4200 - val_loss: 2.1176 - val_accuracy: 0.2333\n",
      "Epoch 679/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4369 - accuracy: 0.4257 - val_loss: 2.1406 - val_accuracy: 0.2367\n",
      "Epoch 680/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4377 - accuracy: 0.4157 - val_loss: 2.1416 - val_accuracy: 0.2400\n",
      "Epoch 681/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4370 - accuracy: 0.4186 - val_loss: 2.1307 - val_accuracy: 0.2400\n",
      "Epoch 682/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4360 - accuracy: 0.4214 - val_loss: 2.1368 - val_accuracy: 0.2567\n",
      "Epoch 683/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4356 - accuracy: 0.4129 - val_loss: 2.1275 - val_accuracy: 0.2500\n",
      "Epoch 684/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4330 - accuracy: 0.4143 - val_loss: 2.1410 - val_accuracy: 0.2600\n",
      "Epoch 685/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4356 - accuracy: 0.4143 - val_loss: 2.1360 - val_accuracy: 0.2567\n",
      "Epoch 686/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4352 - accuracy: 0.4200 - val_loss: 2.1651 - val_accuracy: 0.2533\n",
      "Epoch 687/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4354 - accuracy: 0.4143 - val_loss: 2.1270 - val_accuracy: 0.2367\n",
      "Epoch 688/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4355 - accuracy: 0.4157 - val_loss: 2.1346 - val_accuracy: 0.2400\n",
      "Epoch 689/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4348 - accuracy: 0.4200 - val_loss: 2.1469 - val_accuracy: 0.2367\n",
      "Epoch 690/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4345 - accuracy: 0.4143 - val_loss: 2.1563 - val_accuracy: 0.2333\n",
      "Epoch 691/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4337 - accuracy: 0.4229 - val_loss: 2.1496 - val_accuracy: 0.2333\n",
      "Epoch 692/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4339 - accuracy: 0.4186 - val_loss: 2.1345 - val_accuracy: 0.2400\n",
      "Epoch 693/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4345 - accuracy: 0.4171 - val_loss: 2.1337 - val_accuracy: 0.2400\n",
      "Epoch 694/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4335 - accuracy: 0.4186 - val_loss: 2.1663 - val_accuracy: 0.2467\n",
      "Epoch 695/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4348 - accuracy: 0.4171 - val_loss: 2.1408 - val_accuracy: 0.2567\n",
      "Epoch 696/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4324 - accuracy: 0.4214 - val_loss: 2.1548 - val_accuracy: 0.2333\n",
      "Epoch 697/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4337 - accuracy: 0.4186 - val_loss: 2.1654 - val_accuracy: 0.2467\n",
      "Epoch 698/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4333 - accuracy: 0.4257 - val_loss: 2.1511 - val_accuracy: 0.2433\n",
      "Epoch 699/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4328 - accuracy: 0.4214 - val_loss: 2.1524 - val_accuracy: 0.2400\n",
      "Epoch 700/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4329 - accuracy: 0.4200 - val_loss: 2.1518 - val_accuracy: 0.2467\n",
      "Epoch 701/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4316 - accuracy: 0.4171 - val_loss: 2.1483 - val_accuracy: 0.2433\n",
      "Epoch 702/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4327 - accuracy: 0.4129 - val_loss: 2.1556 - val_accuracy: 0.2367\n",
      "Epoch 703/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4316 - accuracy: 0.4229 - val_loss: 2.1657 - val_accuracy: 0.2333\n",
      "Epoch 704/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4325 - accuracy: 0.4214 - val_loss: 2.1498 - val_accuracy: 0.2433\n",
      "Epoch 705/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4320 - accuracy: 0.4157 - val_loss: 2.1429 - val_accuracy: 0.2400\n",
      "Epoch 706/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4321 - accuracy: 0.4214 - val_loss: 2.1335 - val_accuracy: 0.2400\n",
      "Epoch 707/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4315 - accuracy: 0.4243 - val_loss: 2.1494 - val_accuracy: 0.2367\n",
      "Epoch 708/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4316 - accuracy: 0.4214 - val_loss: 2.1488 - val_accuracy: 0.2333\n",
      "Epoch 709/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4296 - accuracy: 0.4186 - val_loss: 2.1794 - val_accuracy: 0.2533\n",
      "Epoch 710/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4314 - accuracy: 0.4229 - val_loss: 2.1527 - val_accuracy: 0.2467\n",
      "Epoch 711/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4304 - accuracy: 0.4186 - val_loss: 2.1542 - val_accuracy: 0.2367\n",
      "Epoch 712/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4300 - accuracy: 0.4214 - val_loss: 2.1636 - val_accuracy: 0.2567\n",
      "Epoch 713/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4310 - accuracy: 0.4186 - val_loss: 2.1410 - val_accuracy: 0.2400\n",
      "Epoch 714/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4305 - accuracy: 0.4243 - val_loss: 2.1585 - val_accuracy: 0.2367\n",
      "Epoch 715/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4282 - accuracy: 0.4243 - val_loss: 2.1502 - val_accuracy: 0.2600\n",
      "Epoch 716/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4305 - accuracy: 0.4157 - val_loss: 2.1677 - val_accuracy: 0.2367\n",
      "Epoch 717/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4297 - accuracy: 0.4157 - val_loss: 2.1621 - val_accuracy: 0.2367\n",
      "Epoch 718/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4289 - accuracy: 0.4186 - val_loss: 2.1916 - val_accuracy: 0.2533\n",
      "Epoch 719/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4303 - accuracy: 0.4186 - val_loss: 2.1728 - val_accuracy: 0.2400\n",
      "Epoch 720/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4295 - accuracy: 0.4214 - val_loss: 2.1658 - val_accuracy: 0.2367\n",
      "Epoch 721/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4291 - accuracy: 0.4200 - val_loss: 2.1649 - val_accuracy: 0.2433\n",
      "Epoch 722/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4286 - accuracy: 0.4200 - val_loss: 2.1653 - val_accuracy: 0.2367\n",
      "Epoch 723/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 127us/step - loss: 1.4282 - accuracy: 0.4214 - val_loss: 2.1490 - val_accuracy: 0.2400\n",
      "Epoch 724/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4281 - accuracy: 0.4257 - val_loss: 2.1736 - val_accuracy: 0.2367\n",
      "Epoch 725/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4277 - accuracy: 0.4229 - val_loss: 2.1819 - val_accuracy: 0.2433\n",
      "Epoch 726/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4278 - accuracy: 0.4257 - val_loss: 2.1563 - val_accuracy: 0.2367\n",
      "Epoch 727/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4273 - accuracy: 0.4214 - val_loss: 2.1938 - val_accuracy: 0.2333\n",
      "Epoch 728/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4276 - accuracy: 0.4200 - val_loss: 2.1558 - val_accuracy: 0.2400\n",
      "Epoch 729/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4269 - accuracy: 0.4229 - val_loss: 2.1856 - val_accuracy: 0.2467\n",
      "Epoch 730/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4269 - accuracy: 0.4257 - val_loss: 2.1927 - val_accuracy: 0.2400\n",
      "Epoch 731/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4277 - accuracy: 0.4143 - val_loss: 2.1736 - val_accuracy: 0.2367\n",
      "Epoch 732/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4261 - accuracy: 0.4243 - val_loss: 2.1707 - val_accuracy: 0.2400\n",
      "Epoch 733/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4263 - accuracy: 0.4286 - val_loss: 2.1618 - val_accuracy: 0.2400\n",
      "Epoch 734/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4271 - accuracy: 0.4214 - val_loss: 2.1844 - val_accuracy: 0.2400\n",
      "Epoch 735/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4261 - accuracy: 0.4286 - val_loss: 2.1732 - val_accuracy: 0.2367\n",
      "Epoch 736/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4249 - accuracy: 0.4300 - val_loss: 2.1629 - val_accuracy: 0.2400\n",
      "Epoch 737/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4265 - accuracy: 0.4229 - val_loss: 2.1866 - val_accuracy: 0.2433\n",
      "Epoch 738/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4265 - accuracy: 0.4200 - val_loss: 2.1722 - val_accuracy: 0.2467\n",
      "Epoch 739/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4251 - accuracy: 0.4271 - val_loss: 2.1827 - val_accuracy: 0.2367\n",
      "Epoch 740/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4250 - accuracy: 0.4314 - val_loss: 2.1680 - val_accuracy: 0.2400\n",
      "Epoch 741/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4249 - accuracy: 0.4200 - val_loss: 2.1864 - val_accuracy: 0.2567\n",
      "Epoch 742/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4252 - accuracy: 0.4143 - val_loss: 2.1628 - val_accuracy: 0.2533\n",
      "Epoch 743/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4240 - accuracy: 0.4286 - val_loss: 2.1670 - val_accuracy: 0.2533\n",
      "Epoch 744/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4257 - accuracy: 0.4186 - val_loss: 2.1682 - val_accuracy: 0.2433\n",
      "Epoch 745/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4221 - accuracy: 0.4329 - val_loss: 2.1818 - val_accuracy: 0.2533\n",
      "Epoch 746/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4254 - accuracy: 0.4300 - val_loss: 2.1702 - val_accuracy: 0.2400\n",
      "Epoch 747/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4251 - accuracy: 0.4157 - val_loss: 2.1784 - val_accuracy: 0.2433\n",
      "Epoch 748/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4233 - accuracy: 0.4257 - val_loss: 2.2001 - val_accuracy: 0.2600\n",
      "Epoch 749/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4222 - accuracy: 0.4271 - val_loss: 2.1563 - val_accuracy: 0.2333\n",
      "Epoch 750/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4239 - accuracy: 0.4329 - val_loss: 2.1629 - val_accuracy: 0.2300\n",
      "Epoch 751/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4224 - accuracy: 0.4171 - val_loss: 2.1794 - val_accuracy: 0.2400\n",
      "Epoch 752/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4233 - accuracy: 0.4243 - val_loss: 2.1854 - val_accuracy: 0.2367\n",
      "Epoch 753/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4223 - accuracy: 0.4257 - val_loss: 2.2051 - val_accuracy: 0.2333\n",
      "Epoch 754/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4235 - accuracy: 0.4271 - val_loss: 2.1869 - val_accuracy: 0.2333\n",
      "Epoch 755/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4221 - accuracy: 0.4386 - val_loss: 2.1849 - val_accuracy: 0.2467\n",
      "Epoch 756/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4223 - accuracy: 0.4143 - val_loss: 2.1829 - val_accuracy: 0.2400\n",
      "Epoch 757/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4233 - accuracy: 0.4200 - val_loss: 2.1907 - val_accuracy: 0.2433\n",
      "Epoch 758/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4220 - accuracy: 0.4300 - val_loss: 2.1885 - val_accuracy: 0.2433\n",
      "Epoch 759/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4221 - accuracy: 0.4271 - val_loss: 2.1786 - val_accuracy: 0.2400\n",
      "Epoch 760/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4218 - accuracy: 0.4329 - val_loss: 2.1784 - val_accuracy: 0.2400\n",
      "Epoch 761/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4215 - accuracy: 0.4229 - val_loss: 2.2086 - val_accuracy: 0.2500\n",
      "Epoch 762/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4225 - accuracy: 0.4257 - val_loss: 2.1981 - val_accuracy: 0.2400\n",
      "Epoch 763/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4215 - accuracy: 0.4200 - val_loss: 2.1838 - val_accuracy: 0.2400\n",
      "Epoch 764/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4227 - accuracy: 0.4300 - val_loss: 2.2048 - val_accuracy: 0.2433\n",
      "Epoch 765/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4203 - accuracy: 0.4214 - val_loss: 2.2158 - val_accuracy: 0.2333\n",
      "Epoch 766/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4217 - accuracy: 0.4214 - val_loss: 2.1842 - val_accuracy: 0.2400\n",
      "Epoch 767/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4217 - accuracy: 0.4257 - val_loss: 2.1846 - val_accuracy: 0.2367\n",
      "Epoch 768/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4205 - accuracy: 0.4257 - val_loss: 2.1738 - val_accuracy: 0.2400\n",
      "Epoch 769/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4207 - accuracy: 0.4243 - val_loss: 2.1856 - val_accuracy: 0.2367\n",
      "Epoch 770/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4200 - accuracy: 0.4214 - val_loss: 2.1758 - val_accuracy: 0.2333\n",
      "Epoch 771/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4196 - accuracy: 0.4214 - val_loss: 2.1942 - val_accuracy: 0.2367\n",
      "Epoch 772/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4202 - accuracy: 0.4229 - val_loss: 2.1983 - val_accuracy: 0.2433\n",
      "Epoch 773/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4200 - accuracy: 0.4229 - val_loss: 2.2066 - val_accuracy: 0.2500\n",
      "Epoch 774/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4191 - accuracy: 0.4243 - val_loss: 2.2019 - val_accuracy: 0.2400\n",
      "Epoch 775/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4182 - accuracy: 0.4286 - val_loss: 2.2032 - val_accuracy: 0.2533\n",
      "Epoch 776/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4193 - accuracy: 0.4271 - val_loss: 2.1977 - val_accuracy: 0.2467\n",
      "Epoch 777/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4177 - accuracy: 0.4314 - val_loss: 2.2090 - val_accuracy: 0.2333\n",
      "Epoch 778/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4190 - accuracy: 0.4214 - val_loss: 2.1922 - val_accuracy: 0.2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4191 - accuracy: 0.4300 - val_loss: 2.1962 - val_accuracy: 0.2333\n",
      "Epoch 780/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4190 - accuracy: 0.4229 - val_loss: 2.1879 - val_accuracy: 0.2400\n",
      "Epoch 781/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4196 - accuracy: 0.4214 - val_loss: 2.1973 - val_accuracy: 0.2467\n",
      "Epoch 782/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4184 - accuracy: 0.4257 - val_loss: 2.1738 - val_accuracy: 0.2400\n",
      "Epoch 783/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4186 - accuracy: 0.4329 - val_loss: 2.2047 - val_accuracy: 0.2433\n",
      "Epoch 784/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4181 - accuracy: 0.4300 - val_loss: 2.2132 - val_accuracy: 0.2400\n",
      "Epoch 785/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4179 - accuracy: 0.4271 - val_loss: 2.2198 - val_accuracy: 0.2367\n",
      "Epoch 786/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4180 - accuracy: 0.4271 - val_loss: 2.1994 - val_accuracy: 0.2467\n",
      "Epoch 787/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4184 - accuracy: 0.4243 - val_loss: 2.1838 - val_accuracy: 0.2500\n",
      "Epoch 788/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4178 - accuracy: 0.4271 - val_loss: 2.1991 - val_accuracy: 0.2400\n",
      "Epoch 789/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4173 - accuracy: 0.4229 - val_loss: 2.1994 - val_accuracy: 0.2400\n",
      "Epoch 790/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4174 - accuracy: 0.4314 - val_loss: 2.2033 - val_accuracy: 0.2400\n",
      "Epoch 791/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4164 - accuracy: 0.4286 - val_loss: 2.2056 - val_accuracy: 0.2500\n",
      "Epoch 792/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4171 - accuracy: 0.4229 - val_loss: 2.1936 - val_accuracy: 0.2367\n",
      "Epoch 793/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4166 - accuracy: 0.4257 - val_loss: 2.2141 - val_accuracy: 0.2500\n",
      "Epoch 794/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4169 - accuracy: 0.4271 - val_loss: 2.2061 - val_accuracy: 0.2367\n",
      "Epoch 795/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4164 - accuracy: 0.4314 - val_loss: 2.2030 - val_accuracy: 0.2400\n",
      "Epoch 796/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4160 - accuracy: 0.4300 - val_loss: 2.2047 - val_accuracy: 0.2367\n",
      "Epoch 797/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4164 - accuracy: 0.4200 - val_loss: 2.2128 - val_accuracy: 0.2367\n",
      "Epoch 798/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4162 - accuracy: 0.4386 - val_loss: 2.2137 - val_accuracy: 0.2400\n",
      "Epoch 799/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4152 - accuracy: 0.4329 - val_loss: 2.2049 - val_accuracy: 0.2567\n",
      "Epoch 800/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4159 - accuracy: 0.4200 - val_loss: 2.2158 - val_accuracy: 0.2333\n",
      "Epoch 801/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4159 - accuracy: 0.4329 - val_loss: 2.2122 - val_accuracy: 0.2333\n",
      "Epoch 802/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4158 - accuracy: 0.4329 - val_loss: 2.2595 - val_accuracy: 0.2400\n",
      "Epoch 803/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4146 - accuracy: 0.4271 - val_loss: 2.2121 - val_accuracy: 0.2600\n",
      "Epoch 804/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4148 - accuracy: 0.4243 - val_loss: 2.2039 - val_accuracy: 0.2433\n",
      "Epoch 805/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4143 - accuracy: 0.4329 - val_loss: 2.2054 - val_accuracy: 0.2467\n",
      "Epoch 806/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4148 - accuracy: 0.4357 - val_loss: 2.2052 - val_accuracy: 0.2400\n",
      "Epoch 807/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4148 - accuracy: 0.4386 - val_loss: 2.2125 - val_accuracy: 0.2500\n",
      "Epoch 808/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4143 - accuracy: 0.4314 - val_loss: 2.2125 - val_accuracy: 0.2400\n",
      "Epoch 809/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4150 - accuracy: 0.4229 - val_loss: 2.2137 - val_accuracy: 0.2467\n",
      "Epoch 810/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4139 - accuracy: 0.4357 - val_loss: 2.2157 - val_accuracy: 0.2367\n",
      "Epoch 811/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4142 - accuracy: 0.4314 - val_loss: 2.2169 - val_accuracy: 0.2400\n",
      "Epoch 812/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4141 - accuracy: 0.4271 - val_loss: 2.2032 - val_accuracy: 0.2400\n",
      "Epoch 813/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4139 - accuracy: 0.4329 - val_loss: 2.2245 - val_accuracy: 0.2400\n",
      "Epoch 814/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4131 - accuracy: 0.4286 - val_loss: 2.2157 - val_accuracy: 0.2533\n",
      "Epoch 815/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4139 - accuracy: 0.4314 - val_loss: 2.2224 - val_accuracy: 0.2467\n",
      "Epoch 816/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4136 - accuracy: 0.4300 - val_loss: 2.2146 - val_accuracy: 0.2367\n",
      "Epoch 817/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4116 - accuracy: 0.4300 - val_loss: 2.2146 - val_accuracy: 0.2367\n",
      "Epoch 818/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4123 - accuracy: 0.4286 - val_loss: 2.2243 - val_accuracy: 0.2367\n",
      "Epoch 819/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4110 - accuracy: 0.4357 - val_loss: 2.2386 - val_accuracy: 0.2600\n",
      "Epoch 820/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4131 - accuracy: 0.4329 - val_loss: 2.2190 - val_accuracy: 0.2567\n",
      "Epoch 821/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4129 - accuracy: 0.4300 - val_loss: 2.2348 - val_accuracy: 0.2467\n",
      "Epoch 822/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4130 - accuracy: 0.4329 - val_loss: 2.2198 - val_accuracy: 0.2367\n",
      "Epoch 823/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4114 - accuracy: 0.4271 - val_loss: 2.2264 - val_accuracy: 0.2433\n",
      "Epoch 824/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4110 - accuracy: 0.4300 - val_loss: 2.2265 - val_accuracy: 0.2433\n",
      "Epoch 825/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4112 - accuracy: 0.4314 - val_loss: 2.2452 - val_accuracy: 0.2467\n",
      "Epoch 826/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4122 - accuracy: 0.4271 - val_loss: 2.2332 - val_accuracy: 0.2467\n",
      "Epoch 827/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4112 - accuracy: 0.4300 - val_loss: 2.2318 - val_accuracy: 0.2400\n",
      "Epoch 828/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4118 - accuracy: 0.4343 - val_loss: 2.2184 - val_accuracy: 0.2367\n",
      "Epoch 829/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4111 - accuracy: 0.4314 - val_loss: 2.2233 - val_accuracy: 0.2433\n",
      "Epoch 830/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4104 - accuracy: 0.4271 - val_loss: 2.2284 - val_accuracy: 0.2400\n",
      "Epoch 831/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4105 - accuracy: 0.4443 - val_loss: 2.2469 - val_accuracy: 0.2467\n",
      "Epoch 832/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4111 - accuracy: 0.4343 - val_loss: 2.2477 - val_accuracy: 0.2500\n",
      "Epoch 833/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4110 - accuracy: 0.4243 - val_loss: 2.2534 - val_accuracy: 0.2467\n",
      "Epoch 834/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 1.4106 - accuracy: 0.4329 - val_loss: 2.2659 - val_accuracy: 0.2433\n",
      "Epoch 835/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4095 - accuracy: 0.4300 - val_loss: 2.2260 - val_accuracy: 0.2367\n",
      "Epoch 836/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4098 - accuracy: 0.4271 - val_loss: 2.2383 - val_accuracy: 0.2500\n",
      "Epoch 837/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4102 - accuracy: 0.4300 - val_loss: 2.2211 - val_accuracy: 0.2433\n",
      "Epoch 838/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4107 - accuracy: 0.4329 - val_loss: 2.2368 - val_accuracy: 0.2367\n",
      "Epoch 839/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4088 - accuracy: 0.4300 - val_loss: 2.2353 - val_accuracy: 0.2367\n",
      "Epoch 840/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4081 - accuracy: 0.4343 - val_loss: 2.2224 - val_accuracy: 0.2433\n",
      "Epoch 841/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4092 - accuracy: 0.4371 - val_loss: 2.2331 - val_accuracy: 0.2367\n",
      "Epoch 842/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4098 - accuracy: 0.4271 - val_loss: 2.2487 - val_accuracy: 0.2500\n",
      "Epoch 843/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4090 - accuracy: 0.4314 - val_loss: 2.2326 - val_accuracy: 0.2367\n",
      "Epoch 844/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4082 - accuracy: 0.4300 - val_loss: 2.2510 - val_accuracy: 0.2367\n",
      "Epoch 845/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4088 - accuracy: 0.4314 - val_loss: 2.2242 - val_accuracy: 0.2367\n",
      "Epoch 846/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4092 - accuracy: 0.4357 - val_loss: 2.2349 - val_accuracy: 0.2400\n",
      "Epoch 847/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4075 - accuracy: 0.4229 - val_loss: 2.2487 - val_accuracy: 0.2433\n",
      "Epoch 848/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4079 - accuracy: 0.4371 - val_loss: 2.2414 - val_accuracy: 0.2533\n",
      "Epoch 849/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4086 - accuracy: 0.4300 - val_loss: 2.2446 - val_accuracy: 0.2433\n",
      "Epoch 850/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4071 - accuracy: 0.4314 - val_loss: 2.2355 - val_accuracy: 0.2367\n",
      "Epoch 851/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4071 - accuracy: 0.4229 - val_loss: 2.2345 - val_accuracy: 0.2333\n",
      "Epoch 852/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4086 - accuracy: 0.4371 - val_loss: 2.2389 - val_accuracy: 0.2433\n",
      "Epoch 853/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4066 - accuracy: 0.4329 - val_loss: 2.2368 - val_accuracy: 0.2367\n",
      "Epoch 854/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4046 - accuracy: 0.4371 - val_loss: 2.2682 - val_accuracy: 0.2600\n",
      "Epoch 855/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4074 - accuracy: 0.4271 - val_loss: 2.2383 - val_accuracy: 0.2333\n",
      "Epoch 856/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4074 - accuracy: 0.4357 - val_loss: 2.2498 - val_accuracy: 0.2500\n",
      "Epoch 857/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4067 - accuracy: 0.4286 - val_loss: 2.2486 - val_accuracy: 0.2467\n",
      "Epoch 858/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4066 - accuracy: 0.4343 - val_loss: 2.2459 - val_accuracy: 0.2367\n",
      "Epoch 859/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4052 - accuracy: 0.4357 - val_loss: 2.2438 - val_accuracy: 0.2367\n",
      "Epoch 860/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4057 - accuracy: 0.4357 - val_loss: 2.2736 - val_accuracy: 0.2533\n",
      "Epoch 861/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4064 - accuracy: 0.4343 - val_loss: 2.2575 - val_accuracy: 0.2433\n",
      "Epoch 862/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4071 - accuracy: 0.4271 - val_loss: 2.2603 - val_accuracy: 0.2533\n",
      "Epoch 863/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4055 - accuracy: 0.4329 - val_loss: 2.2607 - val_accuracy: 0.2500\n",
      "Epoch 864/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4053 - accuracy: 0.4329 - val_loss: 2.2554 - val_accuracy: 0.2533\n",
      "Epoch 865/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4047 - accuracy: 0.4386 - val_loss: 2.2618 - val_accuracy: 0.2633\n",
      "Epoch 866/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4049 - accuracy: 0.4314 - val_loss: 2.2232 - val_accuracy: 0.2433\n",
      "Epoch 867/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4052 - accuracy: 0.4357 - val_loss: 2.2613 - val_accuracy: 0.2433\n",
      "Epoch 868/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4054 - accuracy: 0.4357 - val_loss: 2.2531 - val_accuracy: 0.2467\n",
      "Epoch 869/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4050 - accuracy: 0.4386 - val_loss: 2.2509 - val_accuracy: 0.2400\n",
      "Epoch 870/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4034 - accuracy: 0.4357 - val_loss: 2.2675 - val_accuracy: 0.2467\n",
      "Epoch 871/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4048 - accuracy: 0.4314 - val_loss: 2.2729 - val_accuracy: 0.2467\n",
      "Epoch 872/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4037 - accuracy: 0.4357 - val_loss: 2.2533 - val_accuracy: 0.2567\n",
      "Epoch 873/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4042 - accuracy: 0.4343 - val_loss: 2.2292 - val_accuracy: 0.2367\n",
      "Epoch 874/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4048 - accuracy: 0.4329 - val_loss: 2.2420 - val_accuracy: 0.2367\n",
      "Epoch 875/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4038 - accuracy: 0.4329 - val_loss: 2.2705 - val_accuracy: 0.2467\n",
      "Epoch 876/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4035 - accuracy: 0.4314 - val_loss: 2.2423 - val_accuracy: 0.2433\n",
      "Epoch 877/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4037 - accuracy: 0.4271 - val_loss: 2.2683 - val_accuracy: 0.2367\n",
      "Epoch 878/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4042 - accuracy: 0.4343 - val_loss: 2.2634 - val_accuracy: 0.2400\n",
      "Epoch 879/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4012 - accuracy: 0.4371 - val_loss: 2.2625 - val_accuracy: 0.2400\n",
      "Epoch 880/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4051 - accuracy: 0.4329 - val_loss: 2.2507 - val_accuracy: 0.2400\n",
      "Epoch 881/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4035 - accuracy: 0.4429 - val_loss: 2.2849 - val_accuracy: 0.2500\n",
      "Epoch 882/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4035 - accuracy: 0.4371 - val_loss: 2.2680 - val_accuracy: 0.2400\n",
      "Epoch 883/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4044 - accuracy: 0.4286 - val_loss: 2.2364 - val_accuracy: 0.2400\n",
      "Epoch 884/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4027 - accuracy: 0.4314 - val_loss: 2.2784 - val_accuracy: 0.2533\n",
      "Epoch 885/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4031 - accuracy: 0.4314 - val_loss: 2.2322 - val_accuracy: 0.2433\n",
      "Epoch 886/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4036 - accuracy: 0.4386 - val_loss: 2.2614 - val_accuracy: 0.2467\n",
      "Epoch 887/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4026 - accuracy: 0.4371 - val_loss: 2.2456 - val_accuracy: 0.2367\n",
      "Epoch 888/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4027 - accuracy: 0.4357 - val_loss: 2.2595 - val_accuracy: 0.2400\n",
      "Epoch 889/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4010 - accuracy: 0.4443 - val_loss: 2.2736 - val_accuracy: 0.2600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 890/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4028 - accuracy: 0.4386 - val_loss: 2.2630 - val_accuracy: 0.2567\n",
      "Epoch 891/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4024 - accuracy: 0.4271 - val_loss: 2.2669 - val_accuracy: 0.2433\n",
      "Epoch 892/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4024 - accuracy: 0.4357 - val_loss: 2.2699 - val_accuracy: 0.2433\n",
      "Epoch 893/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4018 - accuracy: 0.4357 - val_loss: 2.2777 - val_accuracy: 0.2433\n",
      "Epoch 894/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4020 - accuracy: 0.4429 - val_loss: 2.2620 - val_accuracy: 0.2400\n",
      "Epoch 895/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4012 - accuracy: 0.4343 - val_loss: 2.2655 - val_accuracy: 0.2467\n",
      "Epoch 896/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4014 - accuracy: 0.4357 - val_loss: 2.2715 - val_accuracy: 0.2600\n",
      "Epoch 897/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4017 - accuracy: 0.4343 - val_loss: 2.2648 - val_accuracy: 0.2533\n",
      "Epoch 898/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4011 - accuracy: 0.4386 - val_loss: 2.2896 - val_accuracy: 0.2467\n",
      "Epoch 899/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4015 - accuracy: 0.4343 - val_loss: 2.2583 - val_accuracy: 0.2467\n",
      "Epoch 900/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4001 - accuracy: 0.4471 - val_loss: 2.2617 - val_accuracy: 0.2467\n",
      "Epoch 901/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3999 - accuracy: 0.4400 - val_loss: 2.2772 - val_accuracy: 0.2533\n",
      "Epoch 902/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4001 - accuracy: 0.4343 - val_loss: 2.2689 - val_accuracy: 0.2467\n",
      "Epoch 903/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3992 - accuracy: 0.4414 - val_loss: 2.2865 - val_accuracy: 0.2633\n",
      "Epoch 904/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3991 - accuracy: 0.4357 - val_loss: 2.2582 - val_accuracy: 0.2400\n",
      "Epoch 905/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4010 - accuracy: 0.4400 - val_loss: 2.2543 - val_accuracy: 0.2400\n",
      "Epoch 906/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3998 - accuracy: 0.4371 - val_loss: 2.2494 - val_accuracy: 0.2367\n",
      "Epoch 907/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4003 - accuracy: 0.4386 - val_loss: 2.2830 - val_accuracy: 0.2467\n",
      "Epoch 908/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3997 - accuracy: 0.4414 - val_loss: 2.2715 - val_accuracy: 0.2433\n",
      "Epoch 909/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3993 - accuracy: 0.4329 - val_loss: 2.2790 - val_accuracy: 0.2500\n",
      "Epoch 910/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4004 - accuracy: 0.4357 - val_loss: 2.2561 - val_accuracy: 0.2400\n",
      "Epoch 911/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3991 - accuracy: 0.4371 - val_loss: 2.2786 - val_accuracy: 0.2367\n",
      "Epoch 912/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3995 - accuracy: 0.4400 - val_loss: 2.2665 - val_accuracy: 0.2367\n",
      "Epoch 913/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4000 - accuracy: 0.4371 - val_loss: 2.2924 - val_accuracy: 0.2433\n",
      "Epoch 914/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3988 - accuracy: 0.4386 - val_loss: 2.2909 - val_accuracy: 0.2567\n",
      "Epoch 915/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3990 - accuracy: 0.4343 - val_loss: 2.2737 - val_accuracy: 0.2467\n",
      "Epoch 916/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3987 - accuracy: 0.4386 - val_loss: 2.2810 - val_accuracy: 0.2400\n",
      "Epoch 917/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3978 - accuracy: 0.4400 - val_loss: 2.2807 - val_accuracy: 0.2400\n",
      "Epoch 918/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3970 - accuracy: 0.4386 - val_loss: 2.2802 - val_accuracy: 0.2533\n",
      "Epoch 919/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3984 - accuracy: 0.4329 - val_loss: 2.2901 - val_accuracy: 0.2433\n",
      "Epoch 920/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3988 - accuracy: 0.4343 - val_loss: 2.2681 - val_accuracy: 0.2500\n",
      "Epoch 921/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3984 - accuracy: 0.4357 - val_loss: 2.2706 - val_accuracy: 0.2400\n",
      "Epoch 922/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3967 - accuracy: 0.4400 - val_loss: 2.2872 - val_accuracy: 0.2500\n",
      "Epoch 923/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3966 - accuracy: 0.4386 - val_loss: 2.2698 - val_accuracy: 0.2567\n",
      "Epoch 924/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3988 - accuracy: 0.4414 - val_loss: 2.2782 - val_accuracy: 0.2467\n",
      "Epoch 925/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3970 - accuracy: 0.4343 - val_loss: 2.2855 - val_accuracy: 0.2367\n",
      "Epoch 926/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3972 - accuracy: 0.4443 - val_loss: 2.2793 - val_accuracy: 0.2467\n",
      "Epoch 927/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3975 - accuracy: 0.4357 - val_loss: 2.2798 - val_accuracy: 0.2400\n",
      "Epoch 928/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3971 - accuracy: 0.4400 - val_loss: 2.3013 - val_accuracy: 0.2433\n",
      "Epoch 929/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3971 - accuracy: 0.4414 - val_loss: 2.2997 - val_accuracy: 0.2400\n",
      "Epoch 930/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3971 - accuracy: 0.4357 - val_loss: 2.2816 - val_accuracy: 0.2467\n",
      "Epoch 931/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3967 - accuracy: 0.4329 - val_loss: 2.2836 - val_accuracy: 0.2467\n",
      "Epoch 932/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3962 - accuracy: 0.4400 - val_loss: 2.2720 - val_accuracy: 0.2500\n",
      "Epoch 933/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3966 - accuracy: 0.4314 - val_loss: 2.2861 - val_accuracy: 0.2467\n",
      "Epoch 934/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3958 - accuracy: 0.4414 - val_loss: 2.2939 - val_accuracy: 0.2500\n",
      "Epoch 935/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3966 - accuracy: 0.4414 - val_loss: 2.2901 - val_accuracy: 0.2500\n",
      "Epoch 936/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3965 - accuracy: 0.4429 - val_loss: 2.2962 - val_accuracy: 0.2500\n",
      "Epoch 937/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3960 - accuracy: 0.4400 - val_loss: 2.2877 - val_accuracy: 0.2367\n",
      "Epoch 938/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3953 - accuracy: 0.4443 - val_loss: 2.2991 - val_accuracy: 0.2500\n",
      "Epoch 939/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3953 - accuracy: 0.4386 - val_loss: 2.3114 - val_accuracy: 0.2500\n",
      "Epoch 940/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3960 - accuracy: 0.4343 - val_loss: 2.2826 - val_accuracy: 0.2400\n",
      "Epoch 941/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3957 - accuracy: 0.4343 - val_loss: 2.2917 - val_accuracy: 0.2400\n",
      "Epoch 942/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3947 - accuracy: 0.4357 - val_loss: 2.2695 - val_accuracy: 0.2333\n",
      "Epoch 943/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3955 - accuracy: 0.4414 - val_loss: 2.3028 - val_accuracy: 0.2433\n",
      "Epoch 944/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3944 - accuracy: 0.4371 - val_loss: 2.3057 - val_accuracy: 0.2433\n",
      "Epoch 945/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 1.3947 - accuracy: 0.4329 - val_loss: 2.3010 - val_accuracy: 0.2500\n",
      "Epoch 946/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3945 - accuracy: 0.4329 - val_loss: 2.2912 - val_accuracy: 0.2467\n",
      "Epoch 947/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3939 - accuracy: 0.4414 - val_loss: 2.3067 - val_accuracy: 0.2533\n",
      "Epoch 948/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3940 - accuracy: 0.4300 - val_loss: 2.2777 - val_accuracy: 0.2367\n",
      "Epoch 949/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3938 - accuracy: 0.4471 - val_loss: 2.2906 - val_accuracy: 0.2400\n",
      "Epoch 950/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3929 - accuracy: 0.4386 - val_loss: 2.2916 - val_accuracy: 0.2367\n",
      "Epoch 951/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3940 - accuracy: 0.4429 - val_loss: 2.3014 - val_accuracy: 0.2500\n",
      "Epoch 952/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3938 - accuracy: 0.4414 - val_loss: 2.2949 - val_accuracy: 0.2467\n",
      "Epoch 953/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3935 - accuracy: 0.4371 - val_loss: 2.3148 - val_accuracy: 0.2533\n",
      "Epoch 954/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3940 - accuracy: 0.4471 - val_loss: 2.2962 - val_accuracy: 0.2567\n",
      "Epoch 955/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3936 - accuracy: 0.4429 - val_loss: 2.3098 - val_accuracy: 0.2500\n",
      "Epoch 956/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3928 - accuracy: 0.4386 - val_loss: 2.3181 - val_accuracy: 0.2433\n",
      "Epoch 957/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3925 - accuracy: 0.4414 - val_loss: 2.2925 - val_accuracy: 0.2433\n",
      "Epoch 958/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3938 - accuracy: 0.4343 - val_loss: 2.3365 - val_accuracy: 0.2467\n",
      "Epoch 959/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3936 - accuracy: 0.4414 - val_loss: 2.2892 - val_accuracy: 0.2467\n",
      "Epoch 960/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3930 - accuracy: 0.4400 - val_loss: 2.3049 - val_accuracy: 0.2467\n",
      "Epoch 961/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3923 - accuracy: 0.4429 - val_loss: 2.2714 - val_accuracy: 0.2467\n",
      "Epoch 962/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3931 - accuracy: 0.4400 - val_loss: 2.3025 - val_accuracy: 0.2467\n",
      "Epoch 963/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3926 - accuracy: 0.4386 - val_loss: 2.2963 - val_accuracy: 0.2500\n",
      "Epoch 964/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3919 - accuracy: 0.4357 - val_loss: 2.2856 - val_accuracy: 0.2433\n",
      "Epoch 965/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3913 - accuracy: 0.4414 - val_loss: 2.2959 - val_accuracy: 0.2533\n",
      "Epoch 966/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3924 - accuracy: 0.4429 - val_loss: 2.3148 - val_accuracy: 0.2567\n",
      "Epoch 967/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3923 - accuracy: 0.4429 - val_loss: 2.3105 - val_accuracy: 0.2467\n",
      "Epoch 968/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3913 - accuracy: 0.4400 - val_loss: 2.2989 - val_accuracy: 0.2433\n",
      "Epoch 969/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3917 - accuracy: 0.4414 - val_loss: 2.3052 - val_accuracy: 0.2433\n",
      "Epoch 970/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3916 - accuracy: 0.4400 - val_loss: 2.3201 - val_accuracy: 0.2400\n",
      "Epoch 971/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3916 - accuracy: 0.4414 - val_loss: 2.3001 - val_accuracy: 0.2467\n",
      "Epoch 972/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3913 - accuracy: 0.4386 - val_loss: 2.3213 - val_accuracy: 0.2333\n",
      "Epoch 973/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3901 - accuracy: 0.4400 - val_loss: 2.3114 - val_accuracy: 0.2500\n",
      "Epoch 974/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3908 - accuracy: 0.4386 - val_loss: 2.3123 - val_accuracy: 0.2500\n",
      "Epoch 975/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3907 - accuracy: 0.4443 - val_loss: 2.3262 - val_accuracy: 0.2500\n",
      "Epoch 976/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3905 - accuracy: 0.4429 - val_loss: 2.3076 - val_accuracy: 0.2500\n",
      "Epoch 977/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3905 - accuracy: 0.4343 - val_loss: 2.3044 - val_accuracy: 0.2400\n",
      "Epoch 978/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3904 - accuracy: 0.4486 - val_loss: 2.3117 - val_accuracy: 0.2533\n",
      "Epoch 979/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3906 - accuracy: 0.4429 - val_loss: 2.3081 - val_accuracy: 0.2467\n",
      "Epoch 980/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3906 - accuracy: 0.4429 - val_loss: 2.3256 - val_accuracy: 0.2500\n",
      "Epoch 981/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3894 - accuracy: 0.4371 - val_loss: 2.3378 - val_accuracy: 0.2500\n",
      "Epoch 982/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3902 - accuracy: 0.4400 - val_loss: 2.3157 - val_accuracy: 0.2533\n",
      "Epoch 983/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3897 - accuracy: 0.4357 - val_loss: 2.3231 - val_accuracy: 0.2500\n",
      "Epoch 984/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3898 - accuracy: 0.4414 - val_loss: 2.3133 - val_accuracy: 0.2500\n",
      "Epoch 985/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3891 - accuracy: 0.4400 - val_loss: 2.3245 - val_accuracy: 0.2367\n",
      "Epoch 986/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3891 - accuracy: 0.4414 - val_loss: 2.3228 - val_accuracy: 0.2500\n",
      "Epoch 987/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3887 - accuracy: 0.4414 - val_loss: 2.3043 - val_accuracy: 0.2400\n",
      "Epoch 988/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3886 - accuracy: 0.4429 - val_loss: 2.3385 - val_accuracy: 0.2633\n",
      "Epoch 989/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3903 - accuracy: 0.4357 - val_loss: 2.3375 - val_accuracy: 0.2533\n",
      "Epoch 990/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3887 - accuracy: 0.4443 - val_loss: 2.3547 - val_accuracy: 0.2533\n",
      "Epoch 991/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3890 - accuracy: 0.4471 - val_loss: 2.3138 - val_accuracy: 0.2433\n",
      "Epoch 992/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3888 - accuracy: 0.4371 - val_loss: 2.3301 - val_accuracy: 0.2400\n",
      "Epoch 993/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3885 - accuracy: 0.4457 - val_loss: 2.3353 - val_accuracy: 0.2533\n",
      "Epoch 994/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3885 - accuracy: 0.4357 - val_loss: 2.3073 - val_accuracy: 0.2367\n",
      "Epoch 995/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3890 - accuracy: 0.4429 - val_loss: 2.3282 - val_accuracy: 0.2500\n",
      "Epoch 996/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3877 - accuracy: 0.4457 - val_loss: 2.3284 - val_accuracy: 0.2467\n",
      "Epoch 997/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3879 - accuracy: 0.4429 - val_loss: 2.3277 - val_accuracy: 0.2533\n",
      "Epoch 998/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3887 - accuracy: 0.4386 - val_loss: 2.3401 - val_accuracy: 0.2533\n",
      "Epoch 999/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3881 - accuracy: 0.4386 - val_loss: 2.3246 - val_accuracy: 0.2500\n",
      "Epoch 1000/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 105us/step - loss: 1.3879 - accuracy: 0.4386 - val_loss: 2.3363 - val_accuracy: 0.2500\n",
      "Epoch 1001/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3864 - accuracy: 0.4457 - val_loss: 2.3322 - val_accuracy: 0.2600\n",
      "Epoch 1002/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3883 - accuracy: 0.4371 - val_loss: 2.3279 - val_accuracy: 0.2500\n",
      "Epoch 1003/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3865 - accuracy: 0.4457 - val_loss: 2.3385 - val_accuracy: 0.2567\n",
      "Epoch 1004/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3885 - accuracy: 0.4414 - val_loss: 2.3496 - val_accuracy: 0.2500\n",
      "Epoch 1005/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3874 - accuracy: 0.4386 - val_loss: 2.3295 - val_accuracy: 0.2467\n",
      "Epoch 1006/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3869 - accuracy: 0.4371 - val_loss: 2.3564 - val_accuracy: 0.2500\n",
      "Epoch 1007/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3865 - accuracy: 0.4414 - val_loss: 2.3466 - val_accuracy: 0.2567\n",
      "Epoch 1008/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3868 - accuracy: 0.4386 - val_loss: 2.3211 - val_accuracy: 0.2500\n",
      "Epoch 1009/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3864 - accuracy: 0.4457 - val_loss: 2.3559 - val_accuracy: 0.2533\n",
      "Epoch 1010/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3865 - accuracy: 0.4486 - val_loss: 2.3248 - val_accuracy: 0.2500\n",
      "Epoch 1011/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3859 - accuracy: 0.4414 - val_loss: 2.3421 - val_accuracy: 0.2533\n",
      "Epoch 1012/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3852 - accuracy: 0.4414 - val_loss: 2.3446 - val_accuracy: 0.2533\n",
      "Epoch 1013/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3852 - accuracy: 0.4457 - val_loss: 2.3257 - val_accuracy: 0.2400\n",
      "Epoch 1014/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3853 - accuracy: 0.4414 - val_loss: 2.3256 - val_accuracy: 0.2567\n",
      "Epoch 1015/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3842 - accuracy: 0.4457 - val_loss: 2.3319 - val_accuracy: 0.2400\n",
      "Epoch 1016/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3867 - accuracy: 0.4414 - val_loss: 2.3376 - val_accuracy: 0.2500\n",
      "Epoch 1017/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3863 - accuracy: 0.4357 - val_loss: 2.3347 - val_accuracy: 0.2500\n",
      "Epoch 1018/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3861 - accuracy: 0.4486 - val_loss: 2.3471 - val_accuracy: 0.2500\n",
      "Epoch 1019/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3851 - accuracy: 0.4386 - val_loss: 2.3314 - val_accuracy: 0.2467\n",
      "Epoch 1020/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3845 - accuracy: 0.4529 - val_loss: 2.3294 - val_accuracy: 0.2500\n",
      "Epoch 1021/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3853 - accuracy: 0.4429 - val_loss: 2.3389 - val_accuracy: 0.2533\n",
      "Epoch 1022/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3842 - accuracy: 0.4514 - val_loss: 2.3396 - val_accuracy: 0.2400\n",
      "Epoch 1023/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3855 - accuracy: 0.4414 - val_loss: 2.3287 - val_accuracy: 0.2467\n",
      "Epoch 1024/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3850 - accuracy: 0.4529 - val_loss: 2.3287 - val_accuracy: 0.2433\n",
      "Epoch 1025/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3844 - accuracy: 0.4443 - val_loss: 2.3350 - val_accuracy: 0.2533\n",
      "Epoch 1026/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3848 - accuracy: 0.4457 - val_loss: 2.3112 - val_accuracy: 0.2433\n",
      "Epoch 1027/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3841 - accuracy: 0.4457 - val_loss: 2.3445 - val_accuracy: 0.2500\n",
      "Epoch 1028/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3842 - accuracy: 0.4386 - val_loss: 2.3323 - val_accuracy: 0.2433\n",
      "Epoch 1029/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3844 - accuracy: 0.4443 - val_loss: 2.3308 - val_accuracy: 0.2467\n",
      "Epoch 1030/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3835 - accuracy: 0.4500 - val_loss: 2.3470 - val_accuracy: 0.2500\n",
      "Epoch 1031/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3834 - accuracy: 0.4443 - val_loss: 2.3523 - val_accuracy: 0.2567\n",
      "Epoch 1032/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3846 - accuracy: 0.4443 - val_loss: 2.3494 - val_accuracy: 0.2433\n",
      "Epoch 1033/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3843 - accuracy: 0.4429 - val_loss: 2.3703 - val_accuracy: 0.2467\n",
      "Epoch 1034/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3822 - accuracy: 0.4443 - val_loss: 2.3406 - val_accuracy: 0.2333\n",
      "Epoch 1035/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3842 - accuracy: 0.4443 - val_loss: 2.3459 - val_accuracy: 0.2533\n",
      "Epoch 1036/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3837 - accuracy: 0.4486 - val_loss: 2.3452 - val_accuracy: 0.2500\n",
      "Epoch 1037/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3830 - accuracy: 0.4429 - val_loss: 2.3415 - val_accuracy: 0.2400\n",
      "Epoch 1038/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3838 - accuracy: 0.4443 - val_loss: 2.3751 - val_accuracy: 0.2567\n",
      "Epoch 1039/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3835 - accuracy: 0.4443 - val_loss: 2.3524 - val_accuracy: 0.2467\n",
      "Epoch 1040/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3832 - accuracy: 0.4414 - val_loss: 2.3506 - val_accuracy: 0.2467\n",
      "Epoch 1041/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3825 - accuracy: 0.4414 - val_loss: 2.3684 - val_accuracy: 0.2500\n",
      "Epoch 1042/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3814 - accuracy: 0.4400 - val_loss: 2.3343 - val_accuracy: 0.2467\n",
      "Epoch 1043/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3835 - accuracy: 0.4400 - val_loss: 2.3604 - val_accuracy: 0.2533\n",
      "Epoch 1044/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3825 - accuracy: 0.4429 - val_loss: 2.3520 - val_accuracy: 0.2467\n",
      "Epoch 1045/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3802 - accuracy: 0.4386 - val_loss: 2.3440 - val_accuracy: 0.2333\n",
      "Epoch 1046/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3831 - accuracy: 0.4514 - val_loss: 2.3538 - val_accuracy: 0.2433\n",
      "Epoch 1047/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3808 - accuracy: 0.4457 - val_loss: 2.3428 - val_accuracy: 0.2367\n",
      "Epoch 1048/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3824 - accuracy: 0.4400 - val_loss: 2.3375 - val_accuracy: 0.2433\n",
      "Epoch 1049/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3818 - accuracy: 0.4414 - val_loss: 2.3480 - val_accuracy: 0.2500\n",
      "Epoch 1050/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3808 - accuracy: 0.4471 - val_loss: 2.3605 - val_accuracy: 0.2433\n",
      "Epoch 1051/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3821 - accuracy: 0.4471 - val_loss: 2.3487 - val_accuracy: 0.2467\n",
      "Epoch 1052/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3810 - accuracy: 0.4357 - val_loss: 2.3688 - val_accuracy: 0.2433\n",
      "Epoch 1053/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3814 - accuracy: 0.4443 - val_loss: 2.3598 - val_accuracy: 0.2467\n",
      "Epoch 1054/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3808 - accuracy: 0.4486 - val_loss: 2.3476 - val_accuracy: 0.2500\n",
      "Epoch 1055/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 80us/step - loss: 1.3807 - accuracy: 0.4471 - val_loss: 2.3445 - val_accuracy: 0.2500\n",
      "Epoch 1056/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3805 - accuracy: 0.4400 - val_loss: 2.3697 - val_accuracy: 0.2500\n",
      "Epoch 1057/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3799 - accuracy: 0.4343 - val_loss: 2.3867 - val_accuracy: 0.2433\n",
      "Epoch 1058/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3813 - accuracy: 0.4414 - val_loss: 2.3657 - val_accuracy: 0.2533\n",
      "Epoch 1059/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3797 - accuracy: 0.4486 - val_loss: 2.3663 - val_accuracy: 0.2500\n",
      "Epoch 1060/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3802 - accuracy: 0.4443 - val_loss: 2.3557 - val_accuracy: 0.2500\n",
      "Epoch 1061/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3807 - accuracy: 0.4457 - val_loss: 2.3787 - val_accuracy: 0.2533\n",
      "Epoch 1062/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3811 - accuracy: 0.4386 - val_loss: 2.3482 - val_accuracy: 0.2500\n",
      "Epoch 1063/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3797 - accuracy: 0.4429 - val_loss: 2.3524 - val_accuracy: 0.2533\n",
      "Epoch 1064/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3799 - accuracy: 0.4429 - val_loss: 2.3675 - val_accuracy: 0.2500\n",
      "Epoch 1065/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3800 - accuracy: 0.4400 - val_loss: 2.3518 - val_accuracy: 0.2467\n",
      "Epoch 1066/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3800 - accuracy: 0.4429 - val_loss: 2.3537 - val_accuracy: 0.2400\n",
      "Epoch 1067/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3799 - accuracy: 0.4514 - val_loss: 2.3866 - val_accuracy: 0.2567\n",
      "Epoch 1068/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3793 - accuracy: 0.4443 - val_loss: 2.3872 - val_accuracy: 0.2500\n",
      "Epoch 1069/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3795 - accuracy: 0.4414 - val_loss: 2.3765 - val_accuracy: 0.2500\n",
      "Epoch 1070/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3789 - accuracy: 0.4471 - val_loss: 2.3595 - val_accuracy: 0.2367\n",
      "Epoch 1071/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3783 - accuracy: 0.4457 - val_loss: 2.3945 - val_accuracy: 0.2267\n",
      "Epoch 1072/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3789 - accuracy: 0.4514 - val_loss: 2.3712 - val_accuracy: 0.2533\n",
      "Epoch 1073/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3784 - accuracy: 0.4443 - val_loss: 2.3571 - val_accuracy: 0.2500\n",
      "Epoch 1074/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3788 - accuracy: 0.4514 - val_loss: 2.3474 - val_accuracy: 0.2500\n",
      "Epoch 1075/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3787 - accuracy: 0.4500 - val_loss: 2.3609 - val_accuracy: 0.2367\n",
      "Epoch 1076/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3789 - accuracy: 0.4429 - val_loss: 2.3611 - val_accuracy: 0.2500\n",
      "Epoch 1077/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3785 - accuracy: 0.4457 - val_loss: 2.3490 - val_accuracy: 0.2367\n",
      "Epoch 1078/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3785 - accuracy: 0.4443 - val_loss: 2.3810 - val_accuracy: 0.2400\n",
      "Epoch 1079/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3779 - accuracy: 0.4443 - val_loss: 2.3704 - val_accuracy: 0.2400\n",
      "Epoch 1080/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3780 - accuracy: 0.4414 - val_loss: 2.3673 - val_accuracy: 0.2533\n",
      "Epoch 1081/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3782 - accuracy: 0.4471 - val_loss: 2.3719 - val_accuracy: 0.2400\n",
      "Epoch 1082/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3770 - accuracy: 0.4471 - val_loss: 2.3847 - val_accuracy: 0.2533\n",
      "Epoch 1083/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3782 - accuracy: 0.4429 - val_loss: 2.3637 - val_accuracy: 0.2333\n",
      "Epoch 1084/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3784 - accuracy: 0.4471 - val_loss: 2.3890 - val_accuracy: 0.2433\n",
      "Epoch 1085/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3771 - accuracy: 0.4414 - val_loss: 2.3778 - val_accuracy: 0.2533\n",
      "Epoch 1086/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3776 - accuracy: 0.4471 - val_loss: 2.3988 - val_accuracy: 0.2400\n",
      "Epoch 1087/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3771 - accuracy: 0.4486 - val_loss: 2.3753 - val_accuracy: 0.2333\n",
      "Epoch 1088/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3769 - accuracy: 0.4543 - val_loss: 2.3642 - val_accuracy: 0.2500\n",
      "Epoch 1089/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3781 - accuracy: 0.4457 - val_loss: 2.3738 - val_accuracy: 0.2500\n",
      "Epoch 1090/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3766 - accuracy: 0.4471 - val_loss: 2.3861 - val_accuracy: 0.2533\n",
      "Epoch 1091/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3766 - accuracy: 0.4486 - val_loss: 2.3700 - val_accuracy: 0.2400\n",
      "Epoch 1092/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3765 - accuracy: 0.4514 - val_loss: 2.3865 - val_accuracy: 0.2500\n",
      "Epoch 1093/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3769 - accuracy: 0.4457 - val_loss: 2.3861 - val_accuracy: 0.2467\n",
      "Epoch 1094/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3753 - accuracy: 0.4571 - val_loss: 2.3644 - val_accuracy: 0.2433\n",
      "Epoch 1095/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3779 - accuracy: 0.4429 - val_loss: 2.3857 - val_accuracy: 0.2533\n",
      "Epoch 1096/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3761 - accuracy: 0.4429 - val_loss: 2.3808 - val_accuracy: 0.2367\n",
      "Epoch 1097/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3762 - accuracy: 0.4557 - val_loss: 2.3937 - val_accuracy: 0.2533\n",
      "Epoch 1098/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3767 - accuracy: 0.4457 - val_loss: 2.4162 - val_accuracy: 0.2500\n",
      "Epoch 1099/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3767 - accuracy: 0.4471 - val_loss: 2.4176 - val_accuracy: 0.2467\n",
      "Epoch 1100/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3761 - accuracy: 0.4500 - val_loss: 2.3906 - val_accuracy: 0.2467\n",
      "Epoch 1101/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3756 - accuracy: 0.4471 - val_loss: 2.3871 - val_accuracy: 0.2500\n",
      "Epoch 1102/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3750 - accuracy: 0.4400 - val_loss: 2.3934 - val_accuracy: 0.2367\n",
      "Epoch 1103/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3754 - accuracy: 0.4414 - val_loss: 2.4011 - val_accuracy: 0.2533\n",
      "Epoch 1104/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3758 - accuracy: 0.4414 - val_loss: 2.3780 - val_accuracy: 0.2533\n",
      "Epoch 1105/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3752 - accuracy: 0.4500 - val_loss: 2.3785 - val_accuracy: 0.2533\n",
      "Epoch 1106/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3748 - accuracy: 0.4500 - val_loss: 2.4023 - val_accuracy: 0.2533\n",
      "Epoch 1107/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3758 - accuracy: 0.4471 - val_loss: 2.3591 - val_accuracy: 0.2500\n",
      "Epoch 1108/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3755 - accuracy: 0.4471 - val_loss: 2.3990 - val_accuracy: 0.2467\n",
      "Epoch 1109/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3755 - accuracy: 0.4500 - val_loss: 2.4115 - val_accuracy: 0.2500\n",
      "Epoch 1110/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 1.3746 - accuracy: 0.4414 - val_loss: 2.3729 - val_accuracy: 0.2433\n",
      "Epoch 1111/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3742 - accuracy: 0.4543 - val_loss: 2.3964 - val_accuracy: 0.2500\n",
      "Epoch 1112/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3742 - accuracy: 0.4457 - val_loss: 2.4009 - val_accuracy: 0.2400\n",
      "Epoch 1113/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3738 - accuracy: 0.4486 - val_loss: 2.4031 - val_accuracy: 0.2533\n",
      "Epoch 1114/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3746 - accuracy: 0.4486 - val_loss: 2.3946 - val_accuracy: 0.2533\n",
      "Epoch 1115/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3756 - accuracy: 0.4457 - val_loss: 2.3857 - val_accuracy: 0.2533\n",
      "Epoch 1116/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3737 - accuracy: 0.4500 - val_loss: 2.4026 - val_accuracy: 0.2500\n",
      "Epoch 1117/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3737 - accuracy: 0.4529 - val_loss: 2.3940 - val_accuracy: 0.2467\n",
      "Epoch 1118/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3739 - accuracy: 0.4557 - val_loss: 2.3943 - val_accuracy: 0.2467\n",
      "Epoch 1119/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3732 - accuracy: 0.4386 - val_loss: 2.3894 - val_accuracy: 0.2333\n",
      "Epoch 1120/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3733 - accuracy: 0.4543 - val_loss: 2.4235 - val_accuracy: 0.2500\n",
      "Epoch 1121/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3744 - accuracy: 0.4471 - val_loss: 2.3780 - val_accuracy: 0.2433\n",
      "Epoch 1122/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3736 - accuracy: 0.4486 - val_loss: 2.4027 - val_accuracy: 0.2533\n",
      "Epoch 1123/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3730 - accuracy: 0.4514 - val_loss: 2.4025 - val_accuracy: 0.2467\n",
      "Epoch 1124/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3739 - accuracy: 0.4500 - val_loss: 2.3965 - val_accuracy: 0.2400\n",
      "Epoch 1125/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3735 - accuracy: 0.4471 - val_loss: 2.3919 - val_accuracy: 0.2533\n",
      "Epoch 1126/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3722 - accuracy: 0.4529 - val_loss: 2.3982 - val_accuracy: 0.2533\n",
      "Epoch 1127/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3730 - accuracy: 0.4586 - val_loss: 2.4060 - val_accuracy: 0.2533\n",
      "Epoch 1128/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3737 - accuracy: 0.4457 - val_loss: 2.4372 - val_accuracy: 0.2500\n",
      "Epoch 1129/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3720 - accuracy: 0.4457 - val_loss: 2.4131 - val_accuracy: 0.2333\n",
      "Epoch 1130/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3727 - accuracy: 0.4429 - val_loss: 2.4031 - val_accuracy: 0.2433\n",
      "Epoch 1131/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3709 - accuracy: 0.4457 - val_loss: 2.4240 - val_accuracy: 0.2533\n",
      "Epoch 1132/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3738 - accuracy: 0.4514 - val_loss: 2.4069 - val_accuracy: 0.2467\n",
      "Epoch 1133/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3715 - accuracy: 0.4514 - val_loss: 2.4214 - val_accuracy: 0.2467\n",
      "Epoch 1134/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3717 - accuracy: 0.4457 - val_loss: 2.4085 - val_accuracy: 0.2333\n",
      "Epoch 1135/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3726 - accuracy: 0.4514 - val_loss: 2.4087 - val_accuracy: 0.2467\n",
      "Epoch 1136/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3718 - accuracy: 0.4514 - val_loss: 2.3966 - val_accuracy: 0.2467\n",
      "Epoch 1137/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3726 - accuracy: 0.4500 - val_loss: 2.4056 - val_accuracy: 0.2467\n",
      "Epoch 1138/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3716 - accuracy: 0.4471 - val_loss: 2.4076 - val_accuracy: 0.2433\n",
      "Epoch 1139/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3717 - accuracy: 0.4557 - val_loss: 2.3976 - val_accuracy: 0.2467\n",
      "Epoch 1140/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3701 - accuracy: 0.4557 - val_loss: 2.3885 - val_accuracy: 0.2300\n",
      "Epoch 1141/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3715 - accuracy: 0.4500 - val_loss: 2.4364 - val_accuracy: 0.2500\n",
      "Epoch 1142/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3718 - accuracy: 0.4557 - val_loss: 2.4286 - val_accuracy: 0.2500\n",
      "Epoch 1143/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3707 - accuracy: 0.4457 - val_loss: 2.4246 - val_accuracy: 0.2433\n",
      "Epoch 1144/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3686 - accuracy: 0.4443 - val_loss: 2.4378 - val_accuracy: 0.2367\n",
      "Epoch 1145/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3718 - accuracy: 0.4529 - val_loss: 2.4172 - val_accuracy: 0.2467\n",
      "Epoch 1146/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3705 - accuracy: 0.4514 - val_loss: 2.4258 - val_accuracy: 0.2333\n",
      "Epoch 1147/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3702 - accuracy: 0.4529 - val_loss: 2.4031 - val_accuracy: 0.2333\n",
      "Epoch 1148/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3715 - accuracy: 0.4543 - val_loss: 2.4235 - val_accuracy: 0.2467\n",
      "Epoch 1149/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3712 - accuracy: 0.4457 - val_loss: 2.4239 - val_accuracy: 0.2367\n",
      "Epoch 1150/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3713 - accuracy: 0.4486 - val_loss: 2.3925 - val_accuracy: 0.2400\n",
      "Epoch 1151/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3712 - accuracy: 0.4514 - val_loss: 2.4041 - val_accuracy: 0.2433\n",
      "Epoch 1152/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3697 - accuracy: 0.4529 - val_loss: 2.4164 - val_accuracy: 0.2533\n",
      "Epoch 1153/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3711 - accuracy: 0.4471 - val_loss: 2.4291 - val_accuracy: 0.2467\n",
      "Epoch 1154/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3699 - accuracy: 0.4543 - val_loss: 2.3820 - val_accuracy: 0.2367\n",
      "Epoch 1155/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3697 - accuracy: 0.4514 - val_loss: 2.4190 - val_accuracy: 0.2433\n",
      "Epoch 1156/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3706 - accuracy: 0.4457 - val_loss: 2.4048 - val_accuracy: 0.2300\n",
      "Epoch 1157/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3707 - accuracy: 0.4529 - val_loss: 2.4173 - val_accuracy: 0.2433\n",
      "Epoch 1158/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3696 - accuracy: 0.4543 - val_loss: 2.4481 - val_accuracy: 0.2533\n",
      "Epoch 1159/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3697 - accuracy: 0.4457 - val_loss: 2.4223 - val_accuracy: 0.2433\n",
      "Epoch 1160/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3708 - accuracy: 0.4543 - val_loss: 2.4358 - val_accuracy: 0.2333\n",
      "Epoch 1161/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3693 - accuracy: 0.4571 - val_loss: 2.4256 - val_accuracy: 0.2467\n",
      "Epoch 1162/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3693 - accuracy: 0.4571 - val_loss: 2.4286 - val_accuracy: 0.2467\n",
      "Epoch 1163/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3691 - accuracy: 0.4543 - val_loss: 2.4364 - val_accuracy: 0.2467\n",
      "Epoch 1164/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3688 - accuracy: 0.4586 - val_loss: 2.4378 - val_accuracy: 0.2333\n",
      "Epoch 1165/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 1.3701 - accuracy: 0.4571 - val_loss: 2.3936 - val_accuracy: 0.2367\n",
      "Epoch 1166/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3689 - accuracy: 0.4543 - val_loss: 2.4123 - val_accuracy: 0.2433\n",
      "Epoch 1167/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3689 - accuracy: 0.4557 - val_loss: 2.4247 - val_accuracy: 0.2433\n",
      "Epoch 1168/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3688 - accuracy: 0.4529 - val_loss: 2.4140 - val_accuracy: 0.2333\n",
      "Epoch 1169/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3682 - accuracy: 0.4529 - val_loss: 2.4288 - val_accuracy: 0.2467\n",
      "Epoch 1170/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3682 - accuracy: 0.4514 - val_loss: 2.4249 - val_accuracy: 0.2467\n",
      "Epoch 1171/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3676 - accuracy: 0.4514 - val_loss: 2.4115 - val_accuracy: 0.2433\n",
      "Epoch 1172/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3681 - accuracy: 0.4529 - val_loss: 2.4387 - val_accuracy: 0.2433\n",
      "Epoch 1173/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3678 - accuracy: 0.4514 - val_loss: 2.4268 - val_accuracy: 0.2300\n",
      "Epoch 1174/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3688 - accuracy: 0.4471 - val_loss: 2.4151 - val_accuracy: 0.2433\n",
      "Epoch 1175/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3671 - accuracy: 0.4514 - val_loss: 2.4241 - val_accuracy: 0.2433\n",
      "Epoch 1176/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3680 - accuracy: 0.4500 - val_loss: 2.4368 - val_accuracy: 0.2433\n",
      "Epoch 1177/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3681 - accuracy: 0.4514 - val_loss: 2.4471 - val_accuracy: 0.2467\n",
      "Epoch 1178/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3675 - accuracy: 0.4500 - val_loss: 2.4336 - val_accuracy: 0.2267\n",
      "Epoch 1179/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3677 - accuracy: 0.4543 - val_loss: 2.4346 - val_accuracy: 0.2300\n",
      "Epoch 1180/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3678 - accuracy: 0.4514 - val_loss: 2.4402 - val_accuracy: 0.2400\n",
      "Epoch 1181/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3672 - accuracy: 0.4571 - val_loss: 2.4477 - val_accuracy: 0.2500\n",
      "Epoch 1182/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3679 - accuracy: 0.4557 - val_loss: 2.4301 - val_accuracy: 0.2400\n",
      "Epoch 1183/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3673 - accuracy: 0.4500 - val_loss: 2.4334 - val_accuracy: 0.2433\n",
      "Epoch 1184/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3663 - accuracy: 0.4586 - val_loss: 2.4227 - val_accuracy: 0.2467\n",
      "Epoch 1185/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3675 - accuracy: 0.4557 - val_loss: 2.4282 - val_accuracy: 0.2400\n",
      "Epoch 1186/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3671 - accuracy: 0.4471 - val_loss: 2.4531 - val_accuracy: 0.2467\n",
      "Epoch 1187/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3664 - accuracy: 0.4529 - val_loss: 2.4296 - val_accuracy: 0.2333\n",
      "Epoch 1188/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3665 - accuracy: 0.4543 - val_loss: 2.4561 - val_accuracy: 0.2467\n",
      "Epoch 1189/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3656 - accuracy: 0.4600 - val_loss: 2.4385 - val_accuracy: 0.2467\n",
      "Epoch 1190/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3665 - accuracy: 0.4500 - val_loss: 2.4635 - val_accuracy: 0.2500\n",
      "Epoch 1191/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3668 - accuracy: 0.4486 - val_loss: 2.4467 - val_accuracy: 0.2333\n",
      "Epoch 1192/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3664 - accuracy: 0.4600 - val_loss: 2.4209 - val_accuracy: 0.2433\n",
      "Epoch 1193/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3669 - accuracy: 0.4557 - val_loss: 2.4436 - val_accuracy: 0.2400\n",
      "Epoch 1194/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3660 - accuracy: 0.4500 - val_loss: 2.4313 - val_accuracy: 0.2300\n",
      "Epoch 1195/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3666 - accuracy: 0.4543 - val_loss: 2.4317 - val_accuracy: 0.2267\n",
      "Epoch 1196/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3657 - accuracy: 0.4614 - val_loss: 2.4489 - val_accuracy: 0.2500\n",
      "Epoch 1197/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3658 - accuracy: 0.4557 - val_loss: 2.4299 - val_accuracy: 0.2433\n",
      "Epoch 1198/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3653 - accuracy: 0.4529 - val_loss: 2.4437 - val_accuracy: 0.2467\n",
      "Epoch 1199/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3656 - accuracy: 0.4543 - val_loss: 2.4290 - val_accuracy: 0.2300\n",
      "Epoch 1200/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3662 - accuracy: 0.4500 - val_loss: 2.4460 - val_accuracy: 0.2400\n",
      "Epoch 1201/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3651 - accuracy: 0.4600 - val_loss: 2.4490 - val_accuracy: 0.2433\n",
      "Epoch 1202/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3660 - accuracy: 0.4529 - val_loss: 2.4605 - val_accuracy: 0.2467\n",
      "Epoch 1203/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3653 - accuracy: 0.4571 - val_loss: 2.4225 - val_accuracy: 0.2467\n",
      "Epoch 1204/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3654 - accuracy: 0.4643 - val_loss: 2.4242 - val_accuracy: 0.2467\n",
      "Epoch 1205/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3639 - accuracy: 0.4571 - val_loss: 2.4371 - val_accuracy: 0.2433\n",
      "Epoch 1206/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3649 - accuracy: 0.4600 - val_loss: 2.4495 - val_accuracy: 0.2433\n",
      "Epoch 1207/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3637 - accuracy: 0.4571 - val_loss: 2.4561 - val_accuracy: 0.2233\n",
      "Epoch 1208/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3636 - accuracy: 0.4514 - val_loss: 2.4504 - val_accuracy: 0.2267\n",
      "Epoch 1209/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3630 - accuracy: 0.4600 - val_loss: 2.4415 - val_accuracy: 0.2433\n",
      "Epoch 1210/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3648 - accuracy: 0.4557 - val_loss: 2.4462 - val_accuracy: 0.2433\n",
      "Epoch 1211/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3645 - accuracy: 0.4586 - val_loss: 2.4559 - val_accuracy: 0.2433\n",
      "Epoch 1212/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3631 - accuracy: 0.4471 - val_loss: 2.4737 - val_accuracy: 0.2500\n",
      "Epoch 1213/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3655 - accuracy: 0.4557 - val_loss: 2.4452 - val_accuracy: 0.2433\n",
      "Epoch 1214/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3634 - accuracy: 0.4557 - val_loss: 2.4679 - val_accuracy: 0.2467\n",
      "Epoch 1215/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3633 - accuracy: 0.4529 - val_loss: 2.4549 - val_accuracy: 0.2467\n",
      "Epoch 1216/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3637 - accuracy: 0.4571 - val_loss: 2.4434 - val_accuracy: 0.2433\n",
      "Epoch 1217/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3636 - accuracy: 0.4514 - val_loss: 2.4625 - val_accuracy: 0.2433\n",
      "Epoch 1218/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3634 - accuracy: 0.4586 - val_loss: 2.4542 - val_accuracy: 0.2433\n",
      "Epoch 1219/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3632 - accuracy: 0.4529 - val_loss: 2.4596 - val_accuracy: 0.2467\n",
      "Epoch 1220/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 1.3642 - accuracy: 0.4529 - val_loss: 2.4367 - val_accuracy: 0.2433\n",
      "Epoch 1221/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3633 - accuracy: 0.4614 - val_loss: 2.4614 - val_accuracy: 0.2300\n",
      "Epoch 1222/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3633 - accuracy: 0.4586 - val_loss: 2.4712 - val_accuracy: 0.2433\n",
      "Epoch 1223/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3632 - accuracy: 0.4586 - val_loss: 2.4696 - val_accuracy: 0.2467\n",
      "Epoch 1224/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3625 - accuracy: 0.4571 - val_loss: 2.4725 - val_accuracy: 0.2467\n",
      "Epoch 1225/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3621 - accuracy: 0.4529 - val_loss: 2.4651 - val_accuracy: 0.2300\n",
      "Epoch 1226/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3636 - accuracy: 0.4629 - val_loss: 2.4592 - val_accuracy: 0.2433\n",
      "Epoch 1227/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3609 - accuracy: 0.4543 - val_loss: 2.4483 - val_accuracy: 0.2433\n",
      "Epoch 1228/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3626 - accuracy: 0.4614 - val_loss: 2.4718 - val_accuracy: 0.2433\n",
      "Epoch 1229/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3630 - accuracy: 0.4543 - val_loss: 2.4582 - val_accuracy: 0.2433\n",
      "Epoch 1230/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3624 - accuracy: 0.4600 - val_loss: 2.4488 - val_accuracy: 0.2467\n",
      "Epoch 1231/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3629 - accuracy: 0.4571 - val_loss: 2.4342 - val_accuracy: 0.2333\n",
      "Epoch 1232/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3626 - accuracy: 0.4543 - val_loss: 2.4819 - val_accuracy: 0.2500\n",
      "Epoch 1233/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3632 - accuracy: 0.4586 - val_loss: 2.4497 - val_accuracy: 0.2433\n",
      "Epoch 1234/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3616 - accuracy: 0.4686 - val_loss: 2.4396 - val_accuracy: 0.2467\n",
      "Epoch 1235/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3618 - accuracy: 0.4571 - val_loss: 2.4482 - val_accuracy: 0.2400\n",
      "Epoch 1236/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3620 - accuracy: 0.4543 - val_loss: 2.4448 - val_accuracy: 0.2367\n",
      "Epoch 1237/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3622 - accuracy: 0.4486 - val_loss: 2.4273 - val_accuracy: 0.2500\n",
      "Epoch 1238/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3610 - accuracy: 0.4586 - val_loss: 2.4741 - val_accuracy: 0.2467\n",
      "Epoch 1239/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3620 - accuracy: 0.4514 - val_loss: 2.4538 - val_accuracy: 0.2400\n",
      "Epoch 1240/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3614 - accuracy: 0.4557 - val_loss: 2.4519 - val_accuracy: 0.2433\n",
      "Epoch 1241/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3614 - accuracy: 0.4557 - val_loss: 2.4660 - val_accuracy: 0.2400\n",
      "Epoch 1242/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3609 - accuracy: 0.4514 - val_loss: 2.4591 - val_accuracy: 0.2433\n",
      "Epoch 1243/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3612 - accuracy: 0.4614 - val_loss: 2.4818 - val_accuracy: 0.2467\n",
      "Epoch 1244/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3611 - accuracy: 0.4529 - val_loss: 2.4443 - val_accuracy: 0.2467\n",
      "Epoch 1245/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3607 - accuracy: 0.4614 - val_loss: 2.4528 - val_accuracy: 0.2433\n",
      "Epoch 1246/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3603 - accuracy: 0.4600 - val_loss: 2.4831 - val_accuracy: 0.2433\n",
      "Epoch 1247/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3601 - accuracy: 0.4614 - val_loss: 2.4707 - val_accuracy: 0.2433\n",
      "Epoch 1248/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3607 - accuracy: 0.4557 - val_loss: 2.4791 - val_accuracy: 0.2400\n",
      "Epoch 1249/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3611 - accuracy: 0.4557 - val_loss: 2.4662 - val_accuracy: 0.2400\n",
      "Epoch 1250/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3596 - accuracy: 0.4571 - val_loss: 2.5088 - val_accuracy: 0.2300\n",
      "Epoch 1251/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3608 - accuracy: 0.4586 - val_loss: 2.4743 - val_accuracy: 0.2400\n",
      "Epoch 1252/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3597 - accuracy: 0.4643 - val_loss: 2.4841 - val_accuracy: 0.2433\n",
      "Epoch 1253/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3609 - accuracy: 0.4500 - val_loss: 2.4688 - val_accuracy: 0.2400\n",
      "Epoch 1254/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3600 - accuracy: 0.4614 - val_loss: 2.4605 - val_accuracy: 0.2433\n",
      "Epoch 1255/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3602 - accuracy: 0.4571 - val_loss: 2.4620 - val_accuracy: 0.2433\n",
      "Epoch 1256/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3592 - accuracy: 0.4586 - val_loss: 2.4859 - val_accuracy: 0.2333\n",
      "Epoch 1257/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3599 - accuracy: 0.4586 - val_loss: 2.4925 - val_accuracy: 0.2467\n",
      "Epoch 1258/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3600 - accuracy: 0.4686 - val_loss: 2.4568 - val_accuracy: 0.2433\n",
      "Epoch 1259/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3597 - accuracy: 0.4600 - val_loss: 2.4545 - val_accuracy: 0.2433\n",
      "Epoch 1260/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3592 - accuracy: 0.4600 - val_loss: 2.4853 - val_accuracy: 0.2467\n",
      "Epoch 1261/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3599 - accuracy: 0.4586 - val_loss: 2.4733 - val_accuracy: 0.2400\n",
      "Epoch 1262/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3597 - accuracy: 0.4571 - val_loss: 2.4772 - val_accuracy: 0.2400\n",
      "Epoch 1263/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3590 - accuracy: 0.4700 - val_loss: 2.4737 - val_accuracy: 0.2400\n",
      "Epoch 1264/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3593 - accuracy: 0.4586 - val_loss: 2.4638 - val_accuracy: 0.2333\n",
      "Epoch 1265/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3593 - accuracy: 0.4614 - val_loss: 2.4736 - val_accuracy: 0.2367\n",
      "Epoch 1266/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3591 - accuracy: 0.4571 - val_loss: 2.4519 - val_accuracy: 0.2467\n",
      "Epoch 1267/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3586 - accuracy: 0.4571 - val_loss: 2.4640 - val_accuracy: 0.2400\n",
      "Epoch 1268/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3596 - accuracy: 0.4629 - val_loss: 2.4807 - val_accuracy: 0.2433\n",
      "Epoch 1269/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3588 - accuracy: 0.4643 - val_loss: 2.4991 - val_accuracy: 0.2500\n",
      "Epoch 1270/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3584 - accuracy: 0.4614 - val_loss: 2.4851 - val_accuracy: 0.2433\n",
      "Epoch 1271/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3589 - accuracy: 0.4557 - val_loss: 2.4717 - val_accuracy: 0.2400\n",
      "Epoch 1272/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3581 - accuracy: 0.4629 - val_loss: 2.4797 - val_accuracy: 0.2433\n",
      "Epoch 1273/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3584 - accuracy: 0.4571 - val_loss: 2.4822 - val_accuracy: 0.2433\n",
      "Epoch 1274/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3586 - accuracy: 0.4614 - val_loss: 2.4796 - val_accuracy: 0.2433\n",
      "Epoch 1275/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 1.3575 - accuracy: 0.4629 - val_loss: 2.4867 - val_accuracy: 0.2433\n",
      "Epoch 1276/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3587 - accuracy: 0.4600 - val_loss: 2.4842 - val_accuracy: 0.2433\n",
      "Epoch 1277/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3580 - accuracy: 0.4600 - val_loss: 2.4837 - val_accuracy: 0.2467\n",
      "Epoch 1278/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3575 - accuracy: 0.4614 - val_loss: 2.5011 - val_accuracy: 0.2467\n",
      "Epoch 1279/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3575 - accuracy: 0.4557 - val_loss: 2.4813 - val_accuracy: 0.2400\n",
      "Epoch 1280/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3577 - accuracy: 0.4614 - val_loss: 2.4975 - val_accuracy: 0.2433\n",
      "Epoch 1281/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3572 - accuracy: 0.4514 - val_loss: 2.4804 - val_accuracy: 0.2433\n",
      "Epoch 1282/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3576 - accuracy: 0.4586 - val_loss: 2.4914 - val_accuracy: 0.2433\n",
      "Epoch 1283/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3573 - accuracy: 0.4671 - val_loss: 2.5163 - val_accuracy: 0.2467\n",
      "Epoch 1284/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3573 - accuracy: 0.4629 - val_loss: 2.5124 - val_accuracy: 0.2533\n",
      "Epoch 1285/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3548 - accuracy: 0.4571 - val_loss: 2.4656 - val_accuracy: 0.2333\n",
      "Epoch 1286/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3547 - accuracy: 0.4643 - val_loss: 2.5010 - val_accuracy: 0.2500\n",
      "Epoch 1287/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3574 - accuracy: 0.4629 - val_loss: 2.5161 - val_accuracy: 0.2500\n",
      "Epoch 1288/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3565 - accuracy: 0.4571 - val_loss: 2.4953 - val_accuracy: 0.2467\n",
      "Epoch 1289/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3569 - accuracy: 0.4671 - val_loss: 2.4891 - val_accuracy: 0.2467\n",
      "Epoch 1290/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3569 - accuracy: 0.4629 - val_loss: 2.4831 - val_accuracy: 0.2400\n",
      "Epoch 1291/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3571 - accuracy: 0.4629 - val_loss: 2.5058 - val_accuracy: 0.2400\n",
      "Epoch 1292/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3563 - accuracy: 0.4600 - val_loss: 2.5124 - val_accuracy: 0.2533\n",
      "Epoch 1293/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3565 - accuracy: 0.4614 - val_loss: 2.4972 - val_accuracy: 0.2400\n",
      "Epoch 1294/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3566 - accuracy: 0.4643 - val_loss: 2.5009 - val_accuracy: 0.2367\n",
      "Epoch 1295/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3556 - accuracy: 0.4671 - val_loss: 2.4956 - val_accuracy: 0.2433\n",
      "Epoch 1296/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3567 - accuracy: 0.4671 - val_loss: 2.4943 - val_accuracy: 0.2400\n",
      "Epoch 1297/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3561 - accuracy: 0.4700 - val_loss: 2.4860 - val_accuracy: 0.2433\n",
      "Epoch 1298/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3563 - accuracy: 0.4643 - val_loss: 2.4872 - val_accuracy: 0.2400\n",
      "Epoch 1299/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3549 - accuracy: 0.4657 - val_loss: 2.5103 - val_accuracy: 0.2400\n",
      "Epoch 1300/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3547 - accuracy: 0.4671 - val_loss: 2.4812 - val_accuracy: 0.2333\n",
      "Epoch 1301/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3544 - accuracy: 0.4529 - val_loss: 2.4786 - val_accuracy: 0.2400\n",
      "Epoch 1302/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3560 - accuracy: 0.4614 - val_loss: 2.5031 - val_accuracy: 0.2467\n",
      "Epoch 1303/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3560 - accuracy: 0.4643 - val_loss: 2.5031 - val_accuracy: 0.2400\n",
      "Epoch 1304/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3556 - accuracy: 0.4729 - val_loss: 2.5089 - val_accuracy: 0.2433\n",
      "Epoch 1305/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3548 - accuracy: 0.4643 - val_loss: 2.5116 - val_accuracy: 0.2500\n",
      "Epoch 1306/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3550 - accuracy: 0.4586 - val_loss: 2.4953 - val_accuracy: 0.2467\n",
      "Epoch 1307/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3555 - accuracy: 0.4643 - val_loss: 2.4956 - val_accuracy: 0.2433\n",
      "Epoch 1308/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3541 - accuracy: 0.4600 - val_loss: 2.4838 - val_accuracy: 0.2400\n",
      "Epoch 1309/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3540 - accuracy: 0.4643 - val_loss: 2.5008 - val_accuracy: 0.2300\n",
      "Epoch 1310/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3551 - accuracy: 0.4643 - val_loss: 2.5070 - val_accuracy: 0.2467\n",
      "Epoch 1311/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3555 - accuracy: 0.4671 - val_loss: 2.5050 - val_accuracy: 0.2433\n",
      "Epoch 1312/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3545 - accuracy: 0.4614 - val_loss: 2.5020 - val_accuracy: 0.2467\n",
      "Epoch 1313/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3544 - accuracy: 0.4614 - val_loss: 2.4838 - val_accuracy: 0.2400\n",
      "Epoch 1314/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3540 - accuracy: 0.4571 - val_loss: 2.5158 - val_accuracy: 0.2367\n",
      "Epoch 1315/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3536 - accuracy: 0.4657 - val_loss: 2.4860 - val_accuracy: 0.2467\n",
      "Epoch 1316/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3545 - accuracy: 0.4643 - val_loss: 2.5217 - val_accuracy: 0.2500\n",
      "Epoch 1317/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3538 - accuracy: 0.4586 - val_loss: 2.4960 - val_accuracy: 0.2300\n",
      "Epoch 1318/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3545 - accuracy: 0.4657 - val_loss: 2.4824 - val_accuracy: 0.2433\n",
      "Epoch 1319/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3545 - accuracy: 0.4700 - val_loss: 2.5131 - val_accuracy: 0.2533\n",
      "Epoch 1320/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3541 - accuracy: 0.4600 - val_loss: 2.4959 - val_accuracy: 0.2433\n",
      "Epoch 1321/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3534 - accuracy: 0.4657 - val_loss: 2.5010 - val_accuracy: 0.2500\n",
      "Epoch 1322/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3536 - accuracy: 0.4629 - val_loss: 2.4931 - val_accuracy: 0.2400\n",
      "Epoch 1323/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3532 - accuracy: 0.4643 - val_loss: 2.5518 - val_accuracy: 0.2467\n",
      "Epoch 1324/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3539 - accuracy: 0.4629 - val_loss: 2.5080 - val_accuracy: 0.2400\n",
      "Epoch 1325/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3525 - accuracy: 0.4629 - val_loss: 2.5249 - val_accuracy: 0.2367\n",
      "Epoch 1326/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3539 - accuracy: 0.4657 - val_loss: 2.5024 - val_accuracy: 0.2400\n",
      "Epoch 1327/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3532 - accuracy: 0.4671 - val_loss: 2.4968 - val_accuracy: 0.2400\n",
      "Epoch 1328/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3529 - accuracy: 0.4643 - val_loss: 2.5416 - val_accuracy: 0.2500\n",
      "Epoch 1329/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3532 - accuracy: 0.4657 - val_loss: 2.5075 - val_accuracy: 0.2500\n",
      "Epoch 1330/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 116us/step - loss: 1.3533 - accuracy: 0.4600 - val_loss: 2.5370 - val_accuracy: 0.2400\n",
      "Epoch 1331/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3532 - accuracy: 0.4643 - val_loss: 2.5303 - val_accuracy: 0.2533\n",
      "Epoch 1332/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3528 - accuracy: 0.4671 - val_loss: 2.5211 - val_accuracy: 0.2433\n",
      "Epoch 1333/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3525 - accuracy: 0.4643 - val_loss: 2.4991 - val_accuracy: 0.2400\n",
      "Epoch 1334/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3520 - accuracy: 0.4657 - val_loss: 2.5432 - val_accuracy: 0.2500\n",
      "Epoch 1335/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3530 - accuracy: 0.4586 - val_loss: 2.4993 - val_accuracy: 0.2400\n",
      "Epoch 1336/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3532 - accuracy: 0.4714 - val_loss: 2.5237 - val_accuracy: 0.2433\n",
      "Epoch 1337/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3524 - accuracy: 0.4629 - val_loss: 2.5068 - val_accuracy: 0.2433\n",
      "Epoch 1338/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3520 - accuracy: 0.4586 - val_loss: 2.5152 - val_accuracy: 0.2400\n",
      "Epoch 1339/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3520 - accuracy: 0.4671 - val_loss: 2.5497 - val_accuracy: 0.2467\n",
      "Epoch 1340/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3526 - accuracy: 0.4643 - val_loss: 2.5148 - val_accuracy: 0.2467\n",
      "Epoch 1341/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3521 - accuracy: 0.4714 - val_loss: 2.5249 - val_accuracy: 0.2467\n",
      "Epoch 1342/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3523 - accuracy: 0.4700 - val_loss: 2.5136 - val_accuracy: 0.2433\n",
      "Epoch 1343/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3514 - accuracy: 0.4629 - val_loss: 2.5182 - val_accuracy: 0.2467\n",
      "Epoch 1344/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3517 - accuracy: 0.4629 - val_loss: 2.5268 - val_accuracy: 0.2500\n",
      "Epoch 1345/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3512 - accuracy: 0.4714 - val_loss: 2.5456 - val_accuracy: 0.2500\n",
      "Epoch 1346/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3513 - accuracy: 0.4600 - val_loss: 2.4946 - val_accuracy: 0.2400\n",
      "Epoch 1347/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3523 - accuracy: 0.4700 - val_loss: 2.5174 - val_accuracy: 0.2467\n",
      "Epoch 1348/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3506 - accuracy: 0.4643 - val_loss: 2.5170 - val_accuracy: 0.2433\n",
      "Epoch 1349/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3508 - accuracy: 0.4643 - val_loss: 2.5316 - val_accuracy: 0.2467\n",
      "Epoch 1350/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3514 - accuracy: 0.4657 - val_loss: 2.5330 - val_accuracy: 0.2433\n",
      "Epoch 1351/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3512 - accuracy: 0.4686 - val_loss: 2.5341 - val_accuracy: 0.2500\n",
      "Epoch 1352/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3513 - accuracy: 0.4714 - val_loss: 2.5058 - val_accuracy: 0.2400\n",
      "Epoch 1353/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3507 - accuracy: 0.4686 - val_loss: 2.5294 - val_accuracy: 0.2433\n",
      "Epoch 1354/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3513 - accuracy: 0.4629 - val_loss: 2.5016 - val_accuracy: 0.2400\n",
      "Epoch 1355/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3500 - accuracy: 0.4700 - val_loss: 2.5319 - val_accuracy: 0.2433\n",
      "Epoch 1356/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3512 - accuracy: 0.4643 - val_loss: 2.5323 - val_accuracy: 0.2400\n",
      "Epoch 1357/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3517 - accuracy: 0.4686 - val_loss: 2.5376 - val_accuracy: 0.2467\n",
      "Epoch 1358/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3506 - accuracy: 0.4643 - val_loss: 2.5133 - val_accuracy: 0.2433\n",
      "Epoch 1359/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3497 - accuracy: 0.4671 - val_loss: 2.5463 - val_accuracy: 0.2400\n",
      "Epoch 1360/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3507 - accuracy: 0.4657 - val_loss: 2.5322 - val_accuracy: 0.2433\n",
      "Epoch 1361/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3510 - accuracy: 0.4629 - val_loss: 2.5432 - val_accuracy: 0.2467\n",
      "Epoch 1362/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3497 - accuracy: 0.4629 - val_loss: 2.5164 - val_accuracy: 0.2433\n",
      "Epoch 1363/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3506 - accuracy: 0.4714 - val_loss: 2.5269 - val_accuracy: 0.2433\n",
      "Epoch 1364/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3498 - accuracy: 0.4643 - val_loss: 2.5448 - val_accuracy: 0.2467\n",
      "Epoch 1365/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3505 - accuracy: 0.4729 - val_loss: 2.5087 - val_accuracy: 0.2400\n",
      "Epoch 1366/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3499 - accuracy: 0.4686 - val_loss: 2.5339 - val_accuracy: 0.2433\n",
      "Epoch 1367/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3499 - accuracy: 0.4757 - val_loss: 2.5131 - val_accuracy: 0.2433\n",
      "Epoch 1368/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3504 - accuracy: 0.4671 - val_loss: 2.5416 - val_accuracy: 0.2467\n",
      "Epoch 1369/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3505 - accuracy: 0.4686 - val_loss: 2.5629 - val_accuracy: 0.2433\n",
      "Epoch 1370/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3490 - accuracy: 0.4657 - val_loss: 2.5629 - val_accuracy: 0.2467\n",
      "Epoch 1371/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3502 - accuracy: 0.4714 - val_loss: 2.5404 - val_accuracy: 0.2400\n",
      "Epoch 1372/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3495 - accuracy: 0.4686 - val_loss: 2.5402 - val_accuracy: 0.2400\n",
      "Epoch 1373/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3495 - accuracy: 0.4714 - val_loss: 2.5460 - val_accuracy: 0.2533\n",
      "Epoch 1374/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3494 - accuracy: 0.4643 - val_loss: 2.5523 - val_accuracy: 0.2500\n",
      "Epoch 1375/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3496 - accuracy: 0.4743 - val_loss: 2.5248 - val_accuracy: 0.2433\n",
      "Epoch 1376/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3488 - accuracy: 0.4700 - val_loss: 2.5314 - val_accuracy: 0.2500\n",
      "Epoch 1377/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3495 - accuracy: 0.4686 - val_loss: 2.5093 - val_accuracy: 0.2433\n",
      "Epoch 1378/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3490 - accuracy: 0.4714 - val_loss: 2.5521 - val_accuracy: 0.2500\n",
      "Epoch 1379/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3487 - accuracy: 0.4643 - val_loss: 2.5612 - val_accuracy: 0.2433\n",
      "Epoch 1380/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3483 - accuracy: 0.4671 - val_loss: 2.5491 - val_accuracy: 0.2467\n",
      "Epoch 1381/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3487 - accuracy: 0.4686 - val_loss: 2.5499 - val_accuracy: 0.2433\n",
      "Epoch 1382/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3470 - accuracy: 0.4729 - val_loss: 2.5616 - val_accuracy: 0.2467\n",
      "Epoch 1383/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3481 - accuracy: 0.4643 - val_loss: 2.5498 - val_accuracy: 0.2433\n",
      "Epoch 1384/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3487 - accuracy: 0.4700 - val_loss: 2.5387 - val_accuracy: 0.2433\n",
      "Epoch 1385/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 1.3475 - accuracy: 0.4743 - val_loss: 2.5509 - val_accuracy: 0.2467\n",
      "Epoch 1386/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3480 - accuracy: 0.4600 - val_loss: 2.5393 - val_accuracy: 0.2333\n",
      "Epoch 1387/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3478 - accuracy: 0.4700 - val_loss: 2.5598 - val_accuracy: 0.2300\n",
      "Epoch 1388/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3481 - accuracy: 0.4657 - val_loss: 2.5517 - val_accuracy: 0.2433\n",
      "Epoch 1389/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3471 - accuracy: 0.4671 - val_loss: 2.5614 - val_accuracy: 0.2467\n",
      "Epoch 1390/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3481 - accuracy: 0.4657 - val_loss: 2.5490 - val_accuracy: 0.2433\n",
      "Epoch 1391/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3483 - accuracy: 0.4657 - val_loss: 2.5623 - val_accuracy: 0.2467\n",
      "Epoch 1392/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3483 - accuracy: 0.4600 - val_loss: 2.5656 - val_accuracy: 0.2400\n",
      "Epoch 1393/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3475 - accuracy: 0.4700 - val_loss: 2.5671 - val_accuracy: 0.2467\n",
      "Epoch 1394/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3463 - accuracy: 0.4586 - val_loss: 2.5563 - val_accuracy: 0.2267\n",
      "Epoch 1395/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3475 - accuracy: 0.4671 - val_loss: 2.5644 - val_accuracy: 0.2300\n",
      "Epoch 1396/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3483 - accuracy: 0.4643 - val_loss: 2.5414 - val_accuracy: 0.2500\n",
      "Epoch 1397/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3462 - accuracy: 0.4657 - val_loss: 2.5557 - val_accuracy: 0.2467\n",
      "Epoch 1398/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3474 - accuracy: 0.4657 - val_loss: 2.5734 - val_accuracy: 0.2500\n",
      "Epoch 1399/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3466 - accuracy: 0.4757 - val_loss: 2.5919 - val_accuracy: 0.2500\n",
      "Epoch 1400/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3460 - accuracy: 0.4657 - val_loss: 2.6060 - val_accuracy: 0.2467\n",
      "Epoch 1401/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3471 - accuracy: 0.4714 - val_loss: 2.5623 - val_accuracy: 0.2500\n",
      "Epoch 1402/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3464 - accuracy: 0.4714 - val_loss: 2.5495 - val_accuracy: 0.2433\n",
      "Epoch 1403/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3450 - accuracy: 0.4671 - val_loss: 2.5464 - val_accuracy: 0.2467\n",
      "Epoch 1404/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3467 - accuracy: 0.4586 - val_loss: 2.5844 - val_accuracy: 0.2467\n",
      "Epoch 1405/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3465 - accuracy: 0.4614 - val_loss: 2.5606 - val_accuracy: 0.2467\n",
      "Epoch 1406/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3466 - accuracy: 0.4671 - val_loss: 2.5438 - val_accuracy: 0.2400\n",
      "Epoch 1407/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3464 - accuracy: 0.4714 - val_loss: 2.5516 - val_accuracy: 0.2433\n",
      "Epoch 1408/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3459 - accuracy: 0.4686 - val_loss: 2.5539 - val_accuracy: 0.2467\n",
      "Epoch 1409/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3458 - accuracy: 0.4657 - val_loss: 2.5339 - val_accuracy: 0.2467\n",
      "Epoch 1410/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3464 - accuracy: 0.4686 - val_loss: 2.5373 - val_accuracy: 0.2467\n",
      "Epoch 1411/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3458 - accuracy: 0.4714 - val_loss: 2.5891 - val_accuracy: 0.2467\n",
      "Epoch 1412/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3462 - accuracy: 0.4729 - val_loss: 2.5486 - val_accuracy: 0.2467\n",
      "Epoch 1413/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3458 - accuracy: 0.4643 - val_loss: 2.5771 - val_accuracy: 0.2400\n",
      "Epoch 1414/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3466 - accuracy: 0.4657 - val_loss: 2.5414 - val_accuracy: 0.2433\n",
      "Epoch 1415/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3458 - accuracy: 0.4743 - val_loss: 2.5668 - val_accuracy: 0.2500\n",
      "Epoch 1416/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3458 - accuracy: 0.4714 - val_loss: 2.5674 - val_accuracy: 0.2500\n",
      "Epoch 1417/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3462 - accuracy: 0.4714 - val_loss: 2.5347 - val_accuracy: 0.2500\n",
      "Epoch 1418/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3449 - accuracy: 0.4629 - val_loss: 2.5530 - val_accuracy: 0.2467\n",
      "Epoch 1419/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3457 - accuracy: 0.4686 - val_loss: 2.5247 - val_accuracy: 0.2433\n",
      "Epoch 1420/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3458 - accuracy: 0.4714 - val_loss: 2.5874 - val_accuracy: 0.2433\n",
      "Epoch 1421/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3458 - accuracy: 0.4657 - val_loss: 2.5665 - val_accuracy: 0.2433\n",
      "Epoch 1422/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3439 - accuracy: 0.4700 - val_loss: 2.5543 - val_accuracy: 0.2467\n",
      "Epoch 1423/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3447 - accuracy: 0.4643 - val_loss: 2.5797 - val_accuracy: 0.2400\n",
      "Epoch 1424/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3454 - accuracy: 0.4700 - val_loss: 2.5645 - val_accuracy: 0.2433\n",
      "Epoch 1425/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3439 - accuracy: 0.4614 - val_loss: 2.5740 - val_accuracy: 0.2333\n",
      "Epoch 1426/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3446 - accuracy: 0.4714 - val_loss: 2.5718 - val_accuracy: 0.2467\n",
      "Epoch 1427/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3441 - accuracy: 0.4686 - val_loss: 2.5912 - val_accuracy: 0.2467\n",
      "Epoch 1428/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3446 - accuracy: 0.4729 - val_loss: 2.5646 - val_accuracy: 0.2467\n",
      "Epoch 1429/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3446 - accuracy: 0.4657 - val_loss: 2.5360 - val_accuracy: 0.2433\n",
      "Epoch 1430/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3445 - accuracy: 0.4671 - val_loss: 2.5871 - val_accuracy: 0.2467\n",
      "Epoch 1431/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3437 - accuracy: 0.4771 - val_loss: 2.5388 - val_accuracy: 0.2400\n",
      "Epoch 1432/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3444 - accuracy: 0.4714 - val_loss: 2.5817 - val_accuracy: 0.2433\n",
      "Epoch 1433/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3449 - accuracy: 0.4686 - val_loss: 2.5714 - val_accuracy: 0.2467\n",
      "Epoch 1434/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3447 - accuracy: 0.4686 - val_loss: 2.5630 - val_accuracy: 0.2467\n",
      "Epoch 1435/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3447 - accuracy: 0.4643 - val_loss: 2.5701 - val_accuracy: 0.2433\n",
      "Epoch 1436/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3424 - accuracy: 0.4643 - val_loss: 2.5874 - val_accuracy: 0.2467\n",
      "Epoch 1437/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3446 - accuracy: 0.4743 - val_loss: 2.5755 - val_accuracy: 0.2467\n",
      "Epoch 1438/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3442 - accuracy: 0.4643 - val_loss: 2.5609 - val_accuracy: 0.2433\n",
      "Epoch 1439/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3439 - accuracy: 0.4729 - val_loss: 2.5808 - val_accuracy: 0.2500\n",
      "Epoch 1440/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 1.3440 - accuracy: 0.4671 - val_loss: 2.5737 - val_accuracy: 0.2467\n",
      "Epoch 1441/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3436 - accuracy: 0.4714 - val_loss: 2.5730 - val_accuracy: 0.2400\n",
      "Epoch 1442/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3440 - accuracy: 0.4729 - val_loss: 2.5866 - val_accuracy: 0.2433\n",
      "Epoch 1443/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3433 - accuracy: 0.4686 - val_loss: 2.5838 - val_accuracy: 0.2433\n",
      "Epoch 1444/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3439 - accuracy: 0.4686 - val_loss: 2.5707 - val_accuracy: 0.2500\n",
      "Epoch 1445/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3425 - accuracy: 0.4600 - val_loss: 2.5708 - val_accuracy: 0.2333\n",
      "Epoch 1446/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3433 - accuracy: 0.4743 - val_loss: 2.6016 - val_accuracy: 0.2467\n",
      "Epoch 1447/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3436 - accuracy: 0.4643 - val_loss: 2.5811 - val_accuracy: 0.2433\n",
      "Epoch 1448/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3422 - accuracy: 0.4671 - val_loss: 2.5787 - val_accuracy: 0.2367\n",
      "Epoch 1449/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3428 - accuracy: 0.4671 - val_loss: 2.5523 - val_accuracy: 0.2433\n",
      "Epoch 1450/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3432 - accuracy: 0.4814 - val_loss: 2.5552 - val_accuracy: 0.2433\n",
      "Epoch 1451/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3425 - accuracy: 0.4714 - val_loss: 2.5922 - val_accuracy: 0.2467\n",
      "Epoch 1452/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3429 - accuracy: 0.4686 - val_loss: 2.5733 - val_accuracy: 0.2433\n",
      "Epoch 1453/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3423 - accuracy: 0.4657 - val_loss: 2.5708 - val_accuracy: 0.2433\n",
      "Epoch 1454/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3429 - accuracy: 0.4771 - val_loss: 2.5675 - val_accuracy: 0.2433\n",
      "Epoch 1455/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3427 - accuracy: 0.4757 - val_loss: 2.5933 - val_accuracy: 0.2467\n",
      "Epoch 1456/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3430 - accuracy: 0.4757 - val_loss: 2.5798 - val_accuracy: 0.2400\n",
      "Epoch 1457/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3425 - accuracy: 0.4643 - val_loss: 2.5912 - val_accuracy: 0.2500\n",
      "Epoch 1458/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3428 - accuracy: 0.4629 - val_loss: 2.5766 - val_accuracy: 0.2400\n",
      "Epoch 1459/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3425 - accuracy: 0.4686 - val_loss: 2.5751 - val_accuracy: 0.2500\n",
      "Epoch 1460/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3414 - accuracy: 0.4714 - val_loss: 2.5802 - val_accuracy: 0.2367\n",
      "Epoch 1461/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3412 - accuracy: 0.4671 - val_loss: 2.5682 - val_accuracy: 0.2533\n",
      "Epoch 1462/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3418 - accuracy: 0.4757 - val_loss: 2.6162 - val_accuracy: 0.2467\n",
      "Epoch 1463/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3418 - accuracy: 0.4657 - val_loss: 2.5876 - val_accuracy: 0.2433\n",
      "Epoch 1464/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3417 - accuracy: 0.4657 - val_loss: 2.5726 - val_accuracy: 0.2467\n",
      "Epoch 1465/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3418 - accuracy: 0.4700 - val_loss: 2.6127 - val_accuracy: 0.2433\n",
      "Epoch 1466/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3417 - accuracy: 0.4671 - val_loss: 2.5952 - val_accuracy: 0.2433\n",
      "Epoch 1467/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3396 - accuracy: 0.4729 - val_loss: 2.5920 - val_accuracy: 0.2433\n",
      "Epoch 1468/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3431 - accuracy: 0.4714 - val_loss: 2.5850 - val_accuracy: 0.2500\n",
      "Epoch 1469/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3417 - accuracy: 0.4686 - val_loss: 2.5990 - val_accuracy: 0.2433\n",
      "Epoch 1470/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3412 - accuracy: 0.4714 - val_loss: 2.5959 - val_accuracy: 0.2433\n",
      "Epoch 1471/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3403 - accuracy: 0.4700 - val_loss: 2.5983 - val_accuracy: 0.2500\n",
      "Epoch 1472/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3413 - accuracy: 0.4643 - val_loss: 2.6075 - val_accuracy: 0.2433\n",
      "Epoch 1473/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3407 - accuracy: 0.4686 - val_loss: 2.5796 - val_accuracy: 0.2433\n",
      "Epoch 1474/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3404 - accuracy: 0.4714 - val_loss: 2.5906 - val_accuracy: 0.2500\n",
      "Epoch 1475/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3403 - accuracy: 0.4714 - val_loss: 2.6062 - val_accuracy: 0.2500\n",
      "Epoch 1476/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3409 - accuracy: 0.4671 - val_loss: 2.5975 - val_accuracy: 0.2433\n",
      "Epoch 1477/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3411 - accuracy: 0.4657 - val_loss: 2.6012 - val_accuracy: 0.2400\n",
      "Epoch 1478/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3401 - accuracy: 0.4729 - val_loss: 2.5700 - val_accuracy: 0.2533\n",
      "Epoch 1479/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3403 - accuracy: 0.4629 - val_loss: 2.5874 - val_accuracy: 0.2433\n",
      "Epoch 1480/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3408 - accuracy: 0.4700 - val_loss: 2.5913 - val_accuracy: 0.2433\n",
      "Epoch 1481/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3400 - accuracy: 0.4657 - val_loss: 2.5908 - val_accuracy: 0.2367\n",
      "Epoch 1482/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3401 - accuracy: 0.4714 - val_loss: 2.6251 - val_accuracy: 0.2500\n",
      "Epoch 1483/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3409 - accuracy: 0.4743 - val_loss: 2.6065 - val_accuracy: 0.2433\n",
      "Epoch 1484/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3397 - accuracy: 0.4686 - val_loss: 2.5875 - val_accuracy: 0.2367\n",
      "Epoch 1485/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3396 - accuracy: 0.4657 - val_loss: 2.6126 - val_accuracy: 0.2267\n",
      "Epoch 1486/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3402 - accuracy: 0.4700 - val_loss: 2.5930 - val_accuracy: 0.2500\n",
      "Epoch 1487/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3396 - accuracy: 0.4686 - val_loss: 2.6135 - val_accuracy: 0.2467\n",
      "Epoch 1488/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3391 - accuracy: 0.4629 - val_loss: 2.5694 - val_accuracy: 0.2400\n",
      "Epoch 1489/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3399 - accuracy: 0.4700 - val_loss: 2.6190 - val_accuracy: 0.2367\n",
      "Epoch 1490/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3390 - accuracy: 0.4686 - val_loss: 2.6249 - val_accuracy: 0.2467\n",
      "Epoch 1491/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3395 - accuracy: 0.4714 - val_loss: 2.6218 - val_accuracy: 0.2433\n",
      "Epoch 1492/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3378 - accuracy: 0.4714 - val_loss: 2.6114 - val_accuracy: 0.2367\n",
      "Epoch 1493/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3412 - accuracy: 0.4614 - val_loss: 2.6008 - val_accuracy: 0.2500\n",
      "Epoch 1494/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3398 - accuracy: 0.4743 - val_loss: 2.5969 - val_accuracy: 0.2500\n",
      "Epoch 1495/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 1.3383 - accuracy: 0.4686 - val_loss: 2.5987 - val_accuracy: 0.2433\n",
      "Epoch 1496/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3393 - accuracy: 0.4714 - val_loss: 2.5972 - val_accuracy: 0.2500\n",
      "Epoch 1497/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3383 - accuracy: 0.4671 - val_loss: 2.6129 - val_accuracy: 0.2433\n",
      "Epoch 1498/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3387 - accuracy: 0.4743 - val_loss: 2.6393 - val_accuracy: 0.2500\n",
      "Epoch 1499/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3395 - accuracy: 0.4700 - val_loss: 2.6042 - val_accuracy: 0.2467\n",
      "Epoch 1500/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3388 - accuracy: 0.4771 - val_loss: 2.6116 - val_accuracy: 0.2433\n",
      "Epoch 1501/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3389 - accuracy: 0.4729 - val_loss: 2.6054 - val_accuracy: 0.2467\n",
      "Epoch 1502/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3390 - accuracy: 0.4714 - val_loss: 2.6098 - val_accuracy: 0.2467\n",
      "Epoch 1503/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3390 - accuracy: 0.4657 - val_loss: 2.6042 - val_accuracy: 0.2433\n",
      "Epoch 1504/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3381 - accuracy: 0.4743 - val_loss: 2.6240 - val_accuracy: 0.2433\n",
      "Epoch 1505/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3386 - accuracy: 0.4686 - val_loss: 2.6131 - val_accuracy: 0.2400\n",
      "Epoch 1506/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3391 - accuracy: 0.4786 - val_loss: 2.5983 - val_accuracy: 0.2433\n",
      "Epoch 1507/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3382 - accuracy: 0.4714 - val_loss: 2.6043 - val_accuracy: 0.2367\n",
      "Epoch 1508/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3387 - accuracy: 0.4643 - val_loss: 2.6308 - val_accuracy: 0.2467\n",
      "Epoch 1509/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3382 - accuracy: 0.4757 - val_loss: 2.6092 - val_accuracy: 0.2433\n",
      "Epoch 1510/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3384 - accuracy: 0.4743 - val_loss: 2.6532 - val_accuracy: 0.2467\n",
      "Epoch 1511/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3379 - accuracy: 0.4729 - val_loss: 2.6494 - val_accuracy: 0.2500\n",
      "Epoch 1512/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3368 - accuracy: 0.4714 - val_loss: 2.6204 - val_accuracy: 0.2433\n",
      "Epoch 1513/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3380 - accuracy: 0.4686 - val_loss: 2.5901 - val_accuracy: 0.2433\n",
      "Epoch 1514/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3381 - accuracy: 0.4671 - val_loss: 2.6135 - val_accuracy: 0.2433\n",
      "Epoch 1515/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3377 - accuracy: 0.4757 - val_loss: 2.6393 - val_accuracy: 0.2500\n",
      "Epoch 1516/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3395 - accuracy: 0.4743 - val_loss: 2.6289 - val_accuracy: 0.2467\n",
      "Epoch 1517/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3373 - accuracy: 0.4743 - val_loss: 2.6084 - val_accuracy: 0.2467\n",
      "Epoch 1518/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3371 - accuracy: 0.4757 - val_loss: 2.5965 - val_accuracy: 0.2500\n",
      "Epoch 1519/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3370 - accuracy: 0.4757 - val_loss: 2.5948 - val_accuracy: 0.2367\n",
      "Epoch 1520/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3373 - accuracy: 0.4700 - val_loss: 2.6313 - val_accuracy: 0.2467\n",
      "Epoch 1521/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3368 - accuracy: 0.4800 - val_loss: 2.5999 - val_accuracy: 0.2433\n",
      "Epoch 1522/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3379 - accuracy: 0.4714 - val_loss: 2.6182 - val_accuracy: 0.2467\n",
      "Epoch 1523/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3371 - accuracy: 0.4743 - val_loss: 2.6055 - val_accuracy: 0.2467\n",
      "Epoch 1524/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3374 - accuracy: 0.4714 - val_loss: 2.6326 - val_accuracy: 0.2467\n",
      "Epoch 1525/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3370 - accuracy: 0.4729 - val_loss: 2.6146 - val_accuracy: 0.2467\n",
      "Epoch 1526/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3369 - accuracy: 0.4743 - val_loss: 2.6632 - val_accuracy: 0.2467\n",
      "Epoch 1527/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3354 - accuracy: 0.4686 - val_loss: 2.6116 - val_accuracy: 0.2333\n",
      "Epoch 1528/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3370 - accuracy: 0.4786 - val_loss: 2.6319 - val_accuracy: 0.2467\n",
      "Epoch 1529/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3375 - accuracy: 0.4657 - val_loss: 2.6297 - val_accuracy: 0.2433\n",
      "Epoch 1530/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3369 - accuracy: 0.4643 - val_loss: 2.6194 - val_accuracy: 0.2433\n",
      "Epoch 1531/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3366 - accuracy: 0.4757 - val_loss: 2.6224 - val_accuracy: 0.2433\n",
      "Epoch 1532/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3364 - accuracy: 0.4800 - val_loss: 2.6019 - val_accuracy: 0.2500\n",
      "Epoch 1533/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3365 - accuracy: 0.4729 - val_loss: 2.6190 - val_accuracy: 0.2433\n",
      "Epoch 1534/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3370 - accuracy: 0.4700 - val_loss: 2.6057 - val_accuracy: 0.2500\n",
      "Epoch 1535/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3368 - accuracy: 0.4771 - val_loss: 2.6405 - val_accuracy: 0.2400\n",
      "Epoch 1536/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3360 - accuracy: 0.4757 - val_loss: 2.6244 - val_accuracy: 0.2400\n",
      "Epoch 1537/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3359 - accuracy: 0.4743 - val_loss: 2.6217 - val_accuracy: 0.2467\n",
      "Epoch 1538/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3354 - accuracy: 0.4729 - val_loss: 2.6127 - val_accuracy: 0.2433\n",
      "Epoch 1539/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3354 - accuracy: 0.4671 - val_loss: 2.6013 - val_accuracy: 0.2500\n",
      "Epoch 1540/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3358 - accuracy: 0.4714 - val_loss: 2.6026 - val_accuracy: 0.2500\n",
      "Epoch 1541/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3362 - accuracy: 0.4714 - val_loss: 2.6284 - val_accuracy: 0.2433\n",
      "Epoch 1542/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3357 - accuracy: 0.4729 - val_loss: 2.6263 - val_accuracy: 0.2367\n",
      "Epoch 1543/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3357 - accuracy: 0.4757 - val_loss: 2.6158 - val_accuracy: 0.2433\n",
      "Epoch 1544/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3362 - accuracy: 0.4800 - val_loss: 2.6253 - val_accuracy: 0.2433\n",
      "Epoch 1545/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3352 - accuracy: 0.4729 - val_loss: 2.6046 - val_accuracy: 0.2433\n",
      "Epoch 1546/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3357 - accuracy: 0.4800 - val_loss: 2.6308 - val_accuracy: 0.2367\n",
      "Epoch 1547/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3356 - accuracy: 0.4757 - val_loss: 2.6498 - val_accuracy: 0.2433\n",
      "Epoch 1548/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3358 - accuracy: 0.4714 - val_loss: 2.6463 - val_accuracy: 0.2500\n",
      "Epoch 1549/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3343 - accuracy: 0.4729 - val_loss: 2.6542 - val_accuracy: 0.2433\n",
      "Epoch 1550/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 101us/step - loss: 1.3352 - accuracy: 0.4700 - val_loss: 2.6547 - val_accuracy: 0.2433\n",
      "Epoch 1551/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3351 - accuracy: 0.4743 - val_loss: 2.6209 - val_accuracy: 0.2367\n",
      "Epoch 1552/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3348 - accuracy: 0.4729 - val_loss: 2.6499 - val_accuracy: 0.2500\n",
      "Epoch 1553/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3348 - accuracy: 0.4771 - val_loss: 2.6502 - val_accuracy: 0.2467\n",
      "Epoch 1554/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3352 - accuracy: 0.4700 - val_loss: 2.6340 - val_accuracy: 0.2367\n",
      "Epoch 1555/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3350 - accuracy: 0.4714 - val_loss: 2.6340 - val_accuracy: 0.2400\n",
      "Epoch 1556/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3342 - accuracy: 0.4729 - val_loss: 2.6275 - val_accuracy: 0.2467\n",
      "Epoch 1557/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3339 - accuracy: 0.4729 - val_loss: 2.6351 - val_accuracy: 0.2433\n",
      "Epoch 1558/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3342 - accuracy: 0.4743 - val_loss: 2.5980 - val_accuracy: 0.2533\n",
      "Epoch 1559/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3345 - accuracy: 0.4757 - val_loss: 2.6485 - val_accuracy: 0.2467\n",
      "Epoch 1560/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3347 - accuracy: 0.4729 - val_loss: 2.6310 - val_accuracy: 0.2433\n",
      "Epoch 1561/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3337 - accuracy: 0.4714 - val_loss: 2.6370 - val_accuracy: 0.2467\n",
      "Epoch 1562/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3343 - accuracy: 0.4700 - val_loss: 2.6726 - val_accuracy: 0.2500\n",
      "Epoch 1563/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3350 - accuracy: 0.4757 - val_loss: 2.6434 - val_accuracy: 0.2467\n",
      "Epoch 1564/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3328 - accuracy: 0.4757 - val_loss: 2.6319 - val_accuracy: 0.2400\n",
      "Epoch 1565/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3350 - accuracy: 0.4757 - val_loss: 2.6307 - val_accuracy: 0.2467\n",
      "Epoch 1566/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3334 - accuracy: 0.4771 - val_loss: 2.6387 - val_accuracy: 0.2367\n",
      "Epoch 1567/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3343 - accuracy: 0.4757 - val_loss: 2.6435 - val_accuracy: 0.2400\n",
      "Epoch 1568/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3337 - accuracy: 0.4729 - val_loss: 2.6328 - val_accuracy: 0.2433\n",
      "Epoch 1569/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3342 - accuracy: 0.4786 - val_loss: 2.6693 - val_accuracy: 0.2467\n",
      "Epoch 1570/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3330 - accuracy: 0.4814 - val_loss: 2.6782 - val_accuracy: 0.2433\n",
      "Epoch 1571/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3347 - accuracy: 0.4714 - val_loss: 2.6616 - val_accuracy: 0.2433\n",
      "Epoch 1572/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3339 - accuracy: 0.4771 - val_loss: 2.6387 - val_accuracy: 0.2367\n",
      "Epoch 1573/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3335 - accuracy: 0.4757 - val_loss: 2.6814 - val_accuracy: 0.2433\n",
      "Epoch 1574/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3339 - accuracy: 0.4671 - val_loss: 2.6534 - val_accuracy: 0.2433\n",
      "Epoch 1575/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3327 - accuracy: 0.4757 - val_loss: 2.6278 - val_accuracy: 0.2467\n",
      "Epoch 1576/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3330 - accuracy: 0.4771 - val_loss: 2.6691 - val_accuracy: 0.2467\n",
      "Epoch 1577/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3337 - accuracy: 0.4700 - val_loss: 2.6356 - val_accuracy: 0.2400\n",
      "Epoch 1578/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3320 - accuracy: 0.4771 - val_loss: 2.6465 - val_accuracy: 0.2433\n",
      "Epoch 1579/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3331 - accuracy: 0.4714 - val_loss: 2.6453 - val_accuracy: 0.2467\n",
      "Epoch 1580/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3321 - accuracy: 0.4800 - val_loss: 2.6620 - val_accuracy: 0.2467\n",
      "Epoch 1581/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3335 - accuracy: 0.4671 - val_loss: 2.6603 - val_accuracy: 0.2400\n",
      "Epoch 1582/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3330 - accuracy: 0.4771 - val_loss: 2.6338 - val_accuracy: 0.2433\n",
      "Epoch 1583/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3323 - accuracy: 0.4743 - val_loss: 2.6476 - val_accuracy: 0.2433\n",
      "Epoch 1584/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3336 - accuracy: 0.4757 - val_loss: 2.6591 - val_accuracy: 0.2433\n",
      "Epoch 1585/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3327 - accuracy: 0.4700 - val_loss: 2.6486 - val_accuracy: 0.2500\n",
      "Epoch 1586/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3318 - accuracy: 0.4729 - val_loss: 2.6663 - val_accuracy: 0.2333\n",
      "Epoch 1587/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3321 - accuracy: 0.4714 - val_loss: 2.6713 - val_accuracy: 0.2400\n",
      "Epoch 1588/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3320 - accuracy: 0.4800 - val_loss: 2.6373 - val_accuracy: 0.2467\n",
      "Epoch 1589/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3324 - accuracy: 0.4786 - val_loss: 2.6690 - val_accuracy: 0.2400\n",
      "Epoch 1590/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3316 - accuracy: 0.4714 - val_loss: 2.6570 - val_accuracy: 0.2500\n",
      "Epoch 1591/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3324 - accuracy: 0.4800 - val_loss: 2.6426 - val_accuracy: 0.2433\n",
      "Epoch 1592/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3319 - accuracy: 0.4686 - val_loss: 2.6602 - val_accuracy: 0.2467\n",
      "Epoch 1593/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3310 - accuracy: 0.4700 - val_loss: 2.6723 - val_accuracy: 0.2400\n",
      "Epoch 1594/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3321 - accuracy: 0.4771 - val_loss: 2.6611 - val_accuracy: 0.2433\n",
      "Epoch 1595/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3310 - accuracy: 0.4771 - val_loss: 2.6530 - val_accuracy: 0.2433\n",
      "Epoch 1596/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3315 - accuracy: 0.4729 - val_loss: 2.6219 - val_accuracy: 0.2467\n",
      "Epoch 1597/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3311 - accuracy: 0.4757 - val_loss: 2.6387 - val_accuracy: 0.2433\n",
      "Epoch 1598/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3323 - accuracy: 0.4829 - val_loss: 2.6641 - val_accuracy: 0.2400\n",
      "Epoch 1599/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3313 - accuracy: 0.4686 - val_loss: 2.6547 - val_accuracy: 0.2333\n",
      "Epoch 1600/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3315 - accuracy: 0.4771 - val_loss: 2.6646 - val_accuracy: 0.2333\n",
      "Epoch 1601/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3320 - accuracy: 0.4771 - val_loss: 2.6424 - val_accuracy: 0.2467\n",
      "Epoch 1602/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3307 - accuracy: 0.4729 - val_loss: 2.6798 - val_accuracy: 0.2467\n",
      "Epoch 1603/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3313 - accuracy: 0.4714 - val_loss: 2.6782 - val_accuracy: 0.2500\n",
      "Epoch 1604/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3311 - accuracy: 0.4757 - val_loss: 2.6673 - val_accuracy: 0.2433\n",
      "Epoch 1605/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 111us/step - loss: 1.3313 - accuracy: 0.4800 - val_loss: 2.6857 - val_accuracy: 0.2500\n",
      "Epoch 1606/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3307 - accuracy: 0.4786 - val_loss: 2.6368 - val_accuracy: 0.2400\n",
      "Epoch 1607/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3324 - accuracy: 0.4800 - val_loss: 2.6526 - val_accuracy: 0.2467\n",
      "Epoch 1608/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3294 - accuracy: 0.4786 - val_loss: 2.6625 - val_accuracy: 0.2467\n",
      "Epoch 1609/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3308 - accuracy: 0.4786 - val_loss: 2.7004 - val_accuracy: 0.2500\n",
      "Epoch 1610/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3312 - accuracy: 0.4729 - val_loss: 2.6731 - val_accuracy: 0.2433\n",
      "Epoch 1611/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3299 - accuracy: 0.4743 - val_loss: 2.6899 - val_accuracy: 0.2433\n",
      "Epoch 1612/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3306 - accuracy: 0.4729 - val_loss: 2.6726 - val_accuracy: 0.2433\n",
      "Epoch 1613/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3300 - accuracy: 0.4743 - val_loss: 2.6727 - val_accuracy: 0.2333\n",
      "Epoch 1614/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3304 - accuracy: 0.4700 - val_loss: 2.6780 - val_accuracy: 0.2467\n",
      "Epoch 1615/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3310 - accuracy: 0.4800 - val_loss: 2.6939 - val_accuracy: 0.2467\n",
      "Epoch 1616/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3307 - accuracy: 0.4786 - val_loss: 2.6709 - val_accuracy: 0.2433\n",
      "Epoch 1617/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3293 - accuracy: 0.4757 - val_loss: 2.6457 - val_accuracy: 0.2433\n",
      "Epoch 1618/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3312 - accuracy: 0.4729 - val_loss: 2.6711 - val_accuracy: 0.2400\n",
      "Epoch 1619/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3300 - accuracy: 0.4743 - val_loss: 2.6753 - val_accuracy: 0.2467\n",
      "Epoch 1620/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3300 - accuracy: 0.4757 - val_loss: 2.6782 - val_accuracy: 0.2400\n",
      "Epoch 1621/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3298 - accuracy: 0.4800 - val_loss: 2.7107 - val_accuracy: 0.2467\n",
      "Epoch 1622/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3293 - accuracy: 0.4743 - val_loss: 2.6503 - val_accuracy: 0.2467\n",
      "Epoch 1623/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3291 - accuracy: 0.4729 - val_loss: 2.6661 - val_accuracy: 0.2400\n",
      "Epoch 1624/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3281 - accuracy: 0.4757 - val_loss: 2.6819 - val_accuracy: 0.2400\n",
      "Epoch 1625/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3297 - accuracy: 0.4743 - val_loss: 2.6781 - val_accuracy: 0.2367\n",
      "Epoch 1626/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3291 - accuracy: 0.4771 - val_loss: 2.6668 - val_accuracy: 0.2400\n",
      "Epoch 1627/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3291 - accuracy: 0.4771 - val_loss: 2.7246 - val_accuracy: 0.2433\n",
      "Epoch 1628/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3292 - accuracy: 0.4800 - val_loss: 2.6879 - val_accuracy: 0.2400\n",
      "Epoch 1629/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3294 - accuracy: 0.4814 - val_loss: 2.6605 - val_accuracy: 0.2433\n",
      "Epoch 1630/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3292 - accuracy: 0.4743 - val_loss: 2.6890 - val_accuracy: 0.2400\n",
      "Epoch 1631/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3295 - accuracy: 0.4800 - val_loss: 2.6815 - val_accuracy: 0.2433\n",
      "Epoch 1632/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3282 - accuracy: 0.4771 - val_loss: 2.7149 - val_accuracy: 0.2433\n",
      "Epoch 1633/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3291 - accuracy: 0.4729 - val_loss: 2.6811 - val_accuracy: 0.2400\n",
      "Epoch 1634/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3282 - accuracy: 0.4771 - val_loss: 2.7043 - val_accuracy: 0.2500\n",
      "Epoch 1635/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3278 - accuracy: 0.4714 - val_loss: 2.6794 - val_accuracy: 0.2400\n",
      "Epoch 1636/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3288 - accuracy: 0.4743 - val_loss: 2.7085 - val_accuracy: 0.2500\n",
      "Epoch 1637/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3265 - accuracy: 0.4714 - val_loss: 2.7041 - val_accuracy: 0.2433\n",
      "Epoch 1638/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3279 - accuracy: 0.4786 - val_loss: 2.7136 - val_accuracy: 0.2467\n",
      "Epoch 1639/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3275 - accuracy: 0.4686 - val_loss: 2.7062 - val_accuracy: 0.2400\n",
      "Epoch 1640/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3276 - accuracy: 0.4757 - val_loss: 2.7232 - val_accuracy: 0.2467\n",
      "Epoch 1641/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3284 - accuracy: 0.4814 - val_loss: 2.6766 - val_accuracy: 0.2400\n",
      "Epoch 1642/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3278 - accuracy: 0.4786 - val_loss: 2.6917 - val_accuracy: 0.2433\n",
      "Epoch 1643/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3274 - accuracy: 0.4814 - val_loss: 2.7086 - val_accuracy: 0.2467\n",
      "Epoch 1644/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3273 - accuracy: 0.4757 - val_loss: 2.6862 - val_accuracy: 0.2400\n",
      "Epoch 1645/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3257 - accuracy: 0.4829 - val_loss: 2.6932 - val_accuracy: 0.2433\n",
      "Epoch 1646/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3263 - accuracy: 0.4686 - val_loss: 2.6691 - val_accuracy: 0.2367\n",
      "Epoch 1647/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3266 - accuracy: 0.4843 - val_loss: 2.7287 - val_accuracy: 0.2433\n",
      "Epoch 1648/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3275 - accuracy: 0.4771 - val_loss: 2.7117 - val_accuracy: 0.2400\n",
      "Epoch 1649/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3265 - accuracy: 0.4743 - val_loss: 2.7074 - val_accuracy: 0.2400\n",
      "Epoch 1650/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3260 - accuracy: 0.4857 - val_loss: 2.6888 - val_accuracy: 0.2433\n",
      "Epoch 1651/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3276 - accuracy: 0.4729 - val_loss: 2.6837 - val_accuracy: 0.2467\n",
      "Epoch 1652/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3268 - accuracy: 0.4743 - val_loss: 2.6958 - val_accuracy: 0.2400\n",
      "Epoch 1653/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3259 - accuracy: 0.4743 - val_loss: 2.7185 - val_accuracy: 0.2500\n",
      "Epoch 1654/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3285 - accuracy: 0.4786 - val_loss: 2.6946 - val_accuracy: 0.2467\n",
      "Epoch 1655/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3257 - accuracy: 0.4771 - val_loss: 2.6982 - val_accuracy: 0.2400\n",
      "Epoch 1656/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3273 - accuracy: 0.4786 - val_loss: 2.6948 - val_accuracy: 0.2400\n",
      "Epoch 1657/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3268 - accuracy: 0.4829 - val_loss: 2.6933 - val_accuracy: 0.2467\n",
      "Epoch 1658/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3263 - accuracy: 0.4786 - val_loss: 2.7085 - val_accuracy: 0.2400\n",
      "Epoch 1659/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3266 - accuracy: 0.4857 - val_loss: 2.6862 - val_accuracy: 0.2400\n",
      "Epoch 1660/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 1.3262 - accuracy: 0.4757 - val_loss: 2.7058 - val_accuracy: 0.2400\n",
      "Epoch 1661/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3259 - accuracy: 0.4786 - val_loss: 2.6907 - val_accuracy: 0.2433\n",
      "Epoch 1662/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3261 - accuracy: 0.4757 - val_loss: 2.6995 - val_accuracy: 0.2433\n",
      "Epoch 1663/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3263 - accuracy: 0.4800 - val_loss: 2.7092 - val_accuracy: 0.2433\n",
      "Epoch 1664/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3267 - accuracy: 0.4757 - val_loss: 2.7177 - val_accuracy: 0.2467\n",
      "Epoch 1665/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3258 - accuracy: 0.4657 - val_loss: 2.6972 - val_accuracy: 0.2467\n",
      "Epoch 1666/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3258 - accuracy: 0.4814 - val_loss: 2.6991 - val_accuracy: 0.2467\n",
      "Epoch 1667/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3253 - accuracy: 0.4786 - val_loss: 2.6890 - val_accuracy: 0.2400\n",
      "Epoch 1668/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3255 - accuracy: 0.4729 - val_loss: 2.6885 - val_accuracy: 0.2400\n",
      "Epoch 1669/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3258 - accuracy: 0.4829 - val_loss: 2.7045 - val_accuracy: 0.2400\n",
      "Epoch 1670/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3249 - accuracy: 0.4814 - val_loss: 2.7292 - val_accuracy: 0.2433\n",
      "Epoch 1671/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3256 - accuracy: 0.4757 - val_loss: 2.7207 - val_accuracy: 0.2433\n",
      "Epoch 1672/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3252 - accuracy: 0.4814 - val_loss: 2.7174 - val_accuracy: 0.2433\n",
      "Epoch 1673/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3248 - accuracy: 0.4771 - val_loss: 2.7509 - val_accuracy: 0.2533\n",
      "Epoch 1674/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3242 - accuracy: 0.4871 - val_loss: 2.7321 - val_accuracy: 0.2433\n",
      "Epoch 1675/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3251 - accuracy: 0.4786 - val_loss: 2.6973 - val_accuracy: 0.2400\n",
      "Epoch 1676/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3255 - accuracy: 0.4771 - val_loss: 2.7175 - val_accuracy: 0.2400\n",
      "Epoch 1677/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3237 - accuracy: 0.4771 - val_loss: 2.6928 - val_accuracy: 0.2467\n",
      "Epoch 1678/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3250 - accuracy: 0.4771 - val_loss: 2.7118 - val_accuracy: 0.2433\n",
      "Epoch 1679/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3245 - accuracy: 0.4757 - val_loss: 2.7226 - val_accuracy: 0.2400\n",
      "Epoch 1680/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3245 - accuracy: 0.4814 - val_loss: 2.7060 - val_accuracy: 0.2433\n",
      "Epoch 1681/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3249 - accuracy: 0.4800 - val_loss: 2.7123 - val_accuracy: 0.2400\n",
      "Epoch 1682/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3248 - accuracy: 0.4800 - val_loss: 2.7110 - val_accuracy: 0.2433\n",
      "Epoch 1683/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3248 - accuracy: 0.4829 - val_loss: 2.7117 - val_accuracy: 0.2400\n",
      "Epoch 1684/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3234 - accuracy: 0.4843 - val_loss: 2.7466 - val_accuracy: 0.2467\n",
      "Epoch 1685/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3248 - accuracy: 0.4786 - val_loss: 2.7151 - val_accuracy: 0.2433\n",
      "Epoch 1686/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3238 - accuracy: 0.4729 - val_loss: 2.7518 - val_accuracy: 0.2500\n",
      "Epoch 1687/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3245 - accuracy: 0.4871 - val_loss: 2.7195 - val_accuracy: 0.2400\n",
      "Epoch 1688/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3245 - accuracy: 0.4886 - val_loss: 2.7087 - val_accuracy: 0.2400\n",
      "Epoch 1689/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3250 - accuracy: 0.4757 - val_loss: 2.7209 - val_accuracy: 0.2433\n",
      "Epoch 1690/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3244 - accuracy: 0.4814 - val_loss: 2.7116 - val_accuracy: 0.2367\n",
      "Epoch 1691/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3233 - accuracy: 0.4829 - val_loss: 2.7133 - val_accuracy: 0.2433\n",
      "Epoch 1692/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3240 - accuracy: 0.4786 - val_loss: 2.7283 - val_accuracy: 0.2433\n",
      "Epoch 1693/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3237 - accuracy: 0.4757 - val_loss: 2.7456 - val_accuracy: 0.2400\n",
      "Epoch 1694/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3243 - accuracy: 0.4829 - val_loss: 2.7446 - val_accuracy: 0.2467\n",
      "Epoch 1695/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3240 - accuracy: 0.4786 - val_loss: 2.7232 - val_accuracy: 0.2433\n",
      "Epoch 1696/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3234 - accuracy: 0.4786 - val_loss: 2.6872 - val_accuracy: 0.2467\n",
      "Epoch 1697/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3235 - accuracy: 0.4871 - val_loss: 2.7205 - val_accuracy: 0.2433\n",
      "Epoch 1698/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3234 - accuracy: 0.4829 - val_loss: 2.7329 - val_accuracy: 0.2400\n",
      "Epoch 1699/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3238 - accuracy: 0.4786 - val_loss: 2.7470 - val_accuracy: 0.2467\n",
      "Epoch 1700/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3229 - accuracy: 0.4771 - val_loss: 2.7461 - val_accuracy: 0.2500\n",
      "Epoch 1701/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3228 - accuracy: 0.4814 - val_loss: 2.7329 - val_accuracy: 0.2433\n",
      "Epoch 1702/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3235 - accuracy: 0.4743 - val_loss: 2.7110 - val_accuracy: 0.2433\n",
      "Epoch 1703/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3229 - accuracy: 0.4714 - val_loss: 2.7191 - val_accuracy: 0.2400\n",
      "Epoch 1704/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3225 - accuracy: 0.4786 - val_loss: 2.7292 - val_accuracy: 0.2400\n",
      "Epoch 1705/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3232 - accuracy: 0.4829 - val_loss: 2.7529 - val_accuracy: 0.2467\n",
      "Epoch 1706/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3226 - accuracy: 0.4800 - val_loss: 2.7202 - val_accuracy: 0.2433\n",
      "Epoch 1707/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3232 - accuracy: 0.4814 - val_loss: 2.7391 - val_accuracy: 0.2467\n",
      "Epoch 1708/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3217 - accuracy: 0.4786 - val_loss: 2.7271 - val_accuracy: 0.2433\n",
      "Epoch 1709/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3221 - accuracy: 0.4771 - val_loss: 2.7326 - val_accuracy: 0.2433\n",
      "Epoch 1710/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3226 - accuracy: 0.4771 - val_loss: 2.7145 - val_accuracy: 0.2433\n",
      "Epoch 1711/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3225 - accuracy: 0.4800 - val_loss: 2.7277 - val_accuracy: 0.2433\n",
      "Epoch 1712/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3231 - accuracy: 0.4786 - val_loss: 2.7367 - val_accuracy: 0.2433\n",
      "Epoch 1713/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3219 - accuracy: 0.4757 - val_loss: 2.7637 - val_accuracy: 0.2500\n",
      "Epoch 1714/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3233 - accuracy: 0.4814 - val_loss: 2.7087 - val_accuracy: 0.2433\n",
      "Epoch 1715/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 1.3225 - accuracy: 0.4857 - val_loss: 2.7605 - val_accuracy: 0.2533\n",
      "Epoch 1716/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3221 - accuracy: 0.4800 - val_loss: 2.7636 - val_accuracy: 0.2533\n",
      "Epoch 1717/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3220 - accuracy: 0.4800 - val_loss: 2.7174 - val_accuracy: 0.2433\n",
      "Epoch 1718/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3229 - accuracy: 0.4886 - val_loss: 2.7441 - val_accuracy: 0.2467\n",
      "Epoch 1719/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3224 - accuracy: 0.4857 - val_loss: 2.6847 - val_accuracy: 0.2433\n",
      "Epoch 1720/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3212 - accuracy: 0.4814 - val_loss: 2.7311 - val_accuracy: 0.2433\n",
      "Epoch 1721/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3220 - accuracy: 0.4800 - val_loss: 2.7231 - val_accuracy: 0.2433\n",
      "Epoch 1722/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3227 - accuracy: 0.4757 - val_loss: 2.7074 - val_accuracy: 0.2400\n",
      "Epoch 1723/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3219 - accuracy: 0.4800 - val_loss: 2.7116 - val_accuracy: 0.2400\n",
      "Epoch 1724/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3210 - accuracy: 0.4857 - val_loss: 2.7300 - val_accuracy: 0.2367\n",
      "Epoch 1725/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3217 - accuracy: 0.4857 - val_loss: 2.7403 - val_accuracy: 0.2433\n",
      "Epoch 1726/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3212 - accuracy: 0.4814 - val_loss: 2.7482 - val_accuracy: 0.2467\n",
      "Epoch 1727/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3221 - accuracy: 0.4829 - val_loss: 2.7459 - val_accuracy: 0.2500\n",
      "Epoch 1728/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3212 - accuracy: 0.4743 - val_loss: 2.7464 - val_accuracy: 0.2433\n",
      "Epoch 1729/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3219 - accuracy: 0.4757 - val_loss: 2.7380 - val_accuracy: 0.2400\n",
      "Epoch 1730/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3210 - accuracy: 0.4843 - val_loss: 2.7198 - val_accuracy: 0.2400\n",
      "Epoch 1731/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3213 - accuracy: 0.4814 - val_loss: 2.7584 - val_accuracy: 0.2500\n",
      "Epoch 1732/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3210 - accuracy: 0.4829 - val_loss: 2.7479 - val_accuracy: 0.2467\n",
      "Epoch 1733/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3201 - accuracy: 0.4800 - val_loss: 2.7631 - val_accuracy: 0.2467\n",
      "Epoch 1734/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3212 - accuracy: 0.4757 - val_loss: 2.7523 - val_accuracy: 0.2433\n",
      "Epoch 1735/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3217 - accuracy: 0.4814 - val_loss: 2.7310 - val_accuracy: 0.2433\n",
      "Epoch 1736/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3209 - accuracy: 0.4829 - val_loss: 2.7489 - val_accuracy: 0.2433\n",
      "Epoch 1737/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3194 - accuracy: 0.4843 - val_loss: 2.7576 - val_accuracy: 0.2433\n",
      "Epoch 1738/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3210 - accuracy: 0.4814 - val_loss: 2.7733 - val_accuracy: 0.2533\n",
      "Epoch 1739/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3208 - accuracy: 0.4800 - val_loss: 2.7405 - val_accuracy: 0.2400\n",
      "Epoch 1740/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3207 - accuracy: 0.4829 - val_loss: 2.7729 - val_accuracy: 0.2500\n",
      "Epoch 1741/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3206 - accuracy: 0.4857 - val_loss: 2.7087 - val_accuracy: 0.2400\n",
      "Epoch 1742/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3199 - accuracy: 0.4843 - val_loss: 2.7658 - val_accuracy: 0.2500\n",
      "Epoch 1743/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3208 - accuracy: 0.4814 - val_loss: 2.7667 - val_accuracy: 0.2467\n",
      "Epoch 1744/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3204 - accuracy: 0.4771 - val_loss: 2.7543 - val_accuracy: 0.2467\n",
      "Epoch 1745/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3201 - accuracy: 0.4843 - val_loss: 2.7372 - val_accuracy: 0.2400\n",
      "Epoch 1746/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3205 - accuracy: 0.4786 - val_loss: 2.7724 - val_accuracy: 0.2500\n",
      "Epoch 1747/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3201 - accuracy: 0.4814 - val_loss: 2.7602 - val_accuracy: 0.2433\n",
      "Epoch 1748/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3194 - accuracy: 0.4743 - val_loss: 2.7610 - val_accuracy: 0.2400\n",
      "Epoch 1749/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3201 - accuracy: 0.4800 - val_loss: 2.7603 - val_accuracy: 0.2467\n",
      "Epoch 1750/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3192 - accuracy: 0.4814 - val_loss: 2.7131 - val_accuracy: 0.2433\n",
      "Epoch 1751/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3200 - accuracy: 0.4829 - val_loss: 2.7128 - val_accuracy: 0.2433\n",
      "Epoch 1752/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3188 - accuracy: 0.4800 - val_loss: 2.7201 - val_accuracy: 0.2433\n",
      "Epoch 1753/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3199 - accuracy: 0.4771 - val_loss: 2.7706 - val_accuracy: 0.2433\n",
      "Epoch 1754/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3200 - accuracy: 0.4843 - val_loss: 2.7730 - val_accuracy: 0.2433\n",
      "Epoch 1755/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3186 - accuracy: 0.4843 - val_loss: 2.7610 - val_accuracy: 0.2467\n",
      "Epoch 1756/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3196 - accuracy: 0.4771 - val_loss: 2.7295 - val_accuracy: 0.2433\n",
      "Epoch 1757/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3193 - accuracy: 0.4871 - val_loss: 2.7785 - val_accuracy: 0.2467\n",
      "Epoch 1758/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3192 - accuracy: 0.4857 - val_loss: 2.7427 - val_accuracy: 0.2433\n",
      "Epoch 1759/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3191 - accuracy: 0.4814 - val_loss: 2.8140 - val_accuracy: 0.2500\n",
      "Epoch 1760/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3197 - accuracy: 0.4843 - val_loss: 2.7251 - val_accuracy: 0.2467\n",
      "Epoch 1761/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3201 - accuracy: 0.4900 - val_loss: 2.7417 - val_accuracy: 0.2433\n",
      "Epoch 1762/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3190 - accuracy: 0.4814 - val_loss: 2.7799 - val_accuracy: 0.2433\n",
      "Epoch 1763/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3190 - accuracy: 0.4771 - val_loss: 2.7540 - val_accuracy: 0.2400\n",
      "Epoch 1764/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3179 - accuracy: 0.4857 - val_loss: 2.7600 - val_accuracy: 0.2433\n",
      "Epoch 1765/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3197 - accuracy: 0.4800 - val_loss: 2.7545 - val_accuracy: 0.2467\n",
      "Epoch 1766/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3186 - accuracy: 0.4800 - val_loss: 2.7405 - val_accuracy: 0.2433\n",
      "Epoch 1767/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3192 - accuracy: 0.4829 - val_loss: 2.7429 - val_accuracy: 0.2433\n",
      "Epoch 1768/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3189 - accuracy: 0.4843 - val_loss: 2.7533 - val_accuracy: 0.2433\n",
      "Epoch 1769/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3183 - accuracy: 0.4829 - val_loss: 2.7567 - val_accuracy: 0.2467\n",
      "Epoch 1770/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 97us/step - loss: 1.3190 - accuracy: 0.4929 - val_loss: 2.7751 - val_accuracy: 0.2467\n",
      "Epoch 1771/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3186 - accuracy: 0.4843 - val_loss: 2.7471 - val_accuracy: 0.2433\n",
      "Epoch 1772/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3185 - accuracy: 0.4814 - val_loss: 2.7740 - val_accuracy: 0.2467\n",
      "Epoch 1773/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3183 - accuracy: 0.4843 - val_loss: 2.7609 - val_accuracy: 0.2400\n",
      "Epoch 1774/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3187 - accuracy: 0.4900 - val_loss: 2.7597 - val_accuracy: 0.2467\n",
      "Epoch 1775/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3187 - accuracy: 0.4829 - val_loss: 2.7884 - val_accuracy: 0.2533\n",
      "Epoch 1776/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3193 - accuracy: 0.4800 - val_loss: 2.7104 - val_accuracy: 0.2433\n",
      "Epoch 1777/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3178 - accuracy: 0.4871 - val_loss: 2.7617 - val_accuracy: 0.2400\n",
      "Epoch 1778/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3177 - accuracy: 0.4829 - val_loss: 2.7374 - val_accuracy: 0.2400\n",
      "Epoch 1779/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3184 - accuracy: 0.4886 - val_loss: 2.7702 - val_accuracy: 0.2400\n",
      "Epoch 1780/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3184 - accuracy: 0.4814 - val_loss: 2.7890 - val_accuracy: 0.2467\n",
      "Epoch 1781/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3174 - accuracy: 0.4871 - val_loss: 2.7951 - val_accuracy: 0.2467\n",
      "Epoch 1782/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3183 - accuracy: 0.4814 - val_loss: 2.7286 - val_accuracy: 0.2400\n",
      "Epoch 1783/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3176 - accuracy: 0.4914 - val_loss: 2.7833 - val_accuracy: 0.2467\n",
      "Epoch 1784/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3174 - accuracy: 0.4829 - val_loss: 2.7522 - val_accuracy: 0.2367\n",
      "Epoch 1785/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3179 - accuracy: 0.4857 - val_loss: 2.7539 - val_accuracy: 0.2467\n",
      "Epoch 1786/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3182 - accuracy: 0.4843 - val_loss: 2.7619 - val_accuracy: 0.2433\n",
      "Epoch 1787/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3176 - accuracy: 0.4914 - val_loss: 2.7564 - val_accuracy: 0.2433\n",
      "Epoch 1788/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3180 - accuracy: 0.4829 - val_loss: 2.7652 - val_accuracy: 0.2400\n",
      "Epoch 1789/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3178 - accuracy: 0.4843 - val_loss: 2.7345 - val_accuracy: 0.2400\n",
      "Epoch 1790/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3175 - accuracy: 0.4857 - val_loss: 2.7287 - val_accuracy: 0.2400\n",
      "Epoch 1791/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3179 - accuracy: 0.4814 - val_loss: 2.7616 - val_accuracy: 0.2400\n",
      "Epoch 1792/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3168 - accuracy: 0.4814 - val_loss: 2.7972 - val_accuracy: 0.2467\n",
      "Epoch 1793/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3170 - accuracy: 0.4814 - val_loss: 2.7817 - val_accuracy: 0.2467\n",
      "Epoch 1794/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3168 - accuracy: 0.4857 - val_loss: 2.7729 - val_accuracy: 0.2433\n",
      "Epoch 1795/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3173 - accuracy: 0.4814 - val_loss: 2.7766 - val_accuracy: 0.2433\n",
      "Epoch 1796/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3167 - accuracy: 0.4814 - val_loss: 2.8113 - val_accuracy: 0.2533\n",
      "Epoch 1797/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3163 - accuracy: 0.4800 - val_loss: 2.7876 - val_accuracy: 0.2433\n",
      "Epoch 1798/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3176 - accuracy: 0.4871 - val_loss: 2.7636 - val_accuracy: 0.2433\n",
      "Epoch 1799/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3168 - accuracy: 0.4900 - val_loss: 2.8183 - val_accuracy: 0.2467\n",
      "Epoch 1800/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3170 - accuracy: 0.4843 - val_loss: 2.7988 - val_accuracy: 0.2467\n",
      "Epoch 1801/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3162 - accuracy: 0.4857 - val_loss: 2.7613 - val_accuracy: 0.2400\n",
      "Epoch 1802/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3164 - accuracy: 0.4857 - val_loss: 2.7926 - val_accuracy: 0.2467\n",
      "Epoch 1803/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3160 - accuracy: 0.4843 - val_loss: 2.7755 - val_accuracy: 0.2467\n",
      "Epoch 1804/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3167 - accuracy: 0.4886 - val_loss: 2.7658 - val_accuracy: 0.2433\n",
      "Epoch 1805/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3167 - accuracy: 0.4843 - val_loss: 2.7955 - val_accuracy: 0.2467\n",
      "Epoch 1806/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3164 - accuracy: 0.4814 - val_loss: 2.7665 - val_accuracy: 0.2400\n",
      "Epoch 1807/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3162 - accuracy: 0.4800 - val_loss: 2.7949 - val_accuracy: 0.2467\n",
      "Epoch 1808/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3157 - accuracy: 0.4771 - val_loss: 2.7954 - val_accuracy: 0.2500\n",
      "Epoch 1809/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3164 - accuracy: 0.4814 - val_loss: 2.7507 - val_accuracy: 0.2367\n",
      "Epoch 1810/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3163 - accuracy: 0.4843 - val_loss: 2.7758 - val_accuracy: 0.2400\n",
      "Epoch 1811/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3158 - accuracy: 0.4871 - val_loss: 2.7749 - val_accuracy: 0.2433\n",
      "Epoch 1812/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3160 - accuracy: 0.4829 - val_loss: 2.7721 - val_accuracy: 0.2467\n",
      "Epoch 1813/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3169 - accuracy: 0.4771 - val_loss: 2.7732 - val_accuracy: 0.2400\n",
      "Epoch 1814/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3167 - accuracy: 0.4771 - val_loss: 2.7828 - val_accuracy: 0.2467\n",
      "Epoch 1815/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3155 - accuracy: 0.4871 - val_loss: 2.7902 - val_accuracy: 0.2467\n",
      "Epoch 1816/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3148 - accuracy: 0.4857 - val_loss: 2.7706 - val_accuracy: 0.2400\n",
      "Epoch 1817/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3150 - accuracy: 0.4843 - val_loss: 2.7923 - val_accuracy: 0.2433\n",
      "Epoch 1818/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3162 - accuracy: 0.4800 - val_loss: 2.7727 - val_accuracy: 0.2400\n",
      "Epoch 1819/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3158 - accuracy: 0.4871 - val_loss: 2.7900 - val_accuracy: 0.2433\n",
      "Epoch 1820/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3166 - accuracy: 0.4829 - val_loss: 2.7606 - val_accuracy: 0.2400\n",
      "Epoch 1821/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3147 - accuracy: 0.4829 - val_loss: 2.8329 - val_accuracy: 0.2467\n",
      "Epoch 1822/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3144 - accuracy: 0.4857 - val_loss: 2.7680 - val_accuracy: 0.2467\n",
      "Epoch 1823/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3142 - accuracy: 0.4786 - val_loss: 2.8176 - val_accuracy: 0.2433\n",
      "Epoch 1824/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3154 - accuracy: 0.4829 - val_loss: 2.8274 - val_accuracy: 0.2500\n",
      "Epoch 1825/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 1.3146 - accuracy: 0.4814 - val_loss: 2.8094 - val_accuracy: 0.2500\n",
      "Epoch 1826/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3144 - accuracy: 0.4829 - val_loss: 2.7718 - val_accuracy: 0.2400\n",
      "Epoch 1827/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3151 - accuracy: 0.4857 - val_loss: 2.7812 - val_accuracy: 0.2433\n",
      "Epoch 1828/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3131 - accuracy: 0.4843 - val_loss: 2.7838 - val_accuracy: 0.2433\n",
      "Epoch 1829/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3153 - accuracy: 0.4800 - val_loss: 2.7718 - val_accuracy: 0.2433\n",
      "Epoch 1830/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3139 - accuracy: 0.4843 - val_loss: 2.7901 - val_accuracy: 0.2433\n",
      "Epoch 1831/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3138 - accuracy: 0.4871 - val_loss: 2.7782 - val_accuracy: 0.2400\n",
      "Epoch 1832/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3138 - accuracy: 0.4857 - val_loss: 2.7998 - val_accuracy: 0.2467\n",
      "Epoch 1833/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3136 - accuracy: 0.4843 - val_loss: 2.8160 - val_accuracy: 0.2433\n",
      "Epoch 1834/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3137 - accuracy: 0.4814 - val_loss: 2.8138 - val_accuracy: 0.2433\n",
      "Epoch 1835/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3134 - accuracy: 0.4871 - val_loss: 2.7999 - val_accuracy: 0.2433\n",
      "Epoch 1836/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3140 - accuracy: 0.4886 - val_loss: 2.7753 - val_accuracy: 0.2400\n",
      "Epoch 1837/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3136 - accuracy: 0.4843 - val_loss: 2.7887 - val_accuracy: 0.2400\n",
      "Epoch 1838/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3133 - accuracy: 0.4800 - val_loss: 2.7816 - val_accuracy: 0.2400\n",
      "Epoch 1839/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3124 - accuracy: 0.4900 - val_loss: 2.8309 - val_accuracy: 0.2467\n",
      "Epoch 1840/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3137 - accuracy: 0.4900 - val_loss: 2.7936 - val_accuracy: 0.2367\n",
      "Epoch 1841/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3119 - accuracy: 0.4843 - val_loss: 2.7613 - val_accuracy: 0.2433\n",
      "Epoch 1842/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3132 - accuracy: 0.4800 - val_loss: 2.8177 - val_accuracy: 0.2433\n",
      "Epoch 1843/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3129 - accuracy: 0.4857 - val_loss: 2.7970 - val_accuracy: 0.2367\n",
      "Epoch 1844/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3129 - accuracy: 0.4814 - val_loss: 2.8158 - val_accuracy: 0.2500\n",
      "Epoch 1845/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3125 - accuracy: 0.4829 - val_loss: 2.7741 - val_accuracy: 0.2400\n",
      "Epoch 1846/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3129 - accuracy: 0.4886 - val_loss: 2.8062 - val_accuracy: 0.2433\n",
      "Epoch 1847/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3133 - accuracy: 0.4943 - val_loss: 2.7454 - val_accuracy: 0.2467\n",
      "Epoch 1848/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3131 - accuracy: 0.4857 - val_loss: 2.8078 - val_accuracy: 0.2433\n",
      "Epoch 1849/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3129 - accuracy: 0.4886 - val_loss: 2.7887 - val_accuracy: 0.2400\n",
      "Epoch 1850/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3125 - accuracy: 0.4843 - val_loss: 2.8107 - val_accuracy: 0.2400\n",
      "Epoch 1851/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3125 - accuracy: 0.4871 - val_loss: 2.8048 - val_accuracy: 0.2433\n",
      "Epoch 1852/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3127 - accuracy: 0.4886 - val_loss: 2.8206 - val_accuracy: 0.2433\n",
      "Epoch 1853/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4141 - accuracy: 0.40 - 0s 92us/step - loss: 1.3130 - accuracy: 0.4857 - val_loss: 2.7899 - val_accuracy: 0.2400\n",
      "Epoch 1854/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3123 - accuracy: 0.4886 - val_loss: 2.7942 - val_accuracy: 0.2500\n",
      "Epoch 1855/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3122 - accuracy: 0.4857 - val_loss: 2.8018 - val_accuracy: 0.2467\n",
      "Epoch 1856/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3108 - accuracy: 0.4871 - val_loss: 2.7939 - val_accuracy: 0.2467\n",
      "Epoch 1857/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3127 - accuracy: 0.4857 - val_loss: 2.7873 - val_accuracy: 0.2400\n",
      "Epoch 1858/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3124 - accuracy: 0.4857 - val_loss: 2.8183 - val_accuracy: 0.2433\n",
      "Epoch 1859/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3116 - accuracy: 0.4857 - val_loss: 2.8009 - val_accuracy: 0.2367\n",
      "Epoch 1860/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3115 - accuracy: 0.4829 - val_loss: 2.8136 - val_accuracy: 0.2500\n",
      "Epoch 1861/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3121 - accuracy: 0.4957 - val_loss: 2.8175 - val_accuracy: 0.2433\n",
      "Epoch 1862/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3122 - accuracy: 0.4900 - val_loss: 2.7980 - val_accuracy: 0.2400\n",
      "Epoch 1863/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3121 - accuracy: 0.4886 - val_loss: 2.7967 - val_accuracy: 0.2400\n",
      "Epoch 1864/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3112 - accuracy: 0.4886 - val_loss: 2.8054 - val_accuracy: 0.2400\n",
      "Epoch 1865/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3112 - accuracy: 0.4886 - val_loss: 2.8361 - val_accuracy: 0.2467\n",
      "Epoch 1866/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3115 - accuracy: 0.4857 - val_loss: 2.8192 - val_accuracy: 0.2467\n",
      "Epoch 1867/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3118 - accuracy: 0.4886 - val_loss: 2.8251 - val_accuracy: 0.2433\n",
      "Epoch 1868/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3116 - accuracy: 0.4871 - val_loss: 2.8125 - val_accuracy: 0.2333\n",
      "Epoch 1869/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3108 - accuracy: 0.4929 - val_loss: 2.8443 - val_accuracy: 0.2500\n",
      "Epoch 1870/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3118 - accuracy: 0.4829 - val_loss: 2.7841 - val_accuracy: 0.2400\n",
      "Epoch 1871/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3113 - accuracy: 0.4829 - val_loss: 2.7913 - val_accuracy: 0.2400\n",
      "Epoch 1872/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3114 - accuracy: 0.4843 - val_loss: 2.7903 - val_accuracy: 0.2400\n",
      "Epoch 1873/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3111 - accuracy: 0.4871 - val_loss: 2.8482 - val_accuracy: 0.2467\n",
      "Epoch 1874/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3110 - accuracy: 0.4943 - val_loss: 2.8149 - val_accuracy: 0.2467\n",
      "Epoch 1875/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3110 - accuracy: 0.4971 - val_loss: 2.8357 - val_accuracy: 0.2467\n",
      "Epoch 1876/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3108 - accuracy: 0.4771 - val_loss: 2.8073 - val_accuracy: 0.2367\n",
      "Epoch 1877/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3113 - accuracy: 0.4843 - val_loss: 2.7962 - val_accuracy: 0.2467\n",
      "Epoch 1878/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3110 - accuracy: 0.4886 - val_loss: 2.8292 - val_accuracy: 0.2500\n",
      "Epoch 1879/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3105 - accuracy: 0.4886 - val_loss: 2.8224 - val_accuracy: 0.2400\n",
      "Epoch 1880/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 103us/step - loss: 1.3104 - accuracy: 0.4957 - val_loss: 2.8272 - val_accuracy: 0.2467\n",
      "Epoch 1881/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3104 - accuracy: 0.4900 - val_loss: 2.8498 - val_accuracy: 0.2467\n",
      "Epoch 1882/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3106 - accuracy: 0.4786 - val_loss: 2.7938 - val_accuracy: 0.2400\n",
      "Epoch 1883/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3107 - accuracy: 0.4843 - val_loss: 2.8107 - val_accuracy: 0.2433\n",
      "Epoch 1884/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3104 - accuracy: 0.4914 - val_loss: 2.8013 - val_accuracy: 0.2400\n",
      "Epoch 1885/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3099 - accuracy: 0.4857 - val_loss: 2.7881 - val_accuracy: 0.2433\n",
      "Epoch 1886/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3106 - accuracy: 0.4857 - val_loss: 2.8056 - val_accuracy: 0.2433\n",
      "Epoch 1887/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3101 - accuracy: 0.4886 - val_loss: 2.8165 - val_accuracy: 0.2400\n",
      "Epoch 1888/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3091 - accuracy: 0.4900 - val_loss: 2.8411 - val_accuracy: 0.2433\n",
      "Epoch 1889/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3106 - accuracy: 0.4886 - val_loss: 2.7948 - val_accuracy: 0.2467\n",
      "Epoch 1890/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3101 - accuracy: 0.4929 - val_loss: 2.8211 - val_accuracy: 0.2433\n",
      "Epoch 1891/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3102 - accuracy: 0.4900 - val_loss: 2.8212 - val_accuracy: 0.2433\n",
      "Epoch 1892/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3098 - accuracy: 0.4886 - val_loss: 2.8131 - val_accuracy: 0.2433\n",
      "Epoch 1893/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3093 - accuracy: 0.4843 - val_loss: 2.8456 - val_accuracy: 0.2500\n",
      "Epoch 1894/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3097 - accuracy: 0.4871 - val_loss: 2.8119 - val_accuracy: 0.2400\n",
      "Epoch 1895/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3099 - accuracy: 0.4914 - val_loss: 2.8029 - val_accuracy: 0.2433\n",
      "Epoch 1896/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3097 - accuracy: 0.4871 - val_loss: 2.8489 - val_accuracy: 0.2467\n",
      "Epoch 1897/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3096 - accuracy: 0.4914 - val_loss: 2.8088 - val_accuracy: 0.2467\n",
      "Epoch 1898/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3097 - accuracy: 0.4829 - val_loss: 2.7960 - val_accuracy: 0.2433\n",
      "Epoch 1899/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3095 - accuracy: 0.4871 - val_loss: 2.8084 - val_accuracy: 0.2500\n",
      "Epoch 1900/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3092 - accuracy: 0.4914 - val_loss: 2.8463 - val_accuracy: 0.2467\n",
      "Epoch 1901/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3096 - accuracy: 0.4843 - val_loss: 2.8045 - val_accuracy: 0.2433\n",
      "Epoch 1902/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3094 - accuracy: 0.4843 - val_loss: 2.8558 - val_accuracy: 0.2433\n",
      "Epoch 1903/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3084 - accuracy: 0.4886 - val_loss: 2.8097 - val_accuracy: 0.2433\n",
      "Epoch 1904/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3091 - accuracy: 0.4929 - val_loss: 2.8486 - val_accuracy: 0.2500\n",
      "Epoch 1905/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3096 - accuracy: 0.4871 - val_loss: 2.8503 - val_accuracy: 0.2467\n",
      "Epoch 1906/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3101 - accuracy: 0.4914 - val_loss: 2.8367 - val_accuracy: 0.2467\n",
      "Epoch 1907/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3085 - accuracy: 0.4886 - val_loss: 2.8391 - val_accuracy: 0.2500\n",
      "Epoch 1908/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3100 - accuracy: 0.4843 - val_loss: 2.8508 - val_accuracy: 0.2467\n",
      "Epoch 1909/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3083 - accuracy: 0.4829 - val_loss: 2.8309 - val_accuracy: 0.2400\n",
      "Epoch 1910/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3090 - accuracy: 0.4900 - val_loss: 2.8291 - val_accuracy: 0.2400\n",
      "Epoch 1911/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3083 - accuracy: 0.4986 - val_loss: 2.8184 - val_accuracy: 0.2367\n",
      "Epoch 1912/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3087 - accuracy: 0.4886 - val_loss: 2.8391 - val_accuracy: 0.2500\n",
      "Epoch 1913/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3084 - accuracy: 0.4900 - val_loss: 2.8394 - val_accuracy: 0.2400\n",
      "Epoch 1914/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3074 - accuracy: 0.4871 - val_loss: 2.8482 - val_accuracy: 0.2500\n",
      "Epoch 1915/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3086 - accuracy: 0.4857 - val_loss: 2.8231 - val_accuracy: 0.2433\n",
      "Epoch 1916/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3084 - accuracy: 0.4886 - val_loss: 2.8078 - val_accuracy: 0.2400\n",
      "Epoch 1917/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3087 - accuracy: 0.4871 - val_loss: 2.8301 - val_accuracy: 0.2500\n",
      "Epoch 1918/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3084 - accuracy: 0.4929 - val_loss: 2.8409 - val_accuracy: 0.2400\n",
      "Epoch 1919/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3081 - accuracy: 0.4886 - val_loss: 2.8454 - val_accuracy: 0.2400\n",
      "Epoch 1920/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3092 - accuracy: 0.4900 - val_loss: 2.8403 - val_accuracy: 0.2433\n",
      "Epoch 1921/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3079 - accuracy: 0.4929 - val_loss: 2.8347 - val_accuracy: 0.2433\n",
      "Epoch 1922/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3073 - accuracy: 0.4886 - val_loss: 2.8219 - val_accuracy: 0.2467\n",
      "Epoch 1923/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3081 - accuracy: 0.4957 - val_loss: 2.8438 - val_accuracy: 0.2433\n",
      "Epoch 1924/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3076 - accuracy: 0.4843 - val_loss: 2.8003 - val_accuracy: 0.2433\n",
      "Epoch 1925/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3076 - accuracy: 0.4929 - val_loss: 2.8544 - val_accuracy: 0.2400\n",
      "Epoch 1926/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3071 - accuracy: 0.4871 - val_loss: 2.8218 - val_accuracy: 0.2433\n",
      "Epoch 1927/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3075 - accuracy: 0.4914 - val_loss: 2.8277 - val_accuracy: 0.2467\n",
      "Epoch 1928/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3070 - accuracy: 0.4900 - val_loss: 2.8586 - val_accuracy: 0.2467\n",
      "Epoch 1929/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3079 - accuracy: 0.4929 - val_loss: 2.8490 - val_accuracy: 0.2433\n",
      "Epoch 1930/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3082 - accuracy: 0.4829 - val_loss: 2.8390 - val_accuracy: 0.2433\n",
      "Epoch 1931/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3078 - accuracy: 0.4929 - val_loss: 2.8290 - val_accuracy: 0.2400\n",
      "Epoch 1932/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3072 - accuracy: 0.4886 - val_loss: 2.8522 - val_accuracy: 0.2467\n",
      "Epoch 1933/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3068 - accuracy: 0.4929 - val_loss: 2.8398 - val_accuracy: 0.2467\n",
      "Epoch 1934/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3075 - accuracy: 0.4814 - val_loss: 2.8384 - val_accuracy: 0.2500\n",
      "Epoch 1935/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 88us/step - loss: 1.3069 - accuracy: 0.4914 - val_loss: 2.8372 - val_accuracy: 0.2467\n",
      "Epoch 1936/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3071 - accuracy: 0.4886 - val_loss: 2.8738 - val_accuracy: 0.2467\n",
      "Epoch 1937/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3067 - accuracy: 0.4957 - val_loss: 2.8457 - val_accuracy: 0.2467\n",
      "Epoch 1938/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3071 - accuracy: 0.4886 - val_loss: 2.8680 - val_accuracy: 0.2467\n",
      "Epoch 1939/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3071 - accuracy: 0.4929 - val_loss: 2.8414 - val_accuracy: 0.2467\n",
      "Epoch 1940/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3071 - accuracy: 0.4914 - val_loss: 2.8538 - val_accuracy: 0.2467\n",
      "Epoch 1941/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3066 - accuracy: 0.4857 - val_loss: 2.8291 - val_accuracy: 0.2467\n",
      "Epoch 1942/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3066 - accuracy: 0.4914 - val_loss: 2.8601 - val_accuracy: 0.2467\n",
      "Epoch 1943/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3066 - accuracy: 0.4900 - val_loss: 2.8644 - val_accuracy: 0.2467\n",
      "Epoch 1944/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3065 - accuracy: 0.4929 - val_loss: 2.8741 - val_accuracy: 0.2467\n",
      "Epoch 1945/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3064 - accuracy: 0.4929 - val_loss: 2.8441 - val_accuracy: 0.2400\n",
      "Epoch 1946/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3068 - accuracy: 0.4871 - val_loss: 2.8646 - val_accuracy: 0.2500\n",
      "Epoch 1947/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3073 - accuracy: 0.4857 - val_loss: 2.8327 - val_accuracy: 0.2467\n",
      "Epoch 1948/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3059 - accuracy: 0.4914 - val_loss: 2.8601 - val_accuracy: 0.2467\n",
      "Epoch 1949/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3074 - accuracy: 0.4900 - val_loss: 2.8628 - val_accuracy: 0.2433\n",
      "Epoch 1950/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3072 - accuracy: 0.4914 - val_loss: 2.8465 - val_accuracy: 0.2400\n",
      "Epoch 1951/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3056 - accuracy: 0.4857 - val_loss: 2.8831 - val_accuracy: 0.2500\n",
      "Epoch 1952/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3065 - accuracy: 0.4857 - val_loss: 2.8920 - val_accuracy: 0.2467\n",
      "Epoch 1953/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3060 - accuracy: 0.4871 - val_loss: 2.8458 - val_accuracy: 0.2467\n",
      "Epoch 1954/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3061 - accuracy: 0.4929 - val_loss: 2.8430 - val_accuracy: 0.2500\n",
      "Epoch 1955/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3063 - accuracy: 0.4886 - val_loss: 2.8634 - val_accuracy: 0.2433\n",
      "Epoch 1956/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3058 - accuracy: 0.4914 - val_loss: 2.8676 - val_accuracy: 0.2467\n",
      "Epoch 1957/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3057 - accuracy: 0.4886 - val_loss: 2.8187 - val_accuracy: 0.2433\n",
      "Epoch 1958/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3062 - accuracy: 0.4914 - val_loss: 2.8320 - val_accuracy: 0.2433\n",
      "Epoch 1959/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3057 - accuracy: 0.4943 - val_loss: 2.8322 - val_accuracy: 0.2433\n",
      "Epoch 1960/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3060 - accuracy: 0.4971 - val_loss: 2.8572 - val_accuracy: 0.2400\n",
      "Epoch 1961/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3058 - accuracy: 0.4843 - val_loss: 2.8839 - val_accuracy: 0.2467\n",
      "Epoch 1962/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3055 - accuracy: 0.4943 - val_loss: 2.8521 - val_accuracy: 0.2467\n",
      "Epoch 1963/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3049 - accuracy: 0.4900 - val_loss: 2.8646 - val_accuracy: 0.2467\n",
      "Epoch 1964/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3056 - accuracy: 0.4886 - val_loss: 2.8605 - val_accuracy: 0.2400\n",
      "Epoch 1965/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3054 - accuracy: 0.4829 - val_loss: 2.8708 - val_accuracy: 0.2467\n",
      "Epoch 1966/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3055 - accuracy: 0.4900 - val_loss: 2.8691 - val_accuracy: 0.2433\n",
      "Epoch 1967/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3053 - accuracy: 0.4929 - val_loss: 2.8624 - val_accuracy: 0.2433\n",
      "Epoch 1968/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3047 - accuracy: 0.4886 - val_loss: 2.8806 - val_accuracy: 0.2500\n",
      "Epoch 1969/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3059 - accuracy: 0.4943 - val_loss: 2.8855 - val_accuracy: 0.2467\n",
      "Epoch 1970/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3051 - accuracy: 0.4857 - val_loss: 2.8786 - val_accuracy: 0.2467\n",
      "Epoch 1971/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3051 - accuracy: 0.4914 - val_loss: 2.8770 - val_accuracy: 0.2467\n",
      "Epoch 1972/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3040 - accuracy: 0.4900 - val_loss: 2.8643 - val_accuracy: 0.2433\n",
      "Epoch 1973/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3055 - accuracy: 0.4971 - val_loss: 2.8736 - val_accuracy: 0.2467\n",
      "Epoch 1974/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3048 - accuracy: 0.4929 - val_loss: 2.8328 - val_accuracy: 0.2433\n",
      "Epoch 1975/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3050 - accuracy: 0.4929 - val_loss: 2.8568 - val_accuracy: 0.2500\n",
      "Epoch 1976/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3051 - accuracy: 0.4857 - val_loss: 2.8777 - val_accuracy: 0.2467\n",
      "Epoch 1977/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3049 - accuracy: 0.4914 - val_loss: 2.8717 - val_accuracy: 0.2433\n",
      "Epoch 1978/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3052 - accuracy: 0.4943 - val_loss: 2.8666 - val_accuracy: 0.2433\n",
      "Epoch 1979/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3040 - accuracy: 0.4943 - val_loss: 2.8949 - val_accuracy: 0.2467\n",
      "Epoch 1980/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3033 - accuracy: 0.4900 - val_loss: 2.8520 - val_accuracy: 0.2467\n",
      "Epoch 1981/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3044 - accuracy: 0.4900 - val_loss: 2.8652 - val_accuracy: 0.2433\n",
      "Epoch 1982/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3043 - accuracy: 0.4900 - val_loss: 2.8490 - val_accuracy: 0.2500\n",
      "Epoch 1983/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3045 - accuracy: 0.4886 - val_loss: 2.8584 - val_accuracy: 0.2467\n",
      "Epoch 1984/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3045 - accuracy: 0.4943 - val_loss: 2.8657 - val_accuracy: 0.2433\n",
      "Epoch 1985/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3039 - accuracy: 0.4957 - val_loss: 2.8935 - val_accuracy: 0.2467\n",
      "Epoch 1986/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3048 - accuracy: 0.4886 - val_loss: 2.8810 - val_accuracy: 0.2433\n",
      "Epoch 1987/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3042 - accuracy: 0.4957 - val_loss: 2.8605 - val_accuracy: 0.2500\n",
      "Epoch 1988/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3054 - accuracy: 0.4886 - val_loss: 2.9012 - val_accuracy: 0.2467\n",
      "Epoch 1989/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3043 - accuracy: 0.4986 - val_loss: 2.8706 - val_accuracy: 0.2433\n",
      "Epoch 1990/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 1.3037 - accuracy: 0.4857 - val_loss: 2.8657 - val_accuracy: 0.2433\n",
      "Epoch 1991/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3039 - accuracy: 0.4957 - val_loss: 2.8685 - val_accuracy: 0.2433\n",
      "Epoch 1992/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3033 - accuracy: 0.4871 - val_loss: 2.9042 - val_accuracy: 0.2533\n",
      "Epoch 1993/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3037 - accuracy: 0.4914 - val_loss: 2.8293 - val_accuracy: 0.2500\n",
      "Epoch 1994/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3043 - accuracy: 0.4929 - val_loss: 2.8735 - val_accuracy: 0.2467\n",
      "Epoch 1995/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3036 - accuracy: 0.4886 - val_loss: 2.8896 - val_accuracy: 0.2467\n",
      "Epoch 1996/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3034 - accuracy: 0.4914 - val_loss: 2.8969 - val_accuracy: 0.2467\n",
      "Epoch 1997/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3035 - accuracy: 0.4914 - val_loss: 2.8496 - val_accuracy: 0.2433\n",
      "Epoch 1998/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3031 - accuracy: 0.4914 - val_loss: 2.9240 - val_accuracy: 0.2433\n",
      "Epoch 1999/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3040 - accuracy: 0.4900 - val_loss: 2.9074 - val_accuracy: 0.2467\n",
      "Epoch 2000/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3034 - accuracy: 0.4914 - val_loss: 2.8850 - val_accuracy: 0.2467\n",
      "Epoch 2001/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3033 - accuracy: 0.4900 - val_loss: 2.8375 - val_accuracy: 0.2433\n",
      "Epoch 2002/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3039 - accuracy: 0.4914 - val_loss: 2.8816 - val_accuracy: 0.2433\n",
      "Epoch 2003/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3038 - accuracy: 0.4886 - val_loss: 2.9124 - val_accuracy: 0.2433\n",
      "Epoch 2004/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3034 - accuracy: 0.4857 - val_loss: 2.8708 - val_accuracy: 0.2433\n",
      "Epoch 2005/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3029 - accuracy: 0.4900 - val_loss: 2.8974 - val_accuracy: 0.2467\n",
      "Epoch 2006/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3026 - accuracy: 0.4871 - val_loss: 2.9059 - val_accuracy: 0.2467\n",
      "Epoch 2007/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3022 - accuracy: 0.4943 - val_loss: 2.8725 - val_accuracy: 0.2400\n",
      "Epoch 2008/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3024 - accuracy: 0.4914 - val_loss: 2.9234 - val_accuracy: 0.2500\n",
      "Epoch 2009/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3035 - accuracy: 0.4929 - val_loss: 2.8806 - val_accuracy: 0.2400\n",
      "Epoch 2010/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3025 - accuracy: 0.4900 - val_loss: 2.8812 - val_accuracy: 0.2467\n",
      "Epoch 2011/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3033 - accuracy: 0.4943 - val_loss: 2.9064 - val_accuracy: 0.2500\n",
      "Epoch 2012/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3027 - accuracy: 0.4886 - val_loss: 2.8612 - val_accuracy: 0.2467\n",
      "Epoch 2013/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3023 - accuracy: 0.4929 - val_loss: 2.8897 - val_accuracy: 0.2433\n",
      "Epoch 2014/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3021 - accuracy: 0.4971 - val_loss: 2.9538 - val_accuracy: 0.2433\n",
      "Epoch 2015/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3021 - accuracy: 0.4929 - val_loss: 2.8762 - val_accuracy: 0.2467\n",
      "Epoch 2016/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3024 - accuracy: 0.4900 - val_loss: 2.9218 - val_accuracy: 0.2467\n",
      "Epoch 2017/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3022 - accuracy: 0.4957 - val_loss: 2.8549 - val_accuracy: 0.2367\n",
      "Epoch 2018/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3023 - accuracy: 0.4900 - val_loss: 2.9003 - val_accuracy: 0.2467\n",
      "Epoch 2019/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3026 - accuracy: 0.4871 - val_loss: 2.8540 - val_accuracy: 0.2433\n",
      "Epoch 2020/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3025 - accuracy: 0.4943 - val_loss: 2.9057 - val_accuracy: 0.2467\n",
      "Epoch 2021/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3021 - accuracy: 0.4986 - val_loss: 2.9067 - val_accuracy: 0.2467\n",
      "Epoch 2022/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3027 - accuracy: 0.4929 - val_loss: 2.8875 - val_accuracy: 0.2433\n",
      "Epoch 2023/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3020 - accuracy: 0.4943 - val_loss: 2.8703 - val_accuracy: 0.2467\n",
      "Epoch 2024/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3024 - accuracy: 0.4914 - val_loss: 2.9283 - val_accuracy: 0.2433\n",
      "Epoch 2025/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3024 - accuracy: 0.4943 - val_loss: 2.9028 - val_accuracy: 0.2467\n",
      "Epoch 2026/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3018 - accuracy: 0.4971 - val_loss: 2.8720 - val_accuracy: 0.2433\n",
      "Epoch 2027/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3022 - accuracy: 0.4971 - val_loss: 2.8811 - val_accuracy: 0.2400\n",
      "Epoch 2028/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3016 - accuracy: 0.4929 - val_loss: 2.9233 - val_accuracy: 0.2467\n",
      "Epoch 2029/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3013 - accuracy: 0.4971 - val_loss: 2.8877 - val_accuracy: 0.2400\n",
      "Epoch 2030/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3011 - accuracy: 0.4957 - val_loss: 2.9335 - val_accuracy: 0.2433\n",
      "Epoch 2031/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3013 - accuracy: 0.4914 - val_loss: 2.8518 - val_accuracy: 0.2433\n",
      "Epoch 2032/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3018 - accuracy: 0.4929 - val_loss: 2.8966 - val_accuracy: 0.2467\n",
      "Epoch 2033/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3014 - accuracy: 0.4957 - val_loss: 2.9316 - val_accuracy: 0.2467\n",
      "Epoch 2034/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3018 - accuracy: 0.4843 - val_loss: 2.8761 - val_accuracy: 0.2467\n",
      "Epoch 2035/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3012 - accuracy: 0.4943 - val_loss: 2.8715 - val_accuracy: 0.2433\n",
      "Epoch 2036/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3017 - accuracy: 0.4900 - val_loss: 2.8901 - val_accuracy: 0.2500\n",
      "Epoch 2037/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3005 - accuracy: 0.4957 - val_loss: 2.8875 - val_accuracy: 0.2467\n",
      "Epoch 2038/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3009 - accuracy: 0.4914 - val_loss: 2.8858 - val_accuracy: 0.2433\n",
      "Epoch 2039/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3018 - accuracy: 0.4986 - val_loss: 2.9216 - val_accuracy: 0.2500\n",
      "Epoch 2040/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3015 - accuracy: 0.4929 - val_loss: 2.9108 - val_accuracy: 0.2467\n",
      "Epoch 2041/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3005 - accuracy: 0.4943 - val_loss: 2.9133 - val_accuracy: 0.2467\n",
      "Epoch 2042/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3011 - accuracy: 0.4957 - val_loss: 2.9282 - val_accuracy: 0.2467\n",
      "Epoch 2043/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3007 - accuracy: 0.4914 - val_loss: 2.9261 - val_accuracy: 0.2467\n",
      "Epoch 2044/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3010 - accuracy: 0.4914 - val_loss: 2.9057 - val_accuracy: 0.2500\n",
      "Epoch 2045/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 1.3015 - accuracy: 0.4957 - val_loss: 2.9395 - val_accuracy: 0.2433\n",
      "Epoch 2046/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3007 - accuracy: 0.4971 - val_loss: 2.8818 - val_accuracy: 0.2467\n",
      "Epoch 2047/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3000 - accuracy: 0.4929 - val_loss: 2.9029 - val_accuracy: 0.2500\n",
      "Epoch 2048/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3000 - accuracy: 0.4943 - val_loss: 2.8693 - val_accuracy: 0.2433\n",
      "Epoch 2049/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3026 - accuracy: 0.4929 - val_loss: 2.9239 - val_accuracy: 0.2467\n",
      "Epoch 2050/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3009 - accuracy: 0.4900 - val_loss: 2.9248 - val_accuracy: 0.2433\n",
      "Epoch 2051/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3010 - accuracy: 0.4929 - val_loss: 2.8964 - val_accuracy: 0.2400\n",
      "Epoch 2052/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3012 - accuracy: 0.4943 - val_loss: 2.8942 - val_accuracy: 0.2433\n",
      "Epoch 2053/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3008 - accuracy: 0.4900 - val_loss: 2.8887 - val_accuracy: 0.2400\n",
      "Epoch 2054/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3000 - accuracy: 0.4971 - val_loss: 2.9069 - val_accuracy: 0.2433\n",
      "Epoch 2055/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3011 - accuracy: 0.4943 - val_loss: 2.8985 - val_accuracy: 0.2400\n",
      "Epoch 2056/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2995 - accuracy: 0.4986 - val_loss: 2.9264 - val_accuracy: 0.2433\n",
      "Epoch 2057/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3007 - accuracy: 0.4900 - val_loss: 2.9170 - val_accuracy: 0.2467\n",
      "Epoch 2058/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2994 - accuracy: 0.4971 - val_loss: 2.9365 - val_accuracy: 0.2467\n",
      "Epoch 2059/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3001 - accuracy: 0.4929 - val_loss: 2.9158 - val_accuracy: 0.2467\n",
      "Epoch 2060/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2999 - accuracy: 0.4929 - val_loss: 2.9154 - val_accuracy: 0.2467\n",
      "Epoch 2061/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2998 - accuracy: 0.4900 - val_loss: 2.9118 - val_accuracy: 0.2467\n",
      "Epoch 2062/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3000 - accuracy: 0.4914 - val_loss: 2.9181 - val_accuracy: 0.2467\n",
      "Epoch 2063/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2993 - accuracy: 0.4943 - val_loss: 2.9160 - val_accuracy: 0.2467\n",
      "Epoch 2064/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2996 - accuracy: 0.4886 - val_loss: 2.9179 - val_accuracy: 0.2467\n",
      "Epoch 2065/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2999 - accuracy: 0.4943 - val_loss: 2.9116 - val_accuracy: 0.2467\n",
      "Epoch 2066/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2999 - accuracy: 0.4971 - val_loss: 2.9345 - val_accuracy: 0.2433\n",
      "Epoch 2067/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2997 - accuracy: 0.4943 - val_loss: 2.9195 - val_accuracy: 0.2500\n",
      "Epoch 2068/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2996 - accuracy: 0.4929 - val_loss: 2.9196 - val_accuracy: 0.2433\n",
      "Epoch 2069/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2989 - accuracy: 0.4986 - val_loss: 2.9798 - val_accuracy: 0.2467\n",
      "Epoch 2070/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2995 - accuracy: 0.4929 - val_loss: 2.9306 - val_accuracy: 0.2467\n",
      "Epoch 2071/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2994 - accuracy: 0.4929 - val_loss: 2.9406 - val_accuracy: 0.2433\n",
      "Epoch 2072/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2995 - accuracy: 0.4914 - val_loss: 2.9463 - val_accuracy: 0.2433\n",
      "Epoch 2073/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2994 - accuracy: 0.4857 - val_loss: 2.9272 - val_accuracy: 0.2500\n",
      "Epoch 2074/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.2990 - accuracy: 0.4971 - val_loss: 2.9164 - val_accuracy: 0.2467\n",
      "Epoch 2075/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2994 - accuracy: 0.4943 - val_loss: 2.9045 - val_accuracy: 0.2467\n",
      "Epoch 2076/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2993 - accuracy: 0.4900 - val_loss: 2.9156 - val_accuracy: 0.2433\n",
      "Epoch 2077/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2988 - accuracy: 0.4929 - val_loss: 2.9379 - val_accuracy: 0.2467\n",
      "Epoch 2078/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2990 - accuracy: 0.4914 - val_loss: 2.9233 - val_accuracy: 0.2400\n",
      "Epoch 2079/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2988 - accuracy: 0.4929 - val_loss: 2.9485 - val_accuracy: 0.2400\n",
      "Epoch 2080/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2992 - accuracy: 0.4943 - val_loss: 2.9444 - val_accuracy: 0.2433\n",
      "Epoch 2081/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2999 - accuracy: 0.4957 - val_loss: 2.9589 - val_accuracy: 0.2467\n",
      "Epoch 2082/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2988 - accuracy: 0.4857 - val_loss: 2.8897 - val_accuracy: 0.2367\n",
      "Epoch 2083/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2994 - accuracy: 0.4943 - val_loss: 2.9204 - val_accuracy: 0.2467\n",
      "Epoch 2084/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2980 - accuracy: 0.4943 - val_loss: 2.9091 - val_accuracy: 0.2533\n",
      "Epoch 2085/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2987 - accuracy: 0.4929 - val_loss: 2.8924 - val_accuracy: 0.2400\n",
      "Epoch 2086/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2982 - accuracy: 0.4914 - val_loss: 2.9158 - val_accuracy: 0.2467\n",
      "Epoch 2087/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2988 - accuracy: 0.4971 - val_loss: 2.9633 - val_accuracy: 0.2500\n",
      "Epoch 2088/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2989 - accuracy: 0.4943 - val_loss: 2.9321 - val_accuracy: 0.2433\n",
      "Epoch 2089/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2991 - accuracy: 0.4914 - val_loss: 2.9388 - val_accuracy: 0.2467\n",
      "Epoch 2090/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2979 - accuracy: 0.4943 - val_loss: 2.9819 - val_accuracy: 0.2433\n",
      "Epoch 2091/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2980 - accuracy: 0.4929 - val_loss: 2.9268 - val_accuracy: 0.2467\n",
      "Epoch 2092/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2981 - accuracy: 0.4943 - val_loss: 2.9507 - val_accuracy: 0.2467\n",
      "Epoch 2093/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2984 - accuracy: 0.4886 - val_loss: 2.9404 - val_accuracy: 0.2467\n",
      "Epoch 2094/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2987 - accuracy: 0.4943 - val_loss: 2.9301 - val_accuracy: 0.2433\n",
      "Epoch 2095/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2974 - accuracy: 0.4971 - val_loss: 2.9619 - val_accuracy: 0.2467\n",
      "Epoch 2096/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2979 - accuracy: 0.4914 - val_loss: 2.9437 - val_accuracy: 0.2467\n",
      "Epoch 2097/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2974 - accuracy: 0.4929 - val_loss: 2.9237 - val_accuracy: 0.2467\n",
      "Epoch 2098/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2968 - accuracy: 0.4943 - val_loss: 2.9134 - val_accuracy: 0.2433\n",
      "Epoch 2099/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2982 - accuracy: 0.4929 - val_loss: 2.9367 - val_accuracy: 0.2467\n",
      "Epoch 2100/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 1.2977 - accuracy: 0.4943 - val_loss: 2.9300 - val_accuracy: 0.2433\n",
      "Epoch 2101/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2982 - accuracy: 0.5000 - val_loss: 2.9465 - val_accuracy: 0.2467\n",
      "Epoch 2102/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2982 - accuracy: 0.4957 - val_loss: 2.9457 - val_accuracy: 0.2433\n",
      "Epoch 2103/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2974 - accuracy: 0.4957 - val_loss: 2.9532 - val_accuracy: 0.2467\n",
      "Epoch 2104/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2977 - accuracy: 0.4971 - val_loss: 2.9145 - val_accuracy: 0.2467\n",
      "Epoch 2105/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2971 - accuracy: 0.4900 - val_loss: 2.9387 - val_accuracy: 0.2500\n",
      "Epoch 2106/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2978 - accuracy: 0.4957 - val_loss: 2.9099 - val_accuracy: 0.2467\n",
      "Epoch 2107/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2973 - accuracy: 0.4900 - val_loss: 2.9215 - val_accuracy: 0.2433\n",
      "Epoch 2108/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2976 - accuracy: 0.4943 - val_loss: 2.9449 - val_accuracy: 0.2467\n",
      "Epoch 2109/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2976 - accuracy: 0.4914 - val_loss: 2.9393 - val_accuracy: 0.2500\n",
      "Epoch 2110/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2986 - accuracy: 0.4971 - val_loss: 2.9343 - val_accuracy: 0.2433\n",
      "Epoch 2111/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2983 - accuracy: 0.4900 - val_loss: 2.9255 - val_accuracy: 0.2433\n",
      "Epoch 2112/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2969 - accuracy: 0.4914 - val_loss: 2.9790 - val_accuracy: 0.2433\n",
      "Epoch 2113/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2976 - accuracy: 0.4943 - val_loss: 2.9396 - val_accuracy: 0.2467\n",
      "Epoch 2114/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2966 - accuracy: 0.4957 - val_loss: 2.9319 - val_accuracy: 0.2433\n",
      "Epoch 2115/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2973 - accuracy: 0.4957 - val_loss: 2.9676 - val_accuracy: 0.2400\n",
      "Epoch 2116/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2970 - accuracy: 0.4986 - val_loss: 2.9529 - val_accuracy: 0.2467\n",
      "Epoch 2117/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2973 - accuracy: 0.4957 - val_loss: 2.9742 - val_accuracy: 0.2467\n",
      "Epoch 2118/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2965 - accuracy: 0.4943 - val_loss: 2.9443 - val_accuracy: 0.2467\n",
      "Epoch 2119/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2968 - accuracy: 0.4929 - val_loss: 2.9473 - val_accuracy: 0.2467\n",
      "Epoch 2120/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2965 - accuracy: 0.4957 - val_loss: 2.9546 - val_accuracy: 0.2467\n",
      "Epoch 2121/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2965 - accuracy: 0.4986 - val_loss: 2.9825 - val_accuracy: 0.2400\n",
      "Epoch 2122/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2968 - accuracy: 0.4971 - val_loss: 2.9642 - val_accuracy: 0.2433\n",
      "Epoch 2123/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2964 - accuracy: 0.4971 - val_loss: 2.9346 - val_accuracy: 0.2433\n",
      "Epoch 2124/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2967 - accuracy: 0.4957 - val_loss: 2.9504 - val_accuracy: 0.2467\n",
      "Epoch 2125/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2961 - accuracy: 0.4986 - val_loss: 2.9483 - val_accuracy: 0.2433\n",
      "Epoch 2126/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2971 - accuracy: 0.4943 - val_loss: 2.9473 - val_accuracy: 0.2433\n",
      "Epoch 2127/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2966 - accuracy: 0.4914 - val_loss: 2.9366 - val_accuracy: 0.2400\n",
      "Epoch 2128/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2964 - accuracy: 0.4971 - val_loss: 2.9706 - val_accuracy: 0.2433\n",
      "Epoch 2129/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2964 - accuracy: 0.4871 - val_loss: 2.9183 - val_accuracy: 0.2433\n",
      "Epoch 2130/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2965 - accuracy: 0.5000 - val_loss: 2.9546 - val_accuracy: 0.2400\n",
      "Epoch 2131/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2964 - accuracy: 0.4914 - val_loss: 2.9450 - val_accuracy: 0.2467\n",
      "Epoch 2132/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2969 - accuracy: 0.4943 - val_loss: 2.9399 - val_accuracy: 0.2400\n",
      "Epoch 2133/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2960 - accuracy: 0.4943 - val_loss: 2.9527 - val_accuracy: 0.2500\n",
      "Epoch 2134/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2963 - accuracy: 0.5000 - val_loss: 2.9459 - val_accuracy: 0.2433\n",
      "Epoch 2135/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2956 - accuracy: 0.4943 - val_loss: 2.9504 - val_accuracy: 0.2467\n",
      "Epoch 2136/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2964 - accuracy: 0.4914 - val_loss: 2.9276 - val_accuracy: 0.2433\n",
      "Epoch 2137/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2958 - accuracy: 0.4986 - val_loss: 2.9637 - val_accuracy: 0.2433\n",
      "Epoch 2138/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2973 - accuracy: 0.4914 - val_loss: 2.9705 - val_accuracy: 0.2467\n",
      "Epoch 2139/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2959 - accuracy: 0.5014 - val_loss: 2.9424 - val_accuracy: 0.2467\n",
      "Epoch 2140/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2955 - accuracy: 0.4914 - val_loss: 2.9643 - val_accuracy: 0.2433\n",
      "Epoch 2141/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2966 - accuracy: 0.4943 - val_loss: 2.9626 - val_accuracy: 0.2467\n",
      "Epoch 2142/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2956 - accuracy: 0.4943 - val_loss: 2.9579 - val_accuracy: 0.2467\n",
      "Epoch 2143/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2959 - accuracy: 0.4957 - val_loss: 2.9831 - val_accuracy: 0.2433\n",
      "Epoch 2144/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2957 - accuracy: 0.4957 - val_loss: 2.9599 - val_accuracy: 0.2467\n",
      "Epoch 2145/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2950 - accuracy: 0.4914 - val_loss: 2.9394 - val_accuracy: 0.2500\n",
      "Epoch 2146/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2946 - accuracy: 0.4914 - val_loss: 2.9126 - val_accuracy: 0.2467\n",
      "Epoch 2147/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2953 - accuracy: 0.5014 - val_loss: 2.9672 - val_accuracy: 0.2433\n",
      "Epoch 2148/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2964 - accuracy: 0.4857 - val_loss: 2.9567 - val_accuracy: 0.2467\n",
      "Epoch 2149/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2947 - accuracy: 0.5000 - val_loss: 2.9089 - val_accuracy: 0.2467\n",
      "Epoch 2150/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2951 - accuracy: 0.4929 - val_loss: 2.9311 - val_accuracy: 0.2533\n",
      "Epoch 2151/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2954 - accuracy: 0.4929 - val_loss: 2.9897 - val_accuracy: 0.2367\n",
      "Epoch 2152/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2947 - accuracy: 0.4914 - val_loss: 2.9873 - val_accuracy: 0.2467\n",
      "Epoch 2153/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2953 - accuracy: 0.4943 - val_loss: 2.9586 - val_accuracy: 0.2467\n",
      "Epoch 2154/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2949 - accuracy: 0.4957 - val_loss: 2.9991 - val_accuracy: 0.2367\n",
      "Epoch 2155/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 84us/step - loss: 1.2951 - accuracy: 0.4971 - val_loss: 2.9910 - val_accuracy: 0.2433\n",
      "Epoch 2156/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2943 - accuracy: 0.4986 - val_loss: 2.9977 - val_accuracy: 0.2433\n",
      "Epoch 2157/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2946 - accuracy: 0.4871 - val_loss: 2.9287 - val_accuracy: 0.2467\n",
      "Epoch 2158/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2944 - accuracy: 0.4971 - val_loss: 3.0044 - val_accuracy: 0.2433\n",
      "Epoch 2159/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2942 - accuracy: 0.4971 - val_loss: 2.9445 - val_accuracy: 0.2467\n",
      "Epoch 2160/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2951 - accuracy: 0.4943 - val_loss: 2.9919 - val_accuracy: 0.2467\n",
      "Epoch 2161/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2946 - accuracy: 0.5014 - val_loss: 2.9727 - val_accuracy: 0.2467\n",
      "Epoch 2162/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2941 - accuracy: 0.4929 - val_loss: 2.9620 - val_accuracy: 0.2400\n",
      "Epoch 2163/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2946 - accuracy: 0.4914 - val_loss: 2.9412 - val_accuracy: 0.2433\n",
      "Epoch 2164/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2953 - accuracy: 0.4986 - val_loss: 2.9747 - val_accuracy: 0.2467\n",
      "Epoch 2165/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2945 - accuracy: 0.4914 - val_loss: 2.9616 - val_accuracy: 0.2500\n",
      "Epoch 2166/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2949 - accuracy: 0.4957 - val_loss: 2.9696 - val_accuracy: 0.2467\n",
      "Epoch 2167/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2942 - accuracy: 0.4943 - val_loss: 2.9640 - val_accuracy: 0.2467\n",
      "Epoch 2168/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2945 - accuracy: 0.5014 - val_loss: 2.9832 - val_accuracy: 0.2433\n",
      "Epoch 2169/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2940 - accuracy: 0.4957 - val_loss: 2.9874 - val_accuracy: 0.2500\n",
      "Epoch 2170/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2939 - accuracy: 0.5000 - val_loss: 2.9851 - val_accuracy: 0.2433\n",
      "Epoch 2171/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2935 - accuracy: 0.5000 - val_loss: 2.9433 - val_accuracy: 0.2533\n",
      "Epoch 2172/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2937 - accuracy: 0.4971 - val_loss: 3.0003 - val_accuracy: 0.2467\n",
      "Epoch 2173/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2931 - accuracy: 0.4971 - val_loss: 2.9833 - val_accuracy: 0.2467\n",
      "Epoch 2174/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2940 - accuracy: 0.5014 - val_loss: 2.9685 - val_accuracy: 0.2400\n",
      "Epoch 2175/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2931 - accuracy: 0.4914 - val_loss: 2.9362 - val_accuracy: 0.2500\n",
      "Epoch 2176/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2936 - accuracy: 0.4957 - val_loss: 2.9328 - val_accuracy: 0.2467\n",
      "Epoch 2177/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2940 - accuracy: 0.4957 - val_loss: 2.9792 - val_accuracy: 0.2533\n",
      "Epoch 2178/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2939 - accuracy: 0.4957 - val_loss: 2.9736 - val_accuracy: 0.2467\n",
      "Epoch 2179/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2930 - accuracy: 0.4986 - val_loss: 2.9691 - val_accuracy: 0.2467\n",
      "Epoch 2180/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2945 - accuracy: 0.4886 - val_loss: 2.9722 - val_accuracy: 0.2467\n",
      "Epoch 2181/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2933 - accuracy: 0.5000 - val_loss: 2.9766 - val_accuracy: 0.2367\n",
      "Epoch 2182/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2934 - accuracy: 0.4971 - val_loss: 2.9911 - val_accuracy: 0.2433\n",
      "Epoch 2183/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2932 - accuracy: 0.4971 - val_loss: 3.0172 - val_accuracy: 0.2433\n",
      "Epoch 2184/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2942 - accuracy: 0.4957 - val_loss: 2.9783 - val_accuracy: 0.2500\n",
      "Epoch 2185/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2927 - accuracy: 0.4929 - val_loss: 2.9729 - val_accuracy: 0.2433\n",
      "Epoch 2186/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2939 - accuracy: 0.4957 - val_loss: 2.9794 - val_accuracy: 0.2533\n",
      "Epoch 2187/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2933 - accuracy: 0.5014 - val_loss: 2.9947 - val_accuracy: 0.2467\n",
      "Epoch 2188/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2945 - accuracy: 0.4986 - val_loss: 3.0096 - val_accuracy: 0.2433\n",
      "Epoch 2189/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2932 - accuracy: 0.4914 - val_loss: 3.0249 - val_accuracy: 0.2433\n",
      "Epoch 2190/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2924 - accuracy: 0.4957 - val_loss: 2.9966 - val_accuracy: 0.2400\n",
      "Epoch 2191/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2927 - accuracy: 0.4900 - val_loss: 2.9930 - val_accuracy: 0.2400\n",
      "Epoch 2192/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2929 - accuracy: 0.4986 - val_loss: 2.9564 - val_accuracy: 0.2433\n",
      "Epoch 2193/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2929 - accuracy: 0.5000 - val_loss: 2.9775 - val_accuracy: 0.2400\n",
      "Epoch 2194/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2934 - accuracy: 0.4986 - val_loss: 3.0012 - val_accuracy: 0.2433\n",
      "Epoch 2195/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2925 - accuracy: 0.4929 - val_loss: 2.9939 - val_accuracy: 0.2433\n",
      "Epoch 2196/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2931 - accuracy: 0.5000 - val_loss: 3.0017 - val_accuracy: 0.2467\n",
      "Epoch 2197/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2928 - accuracy: 0.5014 - val_loss: 2.9959 - val_accuracy: 0.2467\n",
      "Epoch 2198/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2929 - accuracy: 0.4943 - val_loss: 2.9731 - val_accuracy: 0.2433\n",
      "Epoch 2199/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2930 - accuracy: 0.5014 - val_loss: 3.0075 - val_accuracy: 0.2433\n",
      "Epoch 2200/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2931 - accuracy: 0.4957 - val_loss: 2.9801 - val_accuracy: 0.2400\n",
      "Epoch 2201/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2926 - accuracy: 0.4971 - val_loss: 3.0237 - val_accuracy: 0.2500\n",
      "Epoch 2202/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2908 - accuracy: 0.4957 - val_loss: 2.9923 - val_accuracy: 0.2500\n",
      "Epoch 2203/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2929 - accuracy: 0.4929 - val_loss: 3.0029 - val_accuracy: 0.2433\n",
      "Epoch 2204/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2920 - accuracy: 0.4943 - val_loss: 2.9536 - val_accuracy: 0.2367\n",
      "Epoch 2205/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2919 - accuracy: 0.4957 - val_loss: 3.0053 - val_accuracy: 0.2433\n",
      "Epoch 2206/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2924 - accuracy: 0.4971 - val_loss: 2.9827 - val_accuracy: 0.2467\n",
      "Epoch 2207/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2921 - accuracy: 0.4957 - val_loss: 3.0116 - val_accuracy: 0.2433\n",
      "Epoch 2208/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2923 - accuracy: 0.5014 - val_loss: 2.9527 - val_accuracy: 0.2400\n",
      "Epoch 2209/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2917 - accuracy: 0.4943 - val_loss: 2.9438 - val_accuracy: 0.2533\n",
      "Epoch 2210/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 80us/step - loss: 1.2926 - accuracy: 0.4914 - val_loss: 2.9870 - val_accuracy: 0.2467\n",
      "Epoch 2211/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2922 - accuracy: 0.4914 - val_loss: 2.9898 - val_accuracy: 0.2467\n",
      "Epoch 2212/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2917 - accuracy: 0.4986 - val_loss: 3.0150 - val_accuracy: 0.2500\n",
      "Epoch 2213/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2918 - accuracy: 0.4929 - val_loss: 2.9788 - val_accuracy: 0.2400\n",
      "Epoch 2214/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2908 - accuracy: 0.5014 - val_loss: 3.0061 - val_accuracy: 0.2433\n",
      "Epoch 2215/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2919 - accuracy: 0.4971 - val_loss: 2.9813 - val_accuracy: 0.2433\n",
      "Epoch 2216/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2924 - accuracy: 0.4929 - val_loss: 2.9775 - val_accuracy: 0.2433\n",
      "Epoch 2217/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2916 - accuracy: 0.4957 - val_loss: 2.9995 - val_accuracy: 0.2467\n",
      "Epoch 2218/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2913 - accuracy: 0.5043 - val_loss: 3.0070 - val_accuracy: 0.2367\n",
      "Epoch 2219/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2918 - accuracy: 0.4971 - val_loss: 2.9868 - val_accuracy: 0.2433\n",
      "Epoch 2220/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2905 - accuracy: 0.5014 - val_loss: 2.9751 - val_accuracy: 0.2500\n",
      "Epoch 2221/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2909 - accuracy: 0.5057 - val_loss: 2.9880 - val_accuracy: 0.2533\n",
      "Epoch 2222/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2930 - accuracy: 0.4943 - val_loss: 2.9567 - val_accuracy: 0.2433\n",
      "Epoch 2223/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2917 - accuracy: 0.4986 - val_loss: 3.0000 - val_accuracy: 0.2533\n",
      "Epoch 2224/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2912 - accuracy: 0.4971 - val_loss: 3.0005 - val_accuracy: 0.2467\n",
      "Epoch 2225/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2907 - accuracy: 0.4971 - val_loss: 2.9930 - val_accuracy: 0.2500\n",
      "Epoch 2226/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2911 - accuracy: 0.4971 - val_loss: 3.0288 - val_accuracy: 0.2500\n",
      "Epoch 2227/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2912 - accuracy: 0.5014 - val_loss: 2.9850 - val_accuracy: 0.2433\n",
      "Epoch 2228/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2913 - accuracy: 0.4943 - val_loss: 3.0042 - val_accuracy: 0.2500\n",
      "Epoch 2229/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2908 - accuracy: 0.5043 - val_loss: 2.9709 - val_accuracy: 0.2400\n",
      "Epoch 2230/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2913 - accuracy: 0.5029 - val_loss: 2.9943 - val_accuracy: 0.2433\n",
      "Epoch 2231/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2905 - accuracy: 0.5014 - val_loss: 2.9890 - val_accuracy: 0.2500\n",
      "Epoch 2232/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2912 - accuracy: 0.4957 - val_loss: 3.0006 - val_accuracy: 0.2467\n",
      "Epoch 2233/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2909 - accuracy: 0.4914 - val_loss: 3.0033 - val_accuracy: 0.2500\n",
      "Epoch 2234/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2911 - accuracy: 0.4971 - val_loss: 2.9738 - val_accuracy: 0.2433\n",
      "Epoch 2235/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2904 - accuracy: 0.5014 - val_loss: 3.0174 - val_accuracy: 0.2433\n",
      "Epoch 2236/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2903 - accuracy: 0.4971 - val_loss: 2.9764 - val_accuracy: 0.2400\n",
      "Epoch 2237/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2906 - accuracy: 0.4986 - val_loss: 3.0356 - val_accuracy: 0.2400\n",
      "Epoch 2238/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2909 - accuracy: 0.4986 - val_loss: 3.0531 - val_accuracy: 0.2367\n",
      "Epoch 2239/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2900 - accuracy: 0.4943 - val_loss: 2.9887 - val_accuracy: 0.2567\n",
      "Epoch 2240/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2908 - accuracy: 0.5000 - val_loss: 3.0257 - val_accuracy: 0.2433\n",
      "Epoch 2241/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2909 - accuracy: 0.4957 - val_loss: 2.9856 - val_accuracy: 0.2467\n",
      "Epoch 2242/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2901 - accuracy: 0.4971 - val_loss: 3.0020 - val_accuracy: 0.2467\n",
      "Epoch 2243/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2903 - accuracy: 0.4971 - val_loss: 3.0035 - val_accuracy: 0.2467\n",
      "Epoch 2244/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2904 - accuracy: 0.4957 - val_loss: 2.9939 - val_accuracy: 0.2433\n",
      "Epoch 2245/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2894 - accuracy: 0.5014 - val_loss: 3.0497 - val_accuracy: 0.2433\n",
      "Epoch 2246/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2898 - accuracy: 0.5000 - val_loss: 3.0106 - val_accuracy: 0.2433\n",
      "Epoch 2247/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2900 - accuracy: 0.4971 - val_loss: 3.0019 - val_accuracy: 0.2467\n",
      "Epoch 2248/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2903 - accuracy: 0.4943 - val_loss: 3.0819 - val_accuracy: 0.2367\n",
      "Epoch 2249/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2910 - accuracy: 0.4986 - val_loss: 3.0042 - val_accuracy: 0.2533\n",
      "Epoch 2250/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2896 - accuracy: 0.4986 - val_loss: 2.9994 - val_accuracy: 0.2467\n",
      "Epoch 2251/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2908 - accuracy: 0.4929 - val_loss: 3.0059 - val_accuracy: 0.2467\n",
      "Epoch 2252/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2899 - accuracy: 0.4957 - val_loss: 2.9869 - val_accuracy: 0.2400\n",
      "Epoch 2253/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2888 - accuracy: 0.4957 - val_loss: 3.0356 - val_accuracy: 0.2467\n",
      "Epoch 2254/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2902 - accuracy: 0.4943 - val_loss: 3.0290 - val_accuracy: 0.2500\n",
      "Epoch 2255/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2895 - accuracy: 0.4986 - val_loss: 3.0367 - val_accuracy: 0.2400\n",
      "Epoch 2256/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2899 - accuracy: 0.4986 - val_loss: 3.0064 - val_accuracy: 0.2400\n",
      "Epoch 2257/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2898 - accuracy: 0.5000 - val_loss: 3.0487 - val_accuracy: 0.2367\n",
      "Epoch 2258/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2894 - accuracy: 0.5029 - val_loss: 2.9942 - val_accuracy: 0.2500\n",
      "Epoch 2259/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2886 - accuracy: 0.5014 - val_loss: 3.0578 - val_accuracy: 0.2433\n",
      "Epoch 2260/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2896 - accuracy: 0.4957 - val_loss: 3.0301 - val_accuracy: 0.2500\n",
      "Epoch 2261/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2889 - accuracy: 0.4957 - val_loss: 3.0184 - val_accuracy: 0.2433\n",
      "Epoch 2262/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2894 - accuracy: 0.5057 - val_loss: 3.0172 - val_accuracy: 0.2433\n",
      "Epoch 2263/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2893 - accuracy: 0.4971 - val_loss: 3.0454 - val_accuracy: 0.2367\n",
      "Epoch 2264/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2892 - accuracy: 0.5000 - val_loss: 3.0688 - val_accuracy: 0.2400\n",
      "Epoch 2265/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 1.2898 - accuracy: 0.4971 - val_loss: 3.0117 - val_accuracy: 0.2467\n",
      "Epoch 2266/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2890 - accuracy: 0.5014 - val_loss: 3.0649 - val_accuracy: 0.2400\n",
      "Epoch 2267/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2899 - accuracy: 0.4929 - val_loss: 3.0009 - val_accuracy: 0.2433\n",
      "Epoch 2268/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2891 - accuracy: 0.4986 - val_loss: 2.9907 - val_accuracy: 0.2433\n",
      "Epoch 2269/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2879 - accuracy: 0.4971 - val_loss: 3.0618 - val_accuracy: 0.2500\n",
      "Epoch 2270/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2895 - accuracy: 0.5014 - val_loss: 3.0078 - val_accuracy: 0.2533\n",
      "Epoch 2271/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2893 - accuracy: 0.4929 - val_loss: 3.0545 - val_accuracy: 0.2433\n",
      "Epoch 2272/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2883 - accuracy: 0.4971 - val_loss: 3.0627 - val_accuracy: 0.2433\n",
      "Epoch 2273/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2890 - accuracy: 0.4971 - val_loss: 3.0107 - val_accuracy: 0.2433\n",
      "Epoch 2274/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2892 - accuracy: 0.4957 - val_loss: 3.0373 - val_accuracy: 0.2533\n",
      "Epoch 2275/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2885 - accuracy: 0.5014 - val_loss: 3.0313 - val_accuracy: 0.2433\n",
      "Epoch 2276/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2889 - accuracy: 0.4957 - val_loss: 3.0383 - val_accuracy: 0.2467\n",
      "Epoch 2277/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2895 - accuracy: 0.4957 - val_loss: 3.0362 - val_accuracy: 0.2400\n",
      "Epoch 2278/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2883 - accuracy: 0.4914 - val_loss: 3.0252 - val_accuracy: 0.2433\n",
      "Epoch 2279/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2885 - accuracy: 0.4929 - val_loss: 3.0419 - val_accuracy: 0.2400\n",
      "Epoch 2280/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2882 - accuracy: 0.4943 - val_loss: 3.0568 - val_accuracy: 0.2333\n",
      "Epoch 2281/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2872 - accuracy: 0.5000 - val_loss: 3.0381 - val_accuracy: 0.2500\n",
      "Epoch 2282/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2883 - accuracy: 0.4943 - val_loss: 3.0309 - val_accuracy: 0.2467\n",
      "Epoch 2283/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2874 - accuracy: 0.5000 - val_loss: 2.9868 - val_accuracy: 0.2500\n",
      "Epoch 2284/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2892 - accuracy: 0.5014 - val_loss: 3.0288 - val_accuracy: 0.2533\n",
      "Epoch 2285/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2895 - accuracy: 0.4914 - val_loss: 3.0528 - val_accuracy: 0.2400\n",
      "Epoch 2286/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2882 - accuracy: 0.4971 - val_loss: 3.0373 - val_accuracy: 0.2467\n",
      "Epoch 2287/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2886 - accuracy: 0.4943 - val_loss: 3.0176 - val_accuracy: 0.2400\n",
      "Epoch 2288/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2885 - accuracy: 0.5000 - val_loss: 3.0210 - val_accuracy: 0.2433\n",
      "Epoch 2289/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2888 - accuracy: 0.5029 - val_loss: 3.0571 - val_accuracy: 0.2467\n",
      "Epoch 2290/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2882 - accuracy: 0.4943 - val_loss: 3.0391 - val_accuracy: 0.2400\n",
      "Epoch 2291/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2880 - accuracy: 0.4971 - val_loss: 3.0480 - val_accuracy: 0.2433\n",
      "Epoch 2292/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2874 - accuracy: 0.5029 - val_loss: 3.0390 - val_accuracy: 0.2400\n",
      "Epoch 2293/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2876 - accuracy: 0.5014 - val_loss: 3.0286 - val_accuracy: 0.2467\n",
      "Epoch 2294/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2877 - accuracy: 0.5043 - val_loss: 3.0477 - val_accuracy: 0.2500\n",
      "Epoch 2295/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2881 - accuracy: 0.4943 - val_loss: 3.0455 - val_accuracy: 0.2400\n",
      "Epoch 2296/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2880 - accuracy: 0.4971 - val_loss: 3.0204 - val_accuracy: 0.2467\n",
      "Epoch 2297/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2871 - accuracy: 0.4957 - val_loss: 3.0416 - val_accuracy: 0.2433\n",
      "Epoch 2298/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2871 - accuracy: 0.5000 - val_loss: 3.0597 - val_accuracy: 0.2467\n",
      "Epoch 2299/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2879 - accuracy: 0.5057 - val_loss: 3.0562 - val_accuracy: 0.2500\n",
      "Epoch 2300/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2869 - accuracy: 0.5014 - val_loss: 3.0270 - val_accuracy: 0.2367\n",
      "Epoch 2301/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2885 - accuracy: 0.4943 - val_loss: 3.0287 - val_accuracy: 0.2433\n",
      "Epoch 2302/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2873 - accuracy: 0.4986 - val_loss: 3.0734 - val_accuracy: 0.2433\n",
      "Epoch 2303/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2873 - accuracy: 0.4971 - val_loss: 3.0177 - val_accuracy: 0.2367\n",
      "Epoch 2304/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2878 - accuracy: 0.5000 - val_loss: 3.0454 - val_accuracy: 0.2533\n",
      "Epoch 2305/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2870 - accuracy: 0.4943 - val_loss: 3.1095 - val_accuracy: 0.2433\n",
      "Epoch 2306/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2878 - accuracy: 0.5000 - val_loss: 2.9850 - val_accuracy: 0.2400\n",
      "Epoch 2307/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2875 - accuracy: 0.5014 - val_loss: 3.0265 - val_accuracy: 0.2433\n",
      "Epoch 2308/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2874 - accuracy: 0.5014 - val_loss: 3.0221 - val_accuracy: 0.2500\n",
      "Epoch 2309/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2874 - accuracy: 0.4943 - val_loss: 3.0661 - val_accuracy: 0.2500\n",
      "Epoch 2310/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2868 - accuracy: 0.4986 - val_loss: 3.0606 - val_accuracy: 0.2400\n",
      "Epoch 2311/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2870 - accuracy: 0.4914 - val_loss: 3.0431 - val_accuracy: 0.2433\n",
      "Epoch 2312/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2867 - accuracy: 0.4986 - val_loss: 3.0720 - val_accuracy: 0.2400\n",
      "Epoch 2313/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2864 - accuracy: 0.4971 - val_loss: 3.0546 - val_accuracy: 0.2500\n",
      "Epoch 2314/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2877 - accuracy: 0.4986 - val_loss: 3.0405 - val_accuracy: 0.2433\n",
      "Epoch 2315/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2871 - accuracy: 0.5014 - val_loss: 3.0297 - val_accuracy: 0.2400\n",
      "Epoch 2316/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2867 - accuracy: 0.4943 - val_loss: 3.0755 - val_accuracy: 0.2367\n",
      "Epoch 2317/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2853 - accuracy: 0.5014 - val_loss: 3.0473 - val_accuracy: 0.2500\n",
      "Epoch 2318/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2869 - accuracy: 0.5000 - val_loss: 3.0520 - val_accuracy: 0.2433\n",
      "Epoch 2319/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2869 - accuracy: 0.4943 - val_loss: 3.0260 - val_accuracy: 0.2400\n",
      "Epoch 2320/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 89us/step - loss: 1.2868 - accuracy: 0.4943 - val_loss: 3.0513 - val_accuracy: 0.2533\n",
      "Epoch 2321/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2864 - accuracy: 0.5000 - val_loss: 3.0604 - val_accuracy: 0.2400\n",
      "Epoch 2322/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2866 - accuracy: 0.4957 - val_loss: 3.0595 - val_accuracy: 0.2400\n",
      "Epoch 2323/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2866 - accuracy: 0.5000 - val_loss: 3.0060 - val_accuracy: 0.2500\n",
      "Epoch 2324/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2865 - accuracy: 0.5000 - val_loss: 3.0846 - val_accuracy: 0.2400\n",
      "Epoch 2325/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2866 - accuracy: 0.4943 - val_loss: 3.0392 - val_accuracy: 0.2467\n",
      "Epoch 2326/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2867 - accuracy: 0.5000 - val_loss: 3.0619 - val_accuracy: 0.2433\n",
      "Epoch 2327/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2865 - accuracy: 0.5043 - val_loss: 3.0423 - val_accuracy: 0.2367\n",
      "Epoch 2328/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2865 - accuracy: 0.4971 - val_loss: 3.0824 - val_accuracy: 0.2333\n",
      "Epoch 2329/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2867 - accuracy: 0.4986 - val_loss: 3.0841 - val_accuracy: 0.2367\n",
      "Epoch 2330/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2861 - accuracy: 0.5014 - val_loss: 3.0891 - val_accuracy: 0.2467\n",
      "Epoch 2331/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2855 - accuracy: 0.5014 - val_loss: 3.0540 - val_accuracy: 0.2500\n",
      "Epoch 2332/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2870 - accuracy: 0.4986 - val_loss: 3.0503 - val_accuracy: 0.2533\n",
      "Epoch 2333/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2861 - accuracy: 0.5029 - val_loss: 3.0665 - val_accuracy: 0.2433\n",
      "Epoch 2334/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2863 - accuracy: 0.4971 - val_loss: 3.0518 - val_accuracy: 0.2467\n",
      "Epoch 2335/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2850 - accuracy: 0.5029 - val_loss: 3.0615 - val_accuracy: 0.2367\n",
      "Epoch 2336/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2858 - accuracy: 0.4914 - val_loss: 3.0845 - val_accuracy: 0.2467\n",
      "Epoch 2337/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2875 - accuracy: 0.4986 - val_loss: 3.0611 - val_accuracy: 0.2433\n",
      "Epoch 2338/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2860 - accuracy: 0.4943 - val_loss: 3.0657 - val_accuracy: 0.2467\n",
      "Epoch 2339/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2855 - accuracy: 0.4943 - val_loss: 3.0896 - val_accuracy: 0.2433\n",
      "Epoch 2340/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2853 - accuracy: 0.4957 - val_loss: 3.0997 - val_accuracy: 0.2467\n",
      "Epoch 2341/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2857 - accuracy: 0.4943 - val_loss: 3.0681 - val_accuracy: 0.2500\n",
      "Epoch 2342/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2857 - accuracy: 0.4986 - val_loss: 3.0439 - val_accuracy: 0.2500\n",
      "Epoch 2343/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2856 - accuracy: 0.5029 - val_loss: 3.0690 - val_accuracy: 0.2500\n",
      "Epoch 2344/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2852 - accuracy: 0.4971 - val_loss: 3.0570 - val_accuracy: 0.2500\n",
      "Epoch 2345/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2856 - accuracy: 0.5029 - val_loss: 3.0680 - val_accuracy: 0.2533\n",
      "Epoch 2346/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2858 - accuracy: 0.5000 - val_loss: 3.0885 - val_accuracy: 0.2433\n",
      "Epoch 2347/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2856 - accuracy: 0.5000 - val_loss: 3.0657 - val_accuracy: 0.2467\n",
      "Epoch 2348/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2848 - accuracy: 0.5014 - val_loss: 3.0438 - val_accuracy: 0.2433\n",
      "Epoch 2349/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2855 - accuracy: 0.4957 - val_loss: 3.0639 - val_accuracy: 0.2500\n",
      "Epoch 2350/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2845 - accuracy: 0.4929 - val_loss: 3.0773 - val_accuracy: 0.2533\n",
      "Epoch 2351/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2854 - accuracy: 0.4971 - val_loss: 3.0739 - val_accuracy: 0.2433\n",
      "Epoch 2352/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2866 - accuracy: 0.4971 - val_loss: 3.0754 - val_accuracy: 0.2467\n",
      "Epoch 2353/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2848 - accuracy: 0.4986 - val_loss: 3.0475 - val_accuracy: 0.2500\n",
      "Epoch 2354/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2845 - accuracy: 0.4971 - val_loss: 3.0899 - val_accuracy: 0.2300\n",
      "Epoch 2355/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2850 - accuracy: 0.4986 - val_loss: 3.0844 - val_accuracy: 0.2367\n",
      "Epoch 2356/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2842 - accuracy: 0.4971 - val_loss: 3.0599 - val_accuracy: 0.2433\n",
      "Epoch 2357/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2851 - accuracy: 0.4986 - val_loss: 3.0903 - val_accuracy: 0.2367\n",
      "Epoch 2358/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2850 - accuracy: 0.4971 - val_loss: 3.0877 - val_accuracy: 0.2400\n",
      "Epoch 2359/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2852 - accuracy: 0.5029 - val_loss: 3.0643 - val_accuracy: 0.2533\n",
      "Epoch 2360/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2846 - accuracy: 0.4957 - val_loss: 3.0870 - val_accuracy: 0.2400\n",
      "Epoch 2361/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2851 - accuracy: 0.5014 - val_loss: 3.0751 - val_accuracy: 0.2400\n",
      "Epoch 2362/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2846 - accuracy: 0.4957 - val_loss: 3.0374 - val_accuracy: 0.2467\n",
      "Epoch 2363/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2837 - accuracy: 0.5014 - val_loss: 3.0564 - val_accuracy: 0.2433\n",
      "Epoch 2364/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2844 - accuracy: 0.5029 - val_loss: 3.0695 - val_accuracy: 0.2367\n",
      "Epoch 2365/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2838 - accuracy: 0.5000 - val_loss: 3.1309 - val_accuracy: 0.2467\n",
      "Epoch 2366/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2843 - accuracy: 0.5043 - val_loss: 3.0905 - val_accuracy: 0.2300\n",
      "Epoch 2367/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2844 - accuracy: 0.4986 - val_loss: 3.0719 - val_accuracy: 0.2333\n",
      "Epoch 2368/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2848 - accuracy: 0.5043 - val_loss: 3.0823 - val_accuracy: 0.2333\n",
      "Epoch 2369/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2842 - accuracy: 0.5000 - val_loss: 3.0686 - val_accuracy: 0.2400\n",
      "Epoch 2370/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2830 - accuracy: 0.5029 - val_loss: 3.0698 - val_accuracy: 0.2467\n",
      "Epoch 2371/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2847 - accuracy: 0.5000 - val_loss: 3.0548 - val_accuracy: 0.2533\n",
      "Epoch 2372/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2836 - accuracy: 0.5000 - val_loss: 3.0844 - val_accuracy: 0.2433\n",
      "Epoch 2373/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2851 - accuracy: 0.4929 - val_loss: 3.1075 - val_accuracy: 0.2467\n",
      "Epoch 2374/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2840 - accuracy: 0.5014 - val_loss: 3.1001 - val_accuracy: 0.2367\n",
      "Epoch 2375/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 1.2842 - accuracy: 0.4957 - val_loss: 3.0825 - val_accuracy: 0.2467\n",
      "Epoch 2376/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2841 - accuracy: 0.5014 - val_loss: 3.0905 - val_accuracy: 0.2433\n",
      "Epoch 2377/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2842 - accuracy: 0.4943 - val_loss: 3.0604 - val_accuracy: 0.2433\n",
      "Epoch 2378/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2836 - accuracy: 0.5014 - val_loss: 3.0401 - val_accuracy: 0.2467\n",
      "Epoch 2379/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2840 - accuracy: 0.5000 - val_loss: 3.0907 - val_accuracy: 0.2433\n",
      "Epoch 2380/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2832 - accuracy: 0.5014 - val_loss: 3.0667 - val_accuracy: 0.2467\n",
      "Epoch 2381/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2839 - accuracy: 0.5057 - val_loss: 3.0906 - val_accuracy: 0.2500\n",
      "Epoch 2382/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2836 - accuracy: 0.5014 - val_loss: 3.0918 - val_accuracy: 0.2467\n",
      "Epoch 2383/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2837 - accuracy: 0.5000 - val_loss: 3.0909 - val_accuracy: 0.2433\n",
      "Epoch 2384/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2835 - accuracy: 0.4971 - val_loss: 3.0886 - val_accuracy: 0.2467\n",
      "Epoch 2385/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2835 - accuracy: 0.5029 - val_loss: 3.1000 - val_accuracy: 0.2500\n",
      "Epoch 2386/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2828 - accuracy: 0.5014 - val_loss: 3.0926 - val_accuracy: 0.2433\n",
      "Epoch 2387/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2834 - accuracy: 0.5029 - val_loss: 3.0636 - val_accuracy: 0.2500\n",
      "Epoch 2388/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2831 - accuracy: 0.5029 - val_loss: 3.1069 - val_accuracy: 0.2400\n",
      "Epoch 2389/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2837 - accuracy: 0.5000 - val_loss: 3.0696 - val_accuracy: 0.2367\n",
      "Epoch 2390/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2831 - accuracy: 0.4914 - val_loss: 3.1220 - val_accuracy: 0.2433\n",
      "Epoch 2391/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2830 - accuracy: 0.4986 - val_loss: 3.1081 - val_accuracy: 0.2467\n",
      "Epoch 2392/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2842 - accuracy: 0.5000 - val_loss: 3.0988 - val_accuracy: 0.2433\n",
      "Epoch 2393/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2829 - accuracy: 0.5014 - val_loss: 3.0932 - val_accuracy: 0.2467\n",
      "Epoch 2394/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2833 - accuracy: 0.5057 - val_loss: 3.1029 - val_accuracy: 0.2467\n",
      "Epoch 2395/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2830 - accuracy: 0.4986 - val_loss: 3.1141 - val_accuracy: 0.2433\n",
      "Epoch 2396/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2828 - accuracy: 0.5043 - val_loss: 3.1331 - val_accuracy: 0.2433\n",
      "Epoch 2397/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2828 - accuracy: 0.5029 - val_loss: 3.1119 - val_accuracy: 0.2433\n",
      "Epoch 2398/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2829 - accuracy: 0.5071 - val_loss: 3.0591 - val_accuracy: 0.2500\n",
      "Epoch 2399/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2828 - accuracy: 0.5029 - val_loss: 3.1394 - val_accuracy: 0.2433\n",
      "Epoch 2400/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2825 - accuracy: 0.5000 - val_loss: 3.1111 - val_accuracy: 0.2433\n",
      "Epoch 2401/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2824 - accuracy: 0.4986 - val_loss: 3.1263 - val_accuracy: 0.2433\n",
      "Epoch 2402/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2838 - accuracy: 0.4943 - val_loss: 3.0616 - val_accuracy: 0.2433\n",
      "Epoch 2403/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2829 - accuracy: 0.4986 - val_loss: 3.0919 - val_accuracy: 0.2467\n",
      "Epoch 2404/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2819 - accuracy: 0.5014 - val_loss: 3.0945 - val_accuracy: 0.2500\n",
      "Epoch 2405/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2833 - accuracy: 0.5029 - val_loss: 3.0704 - val_accuracy: 0.2467\n",
      "Epoch 2406/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2828 - accuracy: 0.5000 - val_loss: 3.0973 - val_accuracy: 0.2467\n",
      "Epoch 2407/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2820 - accuracy: 0.5043 - val_loss: 3.0906 - val_accuracy: 0.2367\n",
      "Epoch 2408/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2819 - accuracy: 0.5057 - val_loss: 3.1130 - val_accuracy: 0.2500\n",
      "Epoch 2409/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2827 - accuracy: 0.4986 - val_loss: 3.0946 - val_accuracy: 0.2467\n",
      "Epoch 2410/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2820 - accuracy: 0.4986 - val_loss: 3.1220 - val_accuracy: 0.2367\n",
      "Epoch 2411/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2821 - accuracy: 0.5029 - val_loss: 3.0868 - val_accuracy: 0.2400\n",
      "Epoch 2412/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2825 - accuracy: 0.5029 - val_loss: 3.1544 - val_accuracy: 0.2467\n",
      "Epoch 2413/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2825 - accuracy: 0.4971 - val_loss: 3.1132 - val_accuracy: 0.2367\n",
      "Epoch 2414/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2823 - accuracy: 0.4971 - val_loss: 3.1163 - val_accuracy: 0.2400\n",
      "Epoch 2415/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2826 - accuracy: 0.5014 - val_loss: 3.1122 - val_accuracy: 0.2433\n",
      "Epoch 2416/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2818 - accuracy: 0.4971 - val_loss: 3.0875 - val_accuracy: 0.2400\n",
      "Epoch 2417/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2824 - accuracy: 0.4957 - val_loss: 3.1102 - val_accuracy: 0.2433\n",
      "Epoch 2418/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2825 - accuracy: 0.5000 - val_loss: 3.1335 - val_accuracy: 0.2300\n",
      "Epoch 2419/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2819 - accuracy: 0.4986 - val_loss: 3.0971 - val_accuracy: 0.2500\n",
      "Epoch 2420/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2818 - accuracy: 0.5029 - val_loss: 3.0733 - val_accuracy: 0.2400\n",
      "Epoch 2421/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2825 - accuracy: 0.4986 - val_loss: 3.0775 - val_accuracy: 0.2367\n",
      "Epoch 2422/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2817 - accuracy: 0.5043 - val_loss: 3.1085 - val_accuracy: 0.2367\n",
      "Epoch 2423/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2820 - accuracy: 0.5029 - val_loss: 3.1343 - val_accuracy: 0.2433\n",
      "Epoch 2424/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2816 - accuracy: 0.5014 - val_loss: 3.0903 - val_accuracy: 0.2467\n",
      "Epoch 2425/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2820 - accuracy: 0.5029 - val_loss: 3.1120 - val_accuracy: 0.2400\n",
      "Epoch 2426/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2808 - accuracy: 0.5057 - val_loss: 3.0776 - val_accuracy: 0.2400\n",
      "Epoch 2427/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2817 - accuracy: 0.4986 - val_loss: 3.1057 - val_accuracy: 0.2367\n",
      "Epoch 2428/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2818 - accuracy: 0.5057 - val_loss: 3.0877 - val_accuracy: 0.2400\n",
      "Epoch 2429/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2811 - accuracy: 0.5029 - val_loss: 3.1109 - val_accuracy: 0.2433\n",
      "Epoch 2430/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 1.2812 - accuracy: 0.4986 - val_loss: 3.0771 - val_accuracy: 0.2433\n",
      "Epoch 2431/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2810 - accuracy: 0.5043 - val_loss: 3.1098 - val_accuracy: 0.2400\n",
      "Epoch 2432/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2812 - accuracy: 0.5071 - val_loss: 3.1246 - val_accuracy: 0.2433\n",
      "Epoch 2433/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2813 - accuracy: 0.5000 - val_loss: 3.1046 - val_accuracy: 0.2433\n",
      "Epoch 2434/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2811 - accuracy: 0.4971 - val_loss: 3.0939 - val_accuracy: 0.2467\n",
      "Epoch 2435/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2814 - accuracy: 0.5100 - val_loss: 3.1342 - val_accuracy: 0.2367\n",
      "Epoch 2436/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2808 - accuracy: 0.4986 - val_loss: 3.1451 - val_accuracy: 0.2433\n",
      "Epoch 2437/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2819 - accuracy: 0.4971 - val_loss: 3.1107 - val_accuracy: 0.2467\n",
      "Epoch 2438/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2816 - accuracy: 0.4929 - val_loss: 3.1269 - val_accuracy: 0.2467\n",
      "Epoch 2439/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2818 - accuracy: 0.5057 - val_loss: 3.1426 - val_accuracy: 0.2433\n",
      "Epoch 2440/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2816 - accuracy: 0.5043 - val_loss: 3.1438 - val_accuracy: 0.2433\n",
      "Epoch 2441/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2804 - accuracy: 0.4943 - val_loss: 3.1001 - val_accuracy: 0.2400\n",
      "Epoch 2442/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2814 - accuracy: 0.4971 - val_loss: 3.1627 - val_accuracy: 0.2367\n",
      "Epoch 2443/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2809 - accuracy: 0.5071 - val_loss: 3.1425 - val_accuracy: 0.2433\n",
      "Epoch 2444/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2803 - accuracy: 0.4986 - val_loss: 3.1182 - val_accuracy: 0.2467\n",
      "Epoch 2445/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2812 - accuracy: 0.5014 - val_loss: 3.1150 - val_accuracy: 0.2400\n",
      "Epoch 2446/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2806 - accuracy: 0.5029 - val_loss: 3.0977 - val_accuracy: 0.2500\n",
      "Epoch 2447/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2805 - accuracy: 0.5029 - val_loss: 3.1491 - val_accuracy: 0.2400\n",
      "Epoch 2448/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2805 - accuracy: 0.5000 - val_loss: 3.1152 - val_accuracy: 0.2433\n",
      "Epoch 2449/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2809 - accuracy: 0.4971 - val_loss: 3.1356 - val_accuracy: 0.2367\n",
      "Epoch 2450/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2803 - accuracy: 0.5014 - val_loss: 3.1083 - val_accuracy: 0.2300\n",
      "Epoch 2451/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2809 - accuracy: 0.5029 - val_loss: 3.1150 - val_accuracy: 0.2433\n",
      "Epoch 2452/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2812 - accuracy: 0.5057 - val_loss: 3.1280 - val_accuracy: 0.2400\n",
      "Epoch 2453/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2799 - accuracy: 0.4957 - val_loss: 3.1145 - val_accuracy: 0.2333\n",
      "Epoch 2454/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2804 - accuracy: 0.4986 - val_loss: 3.1742 - val_accuracy: 0.2467\n",
      "Epoch 2455/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2807 - accuracy: 0.5000 - val_loss: 3.1438 - val_accuracy: 0.2367\n",
      "Epoch 2456/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2799 - accuracy: 0.5071 - val_loss: 3.1672 - val_accuracy: 0.2467\n",
      "Epoch 2457/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2810 - accuracy: 0.5029 - val_loss: 3.1377 - val_accuracy: 0.2433\n",
      "Epoch 2458/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2801 - accuracy: 0.5014 - val_loss: 3.1105 - val_accuracy: 0.2467\n",
      "Epoch 2459/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2800 - accuracy: 0.5014 - val_loss: 3.1196 - val_accuracy: 0.2433\n",
      "Epoch 2460/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2800 - accuracy: 0.5000 - val_loss: 3.1112 - val_accuracy: 0.2400\n",
      "Epoch 2461/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2801 - accuracy: 0.5043 - val_loss: 3.1097 - val_accuracy: 0.2500\n",
      "Epoch 2462/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2795 - accuracy: 0.5000 - val_loss: 3.1391 - val_accuracy: 0.2367\n",
      "Epoch 2463/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2802 - accuracy: 0.5029 - val_loss: 3.1201 - val_accuracy: 0.2400\n",
      "Epoch 2464/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2795 - accuracy: 0.5000 - val_loss: 3.1227 - val_accuracy: 0.2467\n",
      "Epoch 2465/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2796 - accuracy: 0.4971 - val_loss: 3.1461 - val_accuracy: 0.2433\n",
      "Epoch 2466/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2793 - accuracy: 0.4971 - val_loss: 3.1242 - val_accuracy: 0.2433\n",
      "Epoch 2467/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2797 - accuracy: 0.5014 - val_loss: 3.1273 - val_accuracy: 0.2300\n",
      "Epoch 2468/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2795 - accuracy: 0.5043 - val_loss: 3.1188 - val_accuracy: 0.2500\n",
      "Epoch 2469/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2794 - accuracy: 0.4986 - val_loss: 3.1380 - val_accuracy: 0.2333\n",
      "Epoch 2470/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2795 - accuracy: 0.4943 - val_loss: 3.1465 - val_accuracy: 0.2467\n",
      "Epoch 2471/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2798 - accuracy: 0.5000 - val_loss: 3.1114 - val_accuracy: 0.2500\n",
      "Epoch 2472/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2792 - accuracy: 0.5029 - val_loss: 3.1518 - val_accuracy: 0.2367\n",
      "Epoch 2473/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2793 - accuracy: 0.5043 - val_loss: 3.1767 - val_accuracy: 0.2333\n",
      "Epoch 2474/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2801 - accuracy: 0.5000 - val_loss: 3.1371 - val_accuracy: 0.2300\n",
      "Epoch 2475/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2791 - accuracy: 0.5000 - val_loss: 3.1544 - val_accuracy: 0.2400\n",
      "Epoch 2476/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2789 - accuracy: 0.5029 - val_loss: 3.1561 - val_accuracy: 0.2433\n",
      "Epoch 2477/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2794 - accuracy: 0.4971 - val_loss: 3.1279 - val_accuracy: 0.2400\n",
      "Epoch 2478/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2798 - accuracy: 0.4957 - val_loss: 3.1436 - val_accuracy: 0.2367\n",
      "Epoch 2479/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2781 - accuracy: 0.5057 - val_loss: 3.0990 - val_accuracy: 0.2467\n",
      "Epoch 2480/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2780 - accuracy: 0.5057 - val_loss: 3.1773 - val_accuracy: 0.2333\n",
      "Epoch 2481/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2784 - accuracy: 0.5014 - val_loss: 3.1510 - val_accuracy: 0.2433\n",
      "Epoch 2482/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2786 - accuracy: 0.4986 - val_loss: 3.1629 - val_accuracy: 0.2367\n",
      "Epoch 2483/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2792 - accuracy: 0.5000 - val_loss: 3.1267 - val_accuracy: 0.2400\n",
      "Epoch 2484/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2793 - accuracy: 0.4986 - val_loss: 3.1525 - val_accuracy: 0.2400\n",
      "Epoch 2485/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 1.2791 - accuracy: 0.5029 - val_loss: 3.1348 - val_accuracy: 0.2333\n",
      "Epoch 2486/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2784 - accuracy: 0.5043 - val_loss: 3.1273 - val_accuracy: 0.2467\n",
      "Epoch 2487/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2785 - accuracy: 0.4971 - val_loss: 3.1741 - val_accuracy: 0.2433\n",
      "Epoch 2488/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2786 - accuracy: 0.4957 - val_loss: 3.0929 - val_accuracy: 0.2467\n",
      "Epoch 2489/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2799 - accuracy: 0.5014 - val_loss: 3.1603 - val_accuracy: 0.2400\n",
      "Epoch 2490/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2783 - accuracy: 0.5029 - val_loss: 3.1238 - val_accuracy: 0.2500\n",
      "Epoch 2491/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2789 - accuracy: 0.4986 - val_loss: 3.1475 - val_accuracy: 0.2367\n",
      "Epoch 2492/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2796 - accuracy: 0.4986 - val_loss: 3.1347 - val_accuracy: 0.2467\n",
      "Epoch 2493/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2787 - accuracy: 0.5029 - val_loss: 3.1816 - val_accuracy: 0.2400\n",
      "Epoch 2494/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2785 - accuracy: 0.4943 - val_loss: 3.1316 - val_accuracy: 0.2433\n",
      "Epoch 2495/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2784 - accuracy: 0.5014 - val_loss: 3.2034 - val_accuracy: 0.2433\n",
      "Epoch 2496/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2791 - accuracy: 0.4986 - val_loss: 3.1675 - val_accuracy: 0.2433\n",
      "Epoch 2497/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2789 - accuracy: 0.5014 - val_loss: 3.1644 - val_accuracy: 0.2400\n",
      "Epoch 2498/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2785 - accuracy: 0.5029 - val_loss: 3.1862 - val_accuracy: 0.2433\n",
      "Epoch 2499/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2784 - accuracy: 0.5057 - val_loss: 3.1285 - val_accuracy: 0.2367\n",
      "Epoch 2500/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2776 - accuracy: 0.5057 - val_loss: 3.1201 - val_accuracy: 0.2533\n",
      "Epoch 2501/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2786 - accuracy: 0.5014 - val_loss: 3.2029 - val_accuracy: 0.2400\n",
      "Epoch 2502/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2781 - accuracy: 0.4971 - val_loss: 3.1570 - val_accuracy: 0.2433\n",
      "Epoch 2503/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2779 - accuracy: 0.4971 - val_loss: 3.1660 - val_accuracy: 0.2400\n",
      "Epoch 2504/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2779 - accuracy: 0.5071 - val_loss: 3.1453 - val_accuracy: 0.2467\n",
      "Epoch 2505/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2791 - accuracy: 0.4957 - val_loss: 3.1572 - val_accuracy: 0.2467\n",
      "Epoch 2506/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2778 - accuracy: 0.5043 - val_loss: 3.1533 - val_accuracy: 0.2400\n",
      "Epoch 2507/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2780 - accuracy: 0.4986 - val_loss: 3.1456 - val_accuracy: 0.2433\n",
      "Epoch 2508/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2777 - accuracy: 0.5014 - val_loss: 3.1998 - val_accuracy: 0.2467\n",
      "Epoch 2509/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2776 - accuracy: 0.5057 - val_loss: 3.1590 - val_accuracy: 0.2433\n",
      "Epoch 2510/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2775 - accuracy: 0.5014 - val_loss: 3.1713 - val_accuracy: 0.2367\n",
      "Epoch 2511/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2777 - accuracy: 0.4986 - val_loss: 3.1361 - val_accuracy: 0.2433\n",
      "Epoch 2512/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2774 - accuracy: 0.5043 - val_loss: 3.1758 - val_accuracy: 0.2467\n",
      "Epoch 2513/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2781 - accuracy: 0.5014 - val_loss: 3.1435 - val_accuracy: 0.2433\n",
      "Epoch 2514/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2770 - accuracy: 0.5000 - val_loss: 3.1296 - val_accuracy: 0.2400\n",
      "Epoch 2515/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2771 - accuracy: 0.5014 - val_loss: 3.1515 - val_accuracy: 0.2433\n",
      "Epoch 2516/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2771 - accuracy: 0.5000 - val_loss: 3.1822 - val_accuracy: 0.2433\n",
      "Epoch 2517/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2782 - accuracy: 0.5000 - val_loss: 3.1818 - val_accuracy: 0.2433\n",
      "Epoch 2518/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2775 - accuracy: 0.5043 - val_loss: 3.1639 - val_accuracy: 0.2433\n",
      "Epoch 2519/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2775 - accuracy: 0.5071 - val_loss: 3.1749 - val_accuracy: 0.2400\n",
      "Epoch 2520/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2769 - accuracy: 0.4971 - val_loss: 3.1710 - val_accuracy: 0.2367\n",
      "Epoch 2521/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2771 - accuracy: 0.4986 - val_loss: 3.1643 - val_accuracy: 0.2367\n",
      "Epoch 2522/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2778 - accuracy: 0.5014 - val_loss: 3.1515 - val_accuracy: 0.2367\n",
      "Epoch 2523/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2774 - accuracy: 0.5000 - val_loss: 3.1499 - val_accuracy: 0.2333\n",
      "Epoch 2524/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2769 - accuracy: 0.4986 - val_loss: 3.1515 - val_accuracy: 0.2433\n",
      "Epoch 2525/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2772 - accuracy: 0.5014 - val_loss: 3.1788 - val_accuracy: 0.2433\n",
      "Epoch 2526/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2769 - accuracy: 0.4986 - val_loss: 3.1544 - val_accuracy: 0.2333\n",
      "Epoch 2527/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2767 - accuracy: 0.5014 - val_loss: 3.1840 - val_accuracy: 0.2400\n",
      "Epoch 2528/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2766 - accuracy: 0.5014 - val_loss: 3.1740 - val_accuracy: 0.2333\n",
      "Epoch 2529/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2777 - accuracy: 0.5057 - val_loss: 3.1967 - val_accuracy: 0.2400\n",
      "Epoch 2530/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2763 - accuracy: 0.5000 - val_loss: 3.1729 - val_accuracy: 0.2367\n",
      "Epoch 2531/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2765 - accuracy: 0.5057 - val_loss: 3.1425 - val_accuracy: 0.2433\n",
      "Epoch 2532/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2766 - accuracy: 0.5071 - val_loss: 3.1751 - val_accuracy: 0.2433\n",
      "Epoch 2533/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2777 - accuracy: 0.5057 - val_loss: 3.1707 - val_accuracy: 0.2433\n",
      "Epoch 2534/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2768 - accuracy: 0.5014 - val_loss: 3.1882 - val_accuracy: 0.2367\n",
      "Epoch 2535/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2770 - accuracy: 0.5043 - val_loss: 3.1639 - val_accuracy: 0.2433\n",
      "Epoch 2536/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2768 - accuracy: 0.5043 - val_loss: 3.1994 - val_accuracy: 0.2400\n",
      "Epoch 2537/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2772 - accuracy: 0.5057 - val_loss: 3.1514 - val_accuracy: 0.2433\n",
      "Epoch 2538/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2762 - accuracy: 0.5029 - val_loss: 3.1809 - val_accuracy: 0.2400\n",
      "Epoch 2539/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2773 - accuracy: 0.4986 - val_loss: 3.2060 - val_accuracy: 0.2400\n",
      "Epoch 2540/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 1.2770 - accuracy: 0.5014 - val_loss: 3.2081 - val_accuracy: 0.2467\n",
      "Epoch 2541/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2764 - accuracy: 0.5057 - val_loss: 3.1819 - val_accuracy: 0.2367\n",
      "Epoch 2542/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2760 - accuracy: 0.5057 - val_loss: 3.1716 - val_accuracy: 0.2433\n",
      "Epoch 2543/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2766 - accuracy: 0.5043 - val_loss: 3.1804 - val_accuracy: 0.2333\n",
      "Epoch 2544/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2768 - accuracy: 0.4986 - val_loss: 3.1759 - val_accuracy: 0.2333\n",
      "Epoch 2545/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2763 - accuracy: 0.5086 - val_loss: 3.2089 - val_accuracy: 0.2400\n",
      "Epoch 2546/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2768 - accuracy: 0.5057 - val_loss: 3.2078 - val_accuracy: 0.2400\n",
      "Epoch 2547/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2767 - accuracy: 0.5043 - val_loss: 3.1964 - val_accuracy: 0.2433\n",
      "Epoch 2548/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2759 - accuracy: 0.5029 - val_loss: 3.1845 - val_accuracy: 0.2433\n",
      "Epoch 2549/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2761 - accuracy: 0.5000 - val_loss: 3.1644 - val_accuracy: 0.2367\n",
      "Epoch 2550/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2762 - accuracy: 0.5043 - val_loss: 3.1715 - val_accuracy: 0.2367\n",
      "Epoch 2551/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2755 - accuracy: 0.4986 - val_loss: 3.2068 - val_accuracy: 0.2433\n",
      "Epoch 2552/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2758 - accuracy: 0.5043 - val_loss: 3.1591 - val_accuracy: 0.2333\n",
      "Epoch 2553/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2754 - accuracy: 0.5000 - val_loss: 3.1693 - val_accuracy: 0.2367\n",
      "Epoch 2554/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2756 - accuracy: 0.4986 - val_loss: 3.1594 - val_accuracy: 0.2333\n",
      "Epoch 2555/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2763 - accuracy: 0.5000 - val_loss: 3.1993 - val_accuracy: 0.2433\n",
      "Epoch 2556/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2762 - accuracy: 0.5000 - val_loss: 3.1612 - val_accuracy: 0.2400\n",
      "Epoch 2557/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2754 - accuracy: 0.5000 - val_loss: 3.2042 - val_accuracy: 0.2433\n",
      "Epoch 2558/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2757 - accuracy: 0.4986 - val_loss: 3.2016 - val_accuracy: 0.2433\n",
      "Epoch 2559/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2758 - accuracy: 0.5043 - val_loss: 3.1937 - val_accuracy: 0.2400\n",
      "Epoch 2560/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2762 - accuracy: 0.5000 - val_loss: 3.1953 - val_accuracy: 0.2400\n",
      "Epoch 2561/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2757 - accuracy: 0.5057 - val_loss: 3.1768 - val_accuracy: 0.2333\n",
      "Epoch 2562/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2751 - accuracy: 0.5000 - val_loss: 3.1692 - val_accuracy: 0.2433\n",
      "Epoch 2563/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2753 - accuracy: 0.5029 - val_loss: 3.1907 - val_accuracy: 0.2467\n",
      "Epoch 2564/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2761 - accuracy: 0.5029 - val_loss: 3.1934 - val_accuracy: 0.2400\n",
      "Epoch 2565/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2755 - accuracy: 0.5043 - val_loss: 3.1817 - val_accuracy: 0.2400\n",
      "Epoch 2566/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2760 - accuracy: 0.5014 - val_loss: 3.1976 - val_accuracy: 0.2400\n",
      "Epoch 2567/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2759 - accuracy: 0.5057 - val_loss: 3.1804 - val_accuracy: 0.2433\n",
      "Epoch 2568/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2754 - accuracy: 0.5043 - val_loss: 3.1809 - val_accuracy: 0.2333\n",
      "Epoch 2569/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2742 - accuracy: 0.5000 - val_loss: 3.1647 - val_accuracy: 0.2433\n",
      "Epoch 2570/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2750 - accuracy: 0.4986 - val_loss: 3.2062 - val_accuracy: 0.2433\n",
      "Epoch 2571/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2750 - accuracy: 0.5043 - val_loss: 3.1963 - val_accuracy: 0.2400\n",
      "Epoch 2572/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2752 - accuracy: 0.5086 - val_loss: 3.2094 - val_accuracy: 0.2433\n",
      "Epoch 2573/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2743 - accuracy: 0.5043 - val_loss: 3.2451 - val_accuracy: 0.2433\n",
      "Epoch 2574/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2754 - accuracy: 0.4971 - val_loss: 3.1492 - val_accuracy: 0.2433\n",
      "Epoch 2575/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2748 - accuracy: 0.5029 - val_loss: 3.2267 - val_accuracy: 0.2433\n",
      "Epoch 2576/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2747 - accuracy: 0.5071 - val_loss: 3.2081 - val_accuracy: 0.2433\n",
      "Epoch 2577/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2749 - accuracy: 0.5029 - val_loss: 3.2051 - val_accuracy: 0.2433\n",
      "Epoch 2578/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2746 - accuracy: 0.5014 - val_loss: 3.1948 - val_accuracy: 0.2433\n",
      "Epoch 2579/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2749 - accuracy: 0.5029 - val_loss: 3.1872 - val_accuracy: 0.2367\n",
      "Epoch 2580/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2746 - accuracy: 0.5014 - val_loss: 3.1996 - val_accuracy: 0.2433\n",
      "Epoch 2581/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2741 - accuracy: 0.5029 - val_loss: 3.1650 - val_accuracy: 0.2367\n",
      "Epoch 2582/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2747 - accuracy: 0.5043 - val_loss: 3.2219 - val_accuracy: 0.2367\n",
      "Epoch 2583/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2749 - accuracy: 0.5043 - val_loss: 3.2027 - val_accuracy: 0.2433\n",
      "Epoch 2584/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2745 - accuracy: 0.5086 - val_loss: 3.2029 - val_accuracy: 0.2400\n",
      "Epoch 2585/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2741 - accuracy: 0.5014 - val_loss: 3.1934 - val_accuracy: 0.2400\n",
      "Epoch 2586/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2742 - accuracy: 0.5071 - val_loss: 3.1815 - val_accuracy: 0.2433\n",
      "Epoch 2587/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2744 - accuracy: 0.5057 - val_loss: 3.2214 - val_accuracy: 0.2400\n",
      "Epoch 2588/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2745 - accuracy: 0.5014 - val_loss: 3.1965 - val_accuracy: 0.2367\n",
      "Epoch 2589/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2743 - accuracy: 0.5014 - val_loss: 3.1901 - val_accuracy: 0.2367\n",
      "Epoch 2590/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2736 - accuracy: 0.5014 - val_loss: 3.1920 - val_accuracy: 0.2333\n",
      "Epoch 2591/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2738 - accuracy: 0.5029 - val_loss: 3.1714 - val_accuracy: 0.2433\n",
      "Epoch 2592/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2743 - accuracy: 0.5071 - val_loss: 3.2311 - val_accuracy: 0.2400\n",
      "Epoch 2593/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2740 - accuracy: 0.4986 - val_loss: 3.1688 - val_accuracy: 0.2433\n",
      "Epoch 2594/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2739 - accuracy: 0.5043 - val_loss: 3.2245 - val_accuracy: 0.2400\n",
      "Epoch 2595/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 1.2745 - accuracy: 0.4971 - val_loss: 3.2038 - val_accuracy: 0.2333\n",
      "Epoch 2596/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2748 - accuracy: 0.5071 - val_loss: 3.1949 - val_accuracy: 0.2367\n",
      "Epoch 2597/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2739 - accuracy: 0.5043 - val_loss: 3.1998 - val_accuracy: 0.2433\n",
      "Epoch 2598/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2733 - accuracy: 0.4986 - val_loss: 3.2180 - val_accuracy: 0.2467\n",
      "Epoch 2599/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2740 - accuracy: 0.5029 - val_loss: 3.1791 - val_accuracy: 0.2367\n",
      "Epoch 2600/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2734 - accuracy: 0.5057 - val_loss: 3.2008 - val_accuracy: 0.2433\n",
      "Epoch 2601/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2734 - accuracy: 0.5029 - val_loss: 3.1994 - val_accuracy: 0.2433\n",
      "Epoch 2602/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2745 - accuracy: 0.5086 - val_loss: 3.2144 - val_accuracy: 0.2433\n",
      "Epoch 2603/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2737 - accuracy: 0.5057 - val_loss: 3.1867 - val_accuracy: 0.2433\n",
      "Epoch 2604/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2734 - accuracy: 0.5057 - val_loss: 3.2175 - val_accuracy: 0.2400\n",
      "Epoch 2605/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2739 - accuracy: 0.5014 - val_loss: 3.2092 - val_accuracy: 0.2367\n",
      "Epoch 2606/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2739 - accuracy: 0.5014 - val_loss: 3.2013 - val_accuracy: 0.2333\n",
      "Epoch 2607/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2733 - accuracy: 0.5000 - val_loss: 3.1853 - val_accuracy: 0.2400\n",
      "Epoch 2608/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2736 - accuracy: 0.5000 - val_loss: 3.2379 - val_accuracy: 0.2400\n",
      "Epoch 2609/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2734 - accuracy: 0.4986 - val_loss: 3.1981 - val_accuracy: 0.2400\n",
      "Epoch 2610/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2736 - accuracy: 0.5029 - val_loss: 3.1858 - val_accuracy: 0.2433\n",
      "Epoch 2611/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2736 - accuracy: 0.5014 - val_loss: 3.1876 - val_accuracy: 0.2400\n",
      "Epoch 2612/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2737 - accuracy: 0.5029 - val_loss: 3.2261 - val_accuracy: 0.2400\n",
      "Epoch 2613/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2733 - accuracy: 0.5057 - val_loss: 3.2148 - val_accuracy: 0.2433\n",
      "Epoch 2614/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2729 - accuracy: 0.5043 - val_loss: 3.2341 - val_accuracy: 0.2433\n",
      "Epoch 2615/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2731 - accuracy: 0.5043 - val_loss: 3.2059 - val_accuracy: 0.2433\n",
      "Epoch 2616/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2733 - accuracy: 0.5043 - val_loss: 3.2451 - val_accuracy: 0.2400\n",
      "Epoch 2617/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2737 - accuracy: 0.5043 - val_loss: 3.2205 - val_accuracy: 0.2400\n",
      "Epoch 2618/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2737 - accuracy: 0.4986 - val_loss: 3.1915 - val_accuracy: 0.2367\n",
      "Epoch 2619/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2733 - accuracy: 0.5043 - val_loss: 3.2209 - val_accuracy: 0.2367\n",
      "Epoch 2620/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2732 - accuracy: 0.5057 - val_loss: 3.2249 - val_accuracy: 0.2367\n",
      "Epoch 2621/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2730 - accuracy: 0.5057 - val_loss: 3.2217 - val_accuracy: 0.2333\n",
      "Epoch 2622/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2736 - accuracy: 0.5000 - val_loss: 3.1888 - val_accuracy: 0.2400\n",
      "Epoch 2623/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2729 - accuracy: 0.5029 - val_loss: 3.2267 - val_accuracy: 0.2400\n",
      "Epoch 2624/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2723 - accuracy: 0.5029 - val_loss: 3.1944 - val_accuracy: 0.2333\n",
      "Epoch 2625/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2725 - accuracy: 0.5043 - val_loss: 3.2388 - val_accuracy: 0.2433\n",
      "Epoch 2626/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2729 - accuracy: 0.5000 - val_loss: 3.2409 - val_accuracy: 0.2433\n",
      "Epoch 2627/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2727 - accuracy: 0.5014 - val_loss: 3.2240 - val_accuracy: 0.2367\n",
      "Epoch 2628/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2724 - accuracy: 0.5043 - val_loss: 3.2312 - val_accuracy: 0.2367\n",
      "Epoch 2629/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2725 - accuracy: 0.5029 - val_loss: 3.2195 - val_accuracy: 0.2367\n",
      "Epoch 2630/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2722 - accuracy: 0.5029 - val_loss: 3.1707 - val_accuracy: 0.2433\n",
      "Epoch 2631/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2726 - accuracy: 0.5057 - val_loss: 3.2321 - val_accuracy: 0.2367\n",
      "Epoch 2632/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2733 - accuracy: 0.4986 - val_loss: 3.2187 - val_accuracy: 0.2433\n",
      "Epoch 2633/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2720 - accuracy: 0.5043 - val_loss: 3.2203 - val_accuracy: 0.2367\n",
      "Epoch 2634/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2718 - accuracy: 0.5086 - val_loss: 3.2083 - val_accuracy: 0.2367\n",
      "Epoch 2635/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2730 - accuracy: 0.5043 - val_loss: 3.2457 - val_accuracy: 0.2367\n",
      "Epoch 2636/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2725 - accuracy: 0.5014 - val_loss: 3.2223 - val_accuracy: 0.2367\n",
      "Epoch 2637/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2727 - accuracy: 0.5057 - val_loss: 3.2285 - val_accuracy: 0.2400\n",
      "Epoch 2638/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2721 - accuracy: 0.5000 - val_loss: 3.2379 - val_accuracy: 0.2433\n",
      "Epoch 2639/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2724 - accuracy: 0.5043 - val_loss: 3.1877 - val_accuracy: 0.2467\n",
      "Epoch 2640/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2721 - accuracy: 0.5071 - val_loss: 3.2542 - val_accuracy: 0.2467\n",
      "Epoch 2641/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2720 - accuracy: 0.5086 - val_loss: 3.3056 - val_accuracy: 0.2467\n",
      "Epoch 2642/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2719 - accuracy: 0.4986 - val_loss: 3.1854 - val_accuracy: 0.2400\n",
      "Epoch 2643/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2720 - accuracy: 0.5129 - val_loss: 3.2231 - val_accuracy: 0.2433\n",
      "Epoch 2644/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2720 - accuracy: 0.5000 - val_loss: 3.2263 - val_accuracy: 0.2433\n",
      "Epoch 2645/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2718 - accuracy: 0.5029 - val_loss: 3.2218 - val_accuracy: 0.2433\n",
      "Epoch 2646/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2724 - accuracy: 0.5057 - val_loss: 3.2380 - val_accuracy: 0.2467\n",
      "Epoch 2647/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2722 - accuracy: 0.5043 - val_loss: 3.2414 - val_accuracy: 0.2467\n",
      "Epoch 2648/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2719 - accuracy: 0.5029 - val_loss: 3.2479 - val_accuracy: 0.2433\n",
      "Epoch 2649/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2721 - accuracy: 0.5043 - val_loss: 3.2017 - val_accuracy: 0.2400\n",
      "Epoch 2650/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 1.2714 - accuracy: 0.5014 - val_loss: 3.2057 - val_accuracy: 0.2400\n",
      "Epoch 2651/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2711 - accuracy: 0.5014 - val_loss: 3.2178 - val_accuracy: 0.2433\n",
      "Epoch 2652/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2714 - accuracy: 0.5100 - val_loss: 3.2037 - val_accuracy: 0.2500\n",
      "Epoch 2653/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2721 - accuracy: 0.5086 - val_loss: 3.2682 - val_accuracy: 0.2433\n",
      "Epoch 2654/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2720 - accuracy: 0.5014 - val_loss: 3.2231 - val_accuracy: 0.2400\n",
      "Epoch 2655/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2713 - accuracy: 0.5043 - val_loss: 3.2401 - val_accuracy: 0.2367\n",
      "Epoch 2656/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2717 - accuracy: 0.5057 - val_loss: 3.2517 - val_accuracy: 0.2400\n",
      "Epoch 2657/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2710 - accuracy: 0.5014 - val_loss: 3.1837 - val_accuracy: 0.2367\n",
      "Epoch 2658/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2713 - accuracy: 0.5029 - val_loss: 3.2474 - val_accuracy: 0.2400\n",
      "Epoch 2659/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2710 - accuracy: 0.4971 - val_loss: 3.2049 - val_accuracy: 0.2367\n",
      "Epoch 2660/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2716 - accuracy: 0.5000 - val_loss: 3.2713 - val_accuracy: 0.2433\n",
      "Epoch 2661/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2724 - accuracy: 0.5000 - val_loss: 3.2303 - val_accuracy: 0.2367\n",
      "Epoch 2662/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2721 - accuracy: 0.5029 - val_loss: 3.2267 - val_accuracy: 0.2400\n",
      "Epoch 2663/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2708 - accuracy: 0.5071 - val_loss: 3.2114 - val_accuracy: 0.2367\n",
      "Epoch 2664/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2708 - accuracy: 0.5043 - val_loss: 3.2271 - val_accuracy: 0.2367\n",
      "Epoch 2665/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2715 - accuracy: 0.5043 - val_loss: 3.2102 - val_accuracy: 0.2367\n",
      "Epoch 2666/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2715 - accuracy: 0.5057 - val_loss: 3.2198 - val_accuracy: 0.2367\n",
      "Epoch 2667/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2706 - accuracy: 0.5114 - val_loss: 3.2256 - val_accuracy: 0.2433\n",
      "Epoch 2668/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2713 - accuracy: 0.5057 - val_loss: 3.2807 - val_accuracy: 0.2500\n",
      "Epoch 2669/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2707 - accuracy: 0.5086 - val_loss: 3.2578 - val_accuracy: 0.2433\n",
      "Epoch 2670/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2710 - accuracy: 0.5043 - val_loss: 3.2652 - val_accuracy: 0.2433\n",
      "Epoch 2671/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2712 - accuracy: 0.5071 - val_loss: 3.2614 - val_accuracy: 0.2400\n",
      "Epoch 2672/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2707 - accuracy: 0.5071 - val_loss: 3.2680 - val_accuracy: 0.2467\n",
      "Epoch 2673/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2713 - accuracy: 0.5086 - val_loss: 3.2224 - val_accuracy: 0.2433\n",
      "Epoch 2674/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2708 - accuracy: 0.5014 - val_loss: 3.2473 - val_accuracy: 0.2433\n",
      "Epoch 2675/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2707 - accuracy: 0.5029 - val_loss: 3.2115 - val_accuracy: 0.2367\n",
      "Epoch 2676/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2712 - accuracy: 0.5043 - val_loss: 3.2497 - val_accuracy: 0.2400\n",
      "Epoch 2677/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2711 - accuracy: 0.5014 - val_loss: 3.2751 - val_accuracy: 0.2467\n",
      "Epoch 2678/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2713 - accuracy: 0.5086 - val_loss: 3.2473 - val_accuracy: 0.2367\n",
      "Epoch 2679/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2710 - accuracy: 0.5029 - val_loss: 3.2511 - val_accuracy: 0.2467\n",
      "Epoch 2680/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2735 - accuracy: 0.5071 - val_loss: 3.2232 - val_accuracy: 0.2367\n",
      "Epoch 2681/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2709 - accuracy: 0.4986 - val_loss: 3.2741 - val_accuracy: 0.2367\n",
      "Epoch 2682/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2702 - accuracy: 0.5029 - val_loss: 3.2300 - val_accuracy: 0.2400\n",
      "Epoch 2683/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2708 - accuracy: 0.5029 - val_loss: 3.2582 - val_accuracy: 0.2433\n",
      "Epoch 2684/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2699 - accuracy: 0.5043 - val_loss: 3.2648 - val_accuracy: 0.2433\n",
      "Epoch 2685/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2706 - accuracy: 0.5043 - val_loss: 3.2406 - val_accuracy: 0.2400\n",
      "Epoch 2686/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2704 - accuracy: 0.5071 - val_loss: 3.2465 - val_accuracy: 0.2400\n",
      "Epoch 2687/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2700 - accuracy: 0.5014 - val_loss: 3.2375 - val_accuracy: 0.2333\n",
      "Epoch 2688/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2703 - accuracy: 0.5071 - val_loss: 3.2737 - val_accuracy: 0.2433\n",
      "Epoch 2689/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2697 - accuracy: 0.5071 - val_loss: 3.2548 - val_accuracy: 0.2433\n",
      "Epoch 2690/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2707 - accuracy: 0.5071 - val_loss: 3.1897 - val_accuracy: 0.2400\n",
      "Epoch 2691/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2706 - accuracy: 0.5029 - val_loss: 3.2644 - val_accuracy: 0.2467\n",
      "Epoch 2692/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2697 - accuracy: 0.5029 - val_loss: 3.2541 - val_accuracy: 0.2367\n",
      "Epoch 2693/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2698 - accuracy: 0.5057 - val_loss: 3.2791 - val_accuracy: 0.2433\n",
      "Epoch 2694/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2701 - accuracy: 0.5029 - val_loss: 3.2400 - val_accuracy: 0.2433\n",
      "Epoch 2695/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2691 - accuracy: 0.5071 - val_loss: 3.2574 - val_accuracy: 0.2467\n",
      "Epoch 2696/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2696 - accuracy: 0.5086 - val_loss: 3.2422 - val_accuracy: 0.2367\n",
      "Epoch 2697/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2706 - accuracy: 0.5057 - val_loss: 3.2268 - val_accuracy: 0.2400\n",
      "Epoch 2698/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2699 - accuracy: 0.5057 - val_loss: 3.2648 - val_accuracy: 0.2367\n",
      "Epoch 2699/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2700 - accuracy: 0.5057 - val_loss: 3.2811 - val_accuracy: 0.2467\n",
      "Epoch 2700/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2696 - accuracy: 0.5043 - val_loss: 3.2638 - val_accuracy: 0.2467\n",
      "Epoch 2701/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2701 - accuracy: 0.5057 - val_loss: 3.2801 - val_accuracy: 0.2433\n",
      "Epoch 2702/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2697 - accuracy: 0.5071 - val_loss: 3.2794 - val_accuracy: 0.2367\n",
      "Epoch 2703/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2693 - accuracy: 0.5057 - val_loss: 3.2559 - val_accuracy: 0.2433\n",
      "Epoch 2704/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2691 - accuracy: 0.5043 - val_loss: 3.2291 - val_accuracy: 0.2433\n",
      "Epoch 2705/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 101us/step - loss: 1.2694 - accuracy: 0.5043 - val_loss: 3.2502 - val_accuracy: 0.2467\n",
      "Epoch 2706/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2700 - accuracy: 0.5057 - val_loss: 3.2647 - val_accuracy: 0.2467\n",
      "Epoch 2707/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2702 - accuracy: 0.5043 - val_loss: 3.2682 - val_accuracy: 0.2400\n",
      "Epoch 2708/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2695 - accuracy: 0.5029 - val_loss: 3.2695 - val_accuracy: 0.2400\n",
      "Epoch 2709/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2690 - accuracy: 0.5043 - val_loss: 3.2455 - val_accuracy: 0.2367\n",
      "Epoch 2710/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2696 - accuracy: 0.5000 - val_loss: 3.2431 - val_accuracy: 0.2367\n",
      "Epoch 2711/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2698 - accuracy: 0.5057 - val_loss: 3.2415 - val_accuracy: 0.2433\n",
      "Epoch 2712/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2690 - accuracy: 0.5014 - val_loss: 3.2078 - val_accuracy: 0.2400\n",
      "Epoch 2713/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2695 - accuracy: 0.5071 - val_loss: 3.2908 - val_accuracy: 0.2500\n",
      "Epoch 2714/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2691 - accuracy: 0.5029 - val_loss: 3.2943 - val_accuracy: 0.2467\n",
      "Epoch 2715/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2697 - accuracy: 0.5071 - val_loss: 3.2615 - val_accuracy: 0.2433\n",
      "Epoch 2716/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2691 - accuracy: 0.5057 - val_loss: 3.2411 - val_accuracy: 0.2433\n",
      "Epoch 2717/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2690 - accuracy: 0.5057 - val_loss: 3.2610 - val_accuracy: 0.2433\n",
      "Epoch 2718/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2695 - accuracy: 0.5057 - val_loss: 3.2803 - val_accuracy: 0.2467\n",
      "Epoch 2719/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2692 - accuracy: 0.5057 - val_loss: 3.2434 - val_accuracy: 0.2433\n",
      "Epoch 2720/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2693 - accuracy: 0.5043 - val_loss: 3.2631 - val_accuracy: 0.2400\n",
      "Epoch 2721/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2695 - accuracy: 0.4986 - val_loss: 3.2488 - val_accuracy: 0.2367\n",
      "Epoch 2722/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2690 - accuracy: 0.5043 - val_loss: 3.2687 - val_accuracy: 0.2467\n",
      "Epoch 2723/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2695 - accuracy: 0.5057 - val_loss: 3.2878 - val_accuracy: 0.2467\n",
      "Epoch 2724/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2692 - accuracy: 0.5029 - val_loss: 3.2782 - val_accuracy: 0.2467\n",
      "Epoch 2725/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2685 - accuracy: 0.5057 - val_loss: 3.2927 - val_accuracy: 0.2467\n",
      "Epoch 2726/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2684 - accuracy: 0.5029 - val_loss: 3.3024 - val_accuracy: 0.2467\n",
      "Epoch 2727/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2683 - accuracy: 0.5071 - val_loss: 3.2825 - val_accuracy: 0.2433\n",
      "Epoch 2728/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2679 - accuracy: 0.5014 - val_loss: 3.2271 - val_accuracy: 0.2433\n",
      "Epoch 2729/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2685 - accuracy: 0.5057 - val_loss: 3.2757 - val_accuracy: 0.2433\n",
      "Epoch 2730/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2684 - accuracy: 0.5086 - val_loss: 3.2483 - val_accuracy: 0.2400\n",
      "Epoch 2731/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2682 - accuracy: 0.5029 - val_loss: 3.2691 - val_accuracy: 0.2400\n",
      "Epoch 2732/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2694 - accuracy: 0.5057 - val_loss: 3.2951 - val_accuracy: 0.2433\n",
      "Epoch 2733/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2699 - accuracy: 0.5029 - val_loss: 3.2470 - val_accuracy: 0.2367\n",
      "Epoch 2734/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2678 - accuracy: 0.5129 - val_loss: 3.2634 - val_accuracy: 0.2433\n",
      "Epoch 2735/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2682 - accuracy: 0.5057 - val_loss: 3.2759 - val_accuracy: 0.2400\n",
      "Epoch 2736/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2681 - accuracy: 0.5114 - val_loss: 3.2153 - val_accuracy: 0.2367\n",
      "Epoch 2737/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2677 - accuracy: 0.5129 - val_loss: 3.3035 - val_accuracy: 0.2500\n",
      "Epoch 2738/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2681 - accuracy: 0.5086 - val_loss: 3.2889 - val_accuracy: 0.2367\n",
      "Epoch 2739/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2678 - accuracy: 0.5100 - val_loss: 3.3000 - val_accuracy: 0.2433\n",
      "Epoch 2740/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2686 - accuracy: 0.5043 - val_loss: 3.2489 - val_accuracy: 0.2400\n",
      "Epoch 2741/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2690 - accuracy: 0.5029 - val_loss: 3.3021 - val_accuracy: 0.2400\n",
      "Epoch 2742/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2691 - accuracy: 0.5029 - val_loss: 3.2899 - val_accuracy: 0.2400\n",
      "Epoch 2743/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2683 - accuracy: 0.5000 - val_loss: 3.2713 - val_accuracy: 0.2400\n",
      "Epoch 2744/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2688 - accuracy: 0.5029 - val_loss: 3.2881 - val_accuracy: 0.2433\n",
      "Epoch 2745/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2683 - accuracy: 0.5014 - val_loss: 3.2947 - val_accuracy: 0.2433\n",
      "Epoch 2746/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2684 - accuracy: 0.5071 - val_loss: 3.2999 - val_accuracy: 0.2433\n",
      "Epoch 2747/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2686 - accuracy: 0.5014 - val_loss: 3.2655 - val_accuracy: 0.2367\n",
      "Epoch 2748/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2681 - accuracy: 0.5057 - val_loss: 3.3114 - val_accuracy: 0.2467\n",
      "Epoch 2749/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2682 - accuracy: 0.5029 - val_loss: 3.2902 - val_accuracy: 0.2433\n",
      "Epoch 2750/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2677 - accuracy: 0.5071 - val_loss: 3.3078 - val_accuracy: 0.2467\n",
      "Epoch 2751/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2679 - accuracy: 0.5057 - val_loss: 3.2918 - val_accuracy: 0.2433\n",
      "Epoch 2752/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2674 - accuracy: 0.5100 - val_loss: 3.2849 - val_accuracy: 0.2367\n",
      "Epoch 2753/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2673 - accuracy: 0.5057 - val_loss: 3.2983 - val_accuracy: 0.2500\n",
      "Epoch 2754/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2682 - accuracy: 0.5071 - val_loss: 3.2634 - val_accuracy: 0.2400\n",
      "Epoch 2755/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2668 - accuracy: 0.5029 - val_loss: 3.2423 - val_accuracy: 0.2433\n",
      "Epoch 2756/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2676 - accuracy: 0.5057 - val_loss: 3.3065 - val_accuracy: 0.2467\n",
      "Epoch 2757/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2685 - accuracy: 0.5043 - val_loss: 3.2728 - val_accuracy: 0.2433\n",
      "Epoch 2758/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2683 - accuracy: 0.5057 - val_loss: 3.2149 - val_accuracy: 0.2367\n",
      "Epoch 2759/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2678 - accuracy: 0.5086 - val_loss: 3.3059 - val_accuracy: 0.2433\n",
      "Epoch 2760/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 102us/step - loss: 1.2676 - accuracy: 0.5071 - val_loss: 3.2988 - val_accuracy: 0.2467\n",
      "Epoch 2761/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2672 - accuracy: 0.5014 - val_loss: 3.2880 - val_accuracy: 0.2467\n",
      "Epoch 2762/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2672 - accuracy: 0.5129 - val_loss: 3.2748 - val_accuracy: 0.2367\n",
      "Epoch 2763/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2680 - accuracy: 0.5057 - val_loss: 3.3126 - val_accuracy: 0.2400\n",
      "Epoch 2764/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2662 - accuracy: 0.5000 - val_loss: 3.3193 - val_accuracy: 0.2467\n",
      "Epoch 2765/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2673 - accuracy: 0.5029 - val_loss: 3.2818 - val_accuracy: 0.2433\n",
      "Epoch 2766/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2666 - accuracy: 0.5100 - val_loss: 3.3025 - val_accuracy: 0.2433\n",
      "Epoch 2767/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2676 - accuracy: 0.5129 - val_loss: 3.3060 - val_accuracy: 0.2400\n",
      "Epoch 2768/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2670 - accuracy: 0.5114 - val_loss: 3.3141 - val_accuracy: 0.2467\n",
      "Epoch 2769/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2664 - accuracy: 0.5071 - val_loss: 3.3091 - val_accuracy: 0.2433\n",
      "Epoch 2770/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2668 - accuracy: 0.5071 - val_loss: 3.2770 - val_accuracy: 0.2367\n",
      "Epoch 2771/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2662 - accuracy: 0.5100 - val_loss: 3.2704 - val_accuracy: 0.2367\n",
      "Epoch 2772/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2694 - accuracy: 0.5071 - val_loss: 3.2732 - val_accuracy: 0.2400\n",
      "Epoch 2773/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2670 - accuracy: 0.5057 - val_loss: 3.2934 - val_accuracy: 0.2400\n",
      "Epoch 2774/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2668 - accuracy: 0.5043 - val_loss: 3.3001 - val_accuracy: 0.2467\n",
      "Epoch 2775/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2668 - accuracy: 0.5043 - val_loss: 3.2830 - val_accuracy: 0.2400\n",
      "Epoch 2776/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2671 - accuracy: 0.5071 - val_loss: 3.2994 - val_accuracy: 0.2433\n",
      "Epoch 2777/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2674 - accuracy: 0.5057 - val_loss: 3.3273 - val_accuracy: 0.2467\n",
      "Epoch 2778/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2672 - accuracy: 0.5043 - val_loss: 3.3110 - val_accuracy: 0.2400\n",
      "Epoch 2779/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2660 - accuracy: 0.5100 - val_loss: 3.2880 - val_accuracy: 0.2433\n",
      "Epoch 2780/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.2666 - accuracy: 0.5029 - val_loss: 3.3233 - val_accuracy: 0.2467\n",
      "Epoch 2781/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2675 - accuracy: 0.5014 - val_loss: 3.3073 - val_accuracy: 0.2433\n",
      "Epoch 2782/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2665 - accuracy: 0.5071 - val_loss: 3.2525 - val_accuracy: 0.2367\n",
      "Epoch 2783/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2664 - accuracy: 0.5043 - val_loss: 3.3217 - val_accuracy: 0.2467\n",
      "Epoch 2784/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2659 - accuracy: 0.5029 - val_loss: 3.3161 - val_accuracy: 0.2467\n",
      "Epoch 2785/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2665 - accuracy: 0.5086 - val_loss: 3.2930 - val_accuracy: 0.2400\n",
      "Epoch 2786/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2668 - accuracy: 0.5100 - val_loss: 3.2067 - val_accuracy: 0.2433\n",
      "Epoch 2787/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2670 - accuracy: 0.5057 - val_loss: 3.3028 - val_accuracy: 0.2433\n",
      "Epoch 2788/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2662 - accuracy: 0.5057 - val_loss: 3.3421 - val_accuracy: 0.2433\n",
      "Epoch 2789/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2661 - accuracy: 0.5043 - val_loss: 3.3268 - val_accuracy: 0.2400\n",
      "Epoch 2790/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2663 - accuracy: 0.5057 - val_loss: 3.3288 - val_accuracy: 0.2433\n",
      "Epoch 2791/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2668 - accuracy: 0.5043 - val_loss: 3.2641 - val_accuracy: 0.2400\n",
      "Epoch 2792/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2661 - accuracy: 0.5029 - val_loss: 3.2729 - val_accuracy: 0.2400\n",
      "Epoch 2793/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2659 - accuracy: 0.5057 - val_loss: 3.2618 - val_accuracy: 0.2367\n",
      "Epoch 2794/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2668 - accuracy: 0.5057 - val_loss: 3.3166 - val_accuracy: 0.2467\n",
      "Epoch 2795/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2657 - accuracy: 0.5057 - val_loss: 3.2778 - val_accuracy: 0.2333\n",
      "Epoch 2796/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2659 - accuracy: 0.5057 - val_loss: 3.3176 - val_accuracy: 0.2467\n",
      "Epoch 2797/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2662 - accuracy: 0.5057 - val_loss: 3.3043 - val_accuracy: 0.2400\n",
      "Epoch 2798/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2653 - accuracy: 0.5114 - val_loss: 3.3345 - val_accuracy: 0.2433\n",
      "Epoch 2799/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2657 - accuracy: 0.5071 - val_loss: 3.2826 - val_accuracy: 0.2400\n",
      "Epoch 2800/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2667 - accuracy: 0.5014 - val_loss: 3.3126 - val_accuracy: 0.2433\n",
      "Epoch 2801/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2663 - accuracy: 0.5086 - val_loss: 3.3535 - val_accuracy: 0.2400\n",
      "Epoch 2802/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2661 - accuracy: 0.5071 - val_loss: 3.3291 - val_accuracy: 0.2433\n",
      "Epoch 2803/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2659 - accuracy: 0.5086 - val_loss: 3.3064 - val_accuracy: 0.2433\n",
      "Epoch 2804/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2655 - accuracy: 0.5043 - val_loss: 3.3189 - val_accuracy: 0.2467\n",
      "Epoch 2805/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2655 - accuracy: 0.5057 - val_loss: 3.3457 - val_accuracy: 0.2433\n",
      "Epoch 2806/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2657 - accuracy: 0.5029 - val_loss: 3.3388 - val_accuracy: 0.2467\n",
      "Epoch 2807/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2658 - accuracy: 0.5057 - val_loss: 3.3205 - val_accuracy: 0.2500\n",
      "Epoch 2808/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2651 - accuracy: 0.5071 - val_loss: 3.2964 - val_accuracy: 0.2467\n",
      "Epoch 2809/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2653 - accuracy: 0.5043 - val_loss: 3.3302 - val_accuracy: 0.2467\n",
      "Epoch 2810/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2653 - accuracy: 0.5057 - val_loss: 3.3129 - val_accuracy: 0.2467\n",
      "Epoch 2811/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2648 - accuracy: 0.5029 - val_loss: 3.3305 - val_accuracy: 0.2467\n",
      "Epoch 2812/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2657 - accuracy: 0.5071 - val_loss: 3.3072 - val_accuracy: 0.2433\n",
      "Epoch 2813/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2659 - accuracy: 0.5129 - val_loss: 3.3457 - val_accuracy: 0.2433\n",
      "Epoch 2814/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2652 - accuracy: 0.5043 - val_loss: 3.3085 - val_accuracy: 0.2367\n",
      "Epoch 2815/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 102us/step - loss: 1.2656 - accuracy: 0.5071 - val_loss: 3.3446 - val_accuracy: 0.2433\n",
      "Epoch 2816/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2658 - accuracy: 0.5071 - val_loss: 3.3064 - val_accuracy: 0.2433\n",
      "Epoch 2817/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2651 - accuracy: 0.5057 - val_loss: 3.3311 - val_accuracy: 0.2433\n",
      "Epoch 2818/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2654 - accuracy: 0.5057 - val_loss: 3.3211 - val_accuracy: 0.2433\n",
      "Epoch 2819/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2651 - accuracy: 0.5071 - val_loss: 3.3147 - val_accuracy: 0.2467\n",
      "Epoch 2820/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2657 - accuracy: 0.5057 - val_loss: 3.2952 - val_accuracy: 0.2367\n",
      "Epoch 2821/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2656 - accuracy: 0.5029 - val_loss: 3.3052 - val_accuracy: 0.2400\n",
      "Epoch 2822/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2652 - accuracy: 0.5100 - val_loss: 3.3329 - val_accuracy: 0.2400\n",
      "Epoch 2823/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2646 - accuracy: 0.5057 - val_loss: 3.3397 - val_accuracy: 0.2400\n",
      "Epoch 2824/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2645 - accuracy: 0.5086 - val_loss: 3.3356 - val_accuracy: 0.2400\n",
      "Epoch 2825/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2650 - accuracy: 0.5071 - val_loss: 3.3444 - val_accuracy: 0.2467\n",
      "Epoch 2826/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2643 - accuracy: 0.5086 - val_loss: 3.3495 - val_accuracy: 0.2433\n",
      "Epoch 2827/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2654 - accuracy: 0.5043 - val_loss: 3.3040 - val_accuracy: 0.2367\n",
      "Epoch 2828/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2654 - accuracy: 0.5071 - val_loss: 3.3586 - val_accuracy: 0.2433\n",
      "Epoch 2829/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2652 - accuracy: 0.5043 - val_loss: 3.3067 - val_accuracy: 0.2400\n",
      "Epoch 2830/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2638 - accuracy: 0.5057 - val_loss: 3.3115 - val_accuracy: 0.2433\n",
      "Epoch 2831/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2652 - accuracy: 0.5143 - val_loss: 3.2955 - val_accuracy: 0.2433\n",
      "Epoch 2832/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2644 - accuracy: 0.5114 - val_loss: 3.3699 - val_accuracy: 0.2467\n",
      "Epoch 2833/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2645 - accuracy: 0.5086 - val_loss: 3.3226 - val_accuracy: 0.2433\n",
      "Epoch 2834/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2648 - accuracy: 0.5029 - val_loss: 3.3242 - val_accuracy: 0.2400\n",
      "Epoch 2835/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2643 - accuracy: 0.5014 - val_loss: 3.3545 - val_accuracy: 0.2433\n",
      "Epoch 2836/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2647 - accuracy: 0.5057 - val_loss: 3.3259 - val_accuracy: 0.2400\n",
      "Epoch 2837/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2642 - accuracy: 0.5086 - val_loss: 3.3462 - val_accuracy: 0.2433\n",
      "Epoch 2838/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2648 - accuracy: 0.5057 - val_loss: 3.2648 - val_accuracy: 0.2400\n",
      "Epoch 2839/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2644 - accuracy: 0.5100 - val_loss: 3.3333 - val_accuracy: 0.2433\n",
      "Epoch 2840/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2645 - accuracy: 0.5029 - val_loss: 3.3324 - val_accuracy: 0.2400\n",
      "Epoch 2841/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2641 - accuracy: 0.5029 - val_loss: 3.3327 - val_accuracy: 0.2467\n",
      "Epoch 2842/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2642 - accuracy: 0.5071 - val_loss: 3.3189 - val_accuracy: 0.2433\n",
      "Epoch 2843/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2644 - accuracy: 0.5057 - val_loss: 3.3272 - val_accuracy: 0.2367\n",
      "Epoch 2844/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2637 - accuracy: 0.5057 - val_loss: 3.3435 - val_accuracy: 0.2467\n",
      "Epoch 2845/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2646 - accuracy: 0.5086 - val_loss: 3.3650 - val_accuracy: 0.2433\n",
      "Epoch 2846/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2636 - accuracy: 0.5071 - val_loss: 3.3953 - val_accuracy: 0.2467\n",
      "Epoch 2847/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2643 - accuracy: 0.5057 - val_loss: 3.3488 - val_accuracy: 0.2433\n",
      "Epoch 2848/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2635 - accuracy: 0.5086 - val_loss: 3.3164 - val_accuracy: 0.2400\n",
      "Epoch 2849/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2641 - accuracy: 0.5100 - val_loss: 3.3499 - val_accuracy: 0.2400\n",
      "Epoch 2850/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2641 - accuracy: 0.5086 - val_loss: 3.3427 - val_accuracy: 0.2367\n",
      "Epoch 2851/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2641 - accuracy: 0.5057 - val_loss: 3.3421 - val_accuracy: 0.2367\n",
      "Epoch 2852/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2640 - accuracy: 0.5071 - val_loss: 3.3851 - val_accuracy: 0.2467\n",
      "Epoch 2853/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2638 - accuracy: 0.5043 - val_loss: 3.3501 - val_accuracy: 0.2467\n",
      "Epoch 2854/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2641 - accuracy: 0.5057 - val_loss: 3.3043 - val_accuracy: 0.2400\n",
      "Epoch 2855/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2637 - accuracy: 0.5086 - val_loss: 3.3529 - val_accuracy: 0.2400\n",
      "Epoch 2856/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2635 - accuracy: 0.5043 - val_loss: 3.3563 - val_accuracy: 0.2367\n",
      "Epoch 2857/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2635 - accuracy: 0.5086 - val_loss: 3.3665 - val_accuracy: 0.2467\n",
      "Epoch 2858/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2634 - accuracy: 0.5057 - val_loss: 3.3732 - val_accuracy: 0.2467\n",
      "Epoch 2859/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2632 - accuracy: 0.5029 - val_loss: 3.3128 - val_accuracy: 0.2400\n",
      "Epoch 2860/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2638 - accuracy: 0.5129 - val_loss: 3.2872 - val_accuracy: 0.2400\n",
      "Epoch 2861/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2636 - accuracy: 0.5100 - val_loss: 3.3611 - val_accuracy: 0.2433\n",
      "Epoch 2862/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2631 - accuracy: 0.5000 - val_loss: 3.3506 - val_accuracy: 0.2433\n",
      "Epoch 2863/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2631 - accuracy: 0.5043 - val_loss: 3.3461 - val_accuracy: 0.2433\n",
      "Epoch 2864/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2633 - accuracy: 0.5014 - val_loss: 3.3307 - val_accuracy: 0.2433\n",
      "Epoch 2865/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2639 - accuracy: 0.5143 - val_loss: 3.3578 - val_accuracy: 0.2400\n",
      "Epoch 2866/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2635 - accuracy: 0.5129 - val_loss: 3.3671 - val_accuracy: 0.2433\n",
      "Epoch 2867/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2631 - accuracy: 0.5100 - val_loss: 3.3584 - val_accuracy: 0.2467\n",
      "Epoch 2868/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2641 - accuracy: 0.5057 - val_loss: 3.3063 - val_accuracy: 0.2433\n",
      "Epoch 2869/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2631 - accuracy: 0.5057 - val_loss: 3.3450 - val_accuracy: 0.2467\n",
      "Epoch 2870/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 100us/step - loss: 1.2627 - accuracy: 0.5057 - val_loss: 3.4149 - val_accuracy: 0.2467\n",
      "Epoch 2871/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2637 - accuracy: 0.5086 - val_loss: 3.3790 - val_accuracy: 0.2467\n",
      "Epoch 2872/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2632 - accuracy: 0.5057 - val_loss: 3.3612 - val_accuracy: 0.2433\n",
      "Epoch 2873/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2630 - accuracy: 0.5129 - val_loss: 3.3120 - val_accuracy: 0.2400\n",
      "Epoch 2874/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2633 - accuracy: 0.5186 - val_loss: 3.3161 - val_accuracy: 0.2433\n",
      "Epoch 2875/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2629 - accuracy: 0.5086 - val_loss: 3.3516 - val_accuracy: 0.2467\n",
      "Epoch 2876/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2643 - accuracy: 0.5057 - val_loss: 3.3909 - val_accuracy: 0.2467\n",
      "Epoch 2877/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2633 - accuracy: 0.5043 - val_loss: 3.3774 - val_accuracy: 0.2433\n",
      "Epoch 2878/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2627 - accuracy: 0.5086 - val_loss: 3.3443 - val_accuracy: 0.2433\n",
      "Epoch 2879/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.3599 - val_accuracy: 0.2467\n",
      "Epoch 2880/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2623 - accuracy: 0.5071 - val_loss: 3.3822 - val_accuracy: 0.2400\n",
      "Epoch 2881/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2636 - accuracy: 0.5071 - val_loss: 3.3618 - val_accuracy: 0.2400\n",
      "Epoch 2882/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2630 - accuracy: 0.5057 - val_loss: 3.3054 - val_accuracy: 0.2400\n",
      "Epoch 2883/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2621 - accuracy: 0.5100 - val_loss: 3.2554 - val_accuracy: 0.2433\n",
      "Epoch 2884/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2629 - accuracy: 0.5071 - val_loss: 3.3988 - val_accuracy: 0.2433\n",
      "Epoch 2885/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2626 - accuracy: 0.5043 - val_loss: 3.3304 - val_accuracy: 0.2367\n",
      "Epoch 2886/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2627 - accuracy: 0.5086 - val_loss: 3.3512 - val_accuracy: 0.2433\n",
      "Epoch 2887/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2626 - accuracy: 0.5114 - val_loss: 3.3845 - val_accuracy: 0.2467\n",
      "Epoch 2888/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2623 - accuracy: 0.5029 - val_loss: 3.3403 - val_accuracy: 0.2467\n",
      "Epoch 2889/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2628 - accuracy: 0.5129 - val_loss: 3.3105 - val_accuracy: 0.2400\n",
      "Epoch 2890/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2627 - accuracy: 0.5114 - val_loss: 3.3306 - val_accuracy: 0.2433\n",
      "Epoch 2891/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2628 - accuracy: 0.5043 - val_loss: 3.3622 - val_accuracy: 0.2467\n",
      "Epoch 2892/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2626 - accuracy: 0.5043 - val_loss: 3.3681 - val_accuracy: 0.2467\n",
      "Epoch 2893/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2636 - accuracy: 0.5057 - val_loss: 3.3630 - val_accuracy: 0.2433\n",
      "Epoch 2894/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2626 - accuracy: 0.5057 - val_loss: 3.4042 - val_accuracy: 0.2467\n",
      "Epoch 2895/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2620 - accuracy: 0.5086 - val_loss: 3.3810 - val_accuracy: 0.2400\n",
      "Epoch 2896/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2625 - accuracy: 0.5086 - val_loss: 3.3710 - val_accuracy: 0.2433\n",
      "Epoch 2897/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2627 - accuracy: 0.5114 - val_loss: 3.4127 - val_accuracy: 0.2400\n",
      "Epoch 2898/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2622 - accuracy: 0.5071 - val_loss: 3.3813 - val_accuracy: 0.2400\n",
      "Epoch 2899/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2624 - accuracy: 0.5100 - val_loss: 3.3686 - val_accuracy: 0.2433\n",
      "Epoch 2900/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2616 - accuracy: 0.5100 - val_loss: 3.3612 - val_accuracy: 0.2433\n",
      "Epoch 2901/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2619 - accuracy: 0.5114 - val_loss: 3.3752 - val_accuracy: 0.2400\n",
      "Epoch 2902/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2625 - accuracy: 0.5100 - val_loss: 3.4206 - val_accuracy: 0.2467\n",
      "Epoch 2903/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2625 - accuracy: 0.5086 - val_loss: 3.3530 - val_accuracy: 0.2400\n",
      "Epoch 2904/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2620 - accuracy: 0.5100 - val_loss: 3.3491 - val_accuracy: 0.2400\n",
      "Epoch 2905/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2617 - accuracy: 0.5114 - val_loss: 3.3764 - val_accuracy: 0.2433\n",
      "Epoch 2906/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.3757 - val_accuracy: 0.2467\n",
      "Epoch 2907/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2611 - accuracy: 0.5057 - val_loss: 3.3800 - val_accuracy: 0.2467\n",
      "Epoch 2908/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2615 - accuracy: 0.5171 - val_loss: 3.4058 - val_accuracy: 0.2400\n",
      "Epoch 2909/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2618 - accuracy: 0.5029 - val_loss: 3.3454 - val_accuracy: 0.2433\n",
      "Epoch 2910/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2617 - accuracy: 0.5143 - val_loss: 3.3665 - val_accuracy: 0.2433\n",
      "Epoch 2911/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2620 - accuracy: 0.5029 - val_loss: 3.3131 - val_accuracy: 0.2333\n",
      "Epoch 2912/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2621 - accuracy: 0.5057 - val_loss: 3.3230 - val_accuracy: 0.2367\n",
      "Epoch 2913/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2621 - accuracy: 0.5043 - val_loss: 3.3574 - val_accuracy: 0.2433\n",
      "Epoch 2914/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2616 - accuracy: 0.5057 - val_loss: 3.3507 - val_accuracy: 0.2400\n",
      "Epoch 2915/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2620 - accuracy: 0.5071 - val_loss: 3.3117 - val_accuracy: 0.2367\n",
      "Epoch 2916/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.4026 - val_accuracy: 0.2467\n",
      "Epoch 2917/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2614 - accuracy: 0.5114 - val_loss: 3.3731 - val_accuracy: 0.2467\n",
      "Epoch 2918/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2616 - accuracy: 0.5129 - val_loss: 3.3862 - val_accuracy: 0.2467\n",
      "Epoch 2919/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2611 - accuracy: 0.5100 - val_loss: 3.3899 - val_accuracy: 0.2433\n",
      "Epoch 2920/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2608 - accuracy: 0.5071 - val_loss: 3.3499 - val_accuracy: 0.2367\n",
      "Epoch 2921/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2613 - accuracy: 0.5100 - val_loss: 3.3484 - val_accuracy: 0.2400\n",
      "Epoch 2922/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2610 - accuracy: 0.5057 - val_loss: 3.3905 - val_accuracy: 0.2400\n",
      "Epoch 2923/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2609 - accuracy: 0.5129 - val_loss: 3.3561 - val_accuracy: 0.2467\n",
      "Epoch 2924/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2613 - accuracy: 0.5114 - val_loss: 3.3779 - val_accuracy: 0.2467\n",
      "Epoch 2925/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 1.2608 - accuracy: 0.5100 - val_loss: 3.4046 - val_accuracy: 0.2433\n",
      "Epoch 2926/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2613 - accuracy: 0.5114 - val_loss: 3.3811 - val_accuracy: 0.2433\n",
      "Epoch 2927/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2618 - accuracy: 0.5086 - val_loss: 3.4173 - val_accuracy: 0.2467\n",
      "Epoch 2928/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2611 - accuracy: 0.5100 - val_loss: 3.3681 - val_accuracy: 0.2433\n",
      "Epoch 2929/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2606 - accuracy: 0.5086 - val_loss: 3.3886 - val_accuracy: 0.2467\n",
      "Epoch 2930/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2604 - accuracy: 0.5057 - val_loss: 3.4308 - val_accuracy: 0.2467\n",
      "Epoch 2931/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2609 - accuracy: 0.5071 - val_loss: 3.4096 - val_accuracy: 0.2433\n",
      "Epoch 2932/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2608 - accuracy: 0.5043 - val_loss: 3.3770 - val_accuracy: 0.2433\n",
      "Epoch 2933/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2604 - accuracy: 0.5129 - val_loss: 3.3914 - val_accuracy: 0.2400\n",
      "Epoch 2934/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2614 - accuracy: 0.5100 - val_loss: 3.4000 - val_accuracy: 0.2467\n",
      "Epoch 2935/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2613 - accuracy: 0.5114 - val_loss: 3.3797 - val_accuracy: 0.2400\n",
      "Epoch 2936/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2602 - accuracy: 0.5129 - val_loss: 3.3810 - val_accuracy: 0.2467\n",
      "Epoch 2937/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2610 - accuracy: 0.5114 - val_loss: 3.4107 - val_accuracy: 0.2433\n",
      "Epoch 2938/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2619 - accuracy: 0.5086 - val_loss: 3.3753 - val_accuracy: 0.2467\n",
      "Epoch 2939/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2610 - accuracy: 0.5086 - val_loss: 3.3962 - val_accuracy: 0.2467\n",
      "Epoch 2940/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2604 - accuracy: 0.5100 - val_loss: 3.4034 - val_accuracy: 0.2400\n",
      "Epoch 2941/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2597 - accuracy: 0.5071 - val_loss: 3.3383 - val_accuracy: 0.2400\n",
      "Epoch 2942/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2626 - accuracy: 0.5100 - val_loss: 3.3910 - val_accuracy: 0.2433\n",
      "Epoch 2943/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2603 - accuracy: 0.5114 - val_loss: 3.4167 - val_accuracy: 0.2433\n",
      "Epoch 2944/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2603 - accuracy: 0.5114 - val_loss: 3.3795 - val_accuracy: 0.2433\n",
      "Epoch 2945/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2602 - accuracy: 0.5114 - val_loss: 3.4175 - val_accuracy: 0.2467\n",
      "Epoch 2946/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2602 - accuracy: 0.5071 - val_loss: 3.4193 - val_accuracy: 0.2433\n",
      "Epoch 2947/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2605 - accuracy: 0.5100 - val_loss: 3.3645 - val_accuracy: 0.2433\n",
      "Epoch 2948/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2601 - accuracy: 0.5071 - val_loss: 3.4020 - val_accuracy: 0.2433\n",
      "Epoch 2949/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2612 - accuracy: 0.5114 - val_loss: 3.3740 - val_accuracy: 0.2367\n",
      "Epoch 2950/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2602 - accuracy: 0.5157 - val_loss: 3.3758 - val_accuracy: 0.2433\n",
      "Epoch 2951/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2606 - accuracy: 0.5114 - val_loss: 3.4402 - val_accuracy: 0.2400\n",
      "Epoch 2952/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2603 - accuracy: 0.5100 - val_loss: 3.4025 - val_accuracy: 0.2367\n",
      "Epoch 2953/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2600 - accuracy: 0.5100 - val_loss: 3.4009 - val_accuracy: 0.2467\n",
      "Epoch 2954/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.3987 - val_accuracy: 0.2433\n",
      "Epoch 2955/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2600 - accuracy: 0.5086 - val_loss: 3.3483 - val_accuracy: 0.2400\n",
      "Epoch 2956/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2604 - accuracy: 0.5071 - val_loss: 3.3517 - val_accuracy: 0.2367\n",
      "Epoch 2957/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2601 - accuracy: 0.5129 - val_loss: 3.4081 - val_accuracy: 0.2433\n",
      "Epoch 2958/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2607 - accuracy: 0.5086 - val_loss: 3.3981 - val_accuracy: 0.2433\n",
      "Epoch 2959/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2602 - accuracy: 0.5057 - val_loss: 3.3814 - val_accuracy: 0.2433\n",
      "Epoch 2960/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2604 - accuracy: 0.5143 - val_loss: 3.3939 - val_accuracy: 0.2400\n",
      "Epoch 2961/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2596 - accuracy: 0.5171 - val_loss: 3.3864 - val_accuracy: 0.2400\n",
      "Epoch 2962/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2601 - accuracy: 0.5071 - val_loss: 3.4121 - val_accuracy: 0.2433\n",
      "Epoch 2963/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2595 - accuracy: 0.5114 - val_loss: 3.3911 - val_accuracy: 0.2433\n",
      "Epoch 2964/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2598 - accuracy: 0.5057 - val_loss: 3.3788 - val_accuracy: 0.2400\n",
      "Epoch 2965/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2599 - accuracy: 0.5129 - val_loss: 3.3494 - val_accuracy: 0.2400\n",
      "Epoch 2966/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2597 - accuracy: 0.5086 - val_loss: 3.3748 - val_accuracy: 0.2367\n",
      "Epoch 2967/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2599 - accuracy: 0.5057 - val_loss: 3.3782 - val_accuracy: 0.2433\n",
      "Epoch 2968/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2596 - accuracy: 0.5043 - val_loss: 3.4237 - val_accuracy: 0.2433\n",
      "Epoch 2969/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2599 - accuracy: 0.5143 - val_loss: 3.4195 - val_accuracy: 0.2433\n",
      "Epoch 2970/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2588 - accuracy: 0.5129 - val_loss: 3.4507 - val_accuracy: 0.2433\n",
      "Epoch 2971/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2598 - accuracy: 0.5086 - val_loss: 3.3750 - val_accuracy: 0.2467\n",
      "Epoch 2972/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2598 - accuracy: 0.5129 - val_loss: 3.3832 - val_accuracy: 0.2433\n",
      "Epoch 2973/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2595 - accuracy: 0.5086 - val_loss: 3.3602 - val_accuracy: 0.2400\n",
      "Epoch 2974/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2591 - accuracy: 0.5129 - val_loss: 3.3969 - val_accuracy: 0.2433\n",
      "Epoch 2975/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2595 - accuracy: 0.5100 - val_loss: 3.4095 - val_accuracy: 0.2433\n",
      "Epoch 2976/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2595 - accuracy: 0.5100 - val_loss: 3.4135 - val_accuracy: 0.2433\n",
      "Epoch 2977/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2589 - accuracy: 0.5100 - val_loss: 3.4090 - val_accuracy: 0.2400\n",
      "Epoch 2978/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2587 - accuracy: 0.5143 - val_loss: 3.4170 - val_accuracy: 0.2467\n",
      "Epoch 2979/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2591 - accuracy: 0.5129 - val_loss: 3.3656 - val_accuracy: 0.2467\n",
      "Epoch 2980/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 102us/step - loss: 1.2588 - accuracy: 0.5071 - val_loss: 3.4359 - val_accuracy: 0.2467\n",
      "Epoch 2981/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2594 - accuracy: 0.5114 - val_loss: 3.4116 - val_accuracy: 0.2467\n",
      "Epoch 2982/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2595 - accuracy: 0.5114 - val_loss: 3.3728 - val_accuracy: 0.2433\n",
      "Epoch 2983/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2593 - accuracy: 0.5114 - val_loss: 3.4204 - val_accuracy: 0.2433\n",
      "Epoch 2984/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2587 - accuracy: 0.5129 - val_loss: 3.4150 - val_accuracy: 0.2467\n",
      "Epoch 2985/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2592 - accuracy: 0.5114 - val_loss: 3.4272 - val_accuracy: 0.2467\n",
      "Epoch 2986/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2587 - accuracy: 0.5129 - val_loss: 3.4170 - val_accuracy: 0.2433\n",
      "Epoch 2987/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2592 - accuracy: 0.5114 - val_loss: 3.4234 - val_accuracy: 0.2433\n",
      "Epoch 2988/3000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.2591 - accuracy: 0.5143 - val_loss: 3.4228 - val_accuracy: 0.2400\n",
      "Epoch 2989/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2587 - accuracy: 0.5071 - val_loss: 3.4008 - val_accuracy: 0.2433\n",
      "Epoch 2990/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2586 - accuracy: 0.5129 - val_loss: 3.4220 - val_accuracy: 0.2433\n",
      "Epoch 2991/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2596 - accuracy: 0.5143 - val_loss: 3.3987 - val_accuracy: 0.2433\n",
      "Epoch 2992/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2594 - accuracy: 0.5114 - val_loss: 3.4029 - val_accuracy: 0.2467\n",
      "Epoch 2993/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2589 - accuracy: 0.5086 - val_loss: 3.4200 - val_accuracy: 0.2433\n",
      "Epoch 2994/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2589 - accuracy: 0.5100 - val_loss: 3.3714 - val_accuracy: 0.2467\n",
      "Epoch 2995/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2583 - accuracy: 0.5071 - val_loss: 3.4406 - val_accuracy: 0.2467\n",
      "Epoch 2996/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2586 - accuracy: 0.5114 - val_loss: 3.4515 - val_accuracy: 0.2467\n",
      "Epoch 2997/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2585 - accuracy: 0.5100 - val_loss: 3.3971 - val_accuracy: 0.2400\n",
      "Epoch 2998/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2587 - accuracy: 0.5114 - val_loss: 3.4285 - val_accuracy: 0.2433\n",
      "Epoch 2999/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2585 - accuracy: 0.5071 - val_loss: 3.4221 - val_accuracy: 0.2433\n",
      "Epoch 3000/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2591 - accuracy: 0.5086 - val_loss: 3.4185 - val_accuracy: 0.2467\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(xTrain,yTrain,epochs=3000,batch_size=10, validation_data=(xVal,yVal))\n",
    "#에폭 높게 줌 -> 오버피팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax=plt.subplots()\n",
    "acc_ax=loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='upper right')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 14us/step\n",
      "cost:3.706244239425659\n",
      "accuracy:0.2597000002861023\n"
     ]
    }
   ],
   "source": [
    "res=model.evaluate(xTest, yTest, batch_size=32)\n",
    "print(\"cost:\"+str(res[0]))\n",
    "print(\"accuracy:\"+str(res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조기 종료 : earlystopping\n",
    "# 콜백(함수) : 어떤 상황이 되었을때(val loss가 떨어지다가 올라가는 시점)\n",
    "#함수 내에서 또 다른 어떤 함수를 호출하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2591 - accuracy: 0.5129 - val_loss: 3.3829 - val_accuracy: 0.2433\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2582 - accuracy: 0.5114 - val_loss: 3.4305 - val_accuracy: 0.2400\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(xTrain,yTrain,epochs=3000,batch_size=10, validation_data=(xVal,yVal),callbacks=[es])\n",
    "#에폭 높게 줌 -> 오버피팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax=plt.subplots()\n",
    "acc_ax=loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='upper right')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping(patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 2.2867 - accuracy: 0.1486 - val_loss: 2.2581 - val_accuracy: 0.1867\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 2.2437 - accuracy: 0.1643 - val_loss: 2.2031 - val_accuracy: 0.2100\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 2.1941 - accuracy: 0.2157 - val_loss: 2.1537 - val_accuracy: 0.2500\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 2.1447 - accuracy: 0.2500 - val_loss: 2.1004 - val_accuracy: 0.3233\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 2.0934 - accuracy: 0.2886 - val_loss: 2.0443 - val_accuracy: 0.3133\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 2.0437 - accuracy: 0.3029 - val_loss: 1.9933 - val_accuracy: 0.3133\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.9935 - accuracy: 0.3114 - val_loss: 1.9407 - val_accuracy: 0.3100\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.9466 - accuracy: 0.3257 - val_loss: 1.8919 - val_accuracy: 0.3100\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.9008 - accuracy: 0.3086 - val_loss: 1.8492 - val_accuracy: 0.3200\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.8605 - accuracy: 0.3157 - val_loss: 1.8140 - val_accuracy: 0.3300\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8254 - accuracy: 0.3314 - val_loss: 1.7788 - val_accuracy: 0.3367\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.7942 - accuracy: 0.3343 - val_loss: 1.7525 - val_accuracy: 0.3167\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.7647 - accuracy: 0.3357 - val_loss: 1.7287 - val_accuracy: 0.3367\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7390 - accuracy: 0.3357 - val_loss: 1.7115 - val_accuracy: 0.3467\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7163 - accuracy: 0.3357 - val_loss: 1.6958 - val_accuracy: 0.3400\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6952 - accuracy: 0.3457 - val_loss: 1.6831 - val_accuracy: 0.3367\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6778 - accuracy: 0.3529 - val_loss: 1.6668 - val_accuracy: 0.3433\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6583 - accuracy: 0.3657 - val_loss: 1.6563 - val_accuracy: 0.3400\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6433 - accuracy: 0.3729 - val_loss: 1.6449 - val_accuracy: 0.3567\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6281 - accuracy: 0.3914 - val_loss: 1.6342 - val_accuracy: 0.3667\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6143 - accuracy: 0.3957 - val_loss: 1.6233 - val_accuracy: 0.3667\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5993 - accuracy: 0.3971 - val_loss: 1.6167 - val_accuracy: 0.3633\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5851 - accuracy: 0.4057 - val_loss: 1.6087 - val_accuracy: 0.3933\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5723 - accuracy: 0.4057 - val_loss: 1.6018 - val_accuracy: 0.3700\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5598 - accuracy: 0.4143 - val_loss: 1.5946 - val_accuracy: 0.3800\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5471 - accuracy: 0.4129 - val_loss: 1.5870 - val_accuracy: 0.3867\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5354 - accuracy: 0.4157 - val_loss: 1.5809 - val_accuracy: 0.3700\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5238 - accuracy: 0.4300 - val_loss: 1.5719 - val_accuracy: 0.3733\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5117 - accuracy: 0.4357 - val_loss: 1.5729 - val_accuracy: 0.3900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5022 - accuracy: 0.4329 - val_loss: 1.5591 - val_accuracy: 0.4033\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4921 - accuracy: 0.4414 - val_loss: 1.5519 - val_accuracy: 0.4233\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4800 - accuracy: 0.4271 - val_loss: 1.5474 - val_accuracy: 0.4333\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4719 - accuracy: 0.4529 - val_loss: 1.5415 - val_accuracy: 0.4333\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4610 - accuracy: 0.4486 - val_loss: 1.5335 - val_accuracy: 0.4300\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4500 - accuracy: 0.4529 - val_loss: 1.5328 - val_accuracy: 0.4333\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4420 - accuracy: 0.4643 - val_loss: 1.5232 - val_accuracy: 0.4333\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4311 - accuracy: 0.4671 - val_loss: 1.5148 - val_accuracy: 0.4500\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4233 - accuracy: 0.4771 - val_loss: 1.5118 - val_accuracy: 0.4467\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4133 - accuracy: 0.4814 - val_loss: 1.5134 - val_accuracy: 0.4300\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4056 - accuracy: 0.4857 - val_loss: 1.4992 - val_accuracy: 0.4367\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3964 - accuracy: 0.4943 - val_loss: 1.4922 - val_accuracy: 0.4467\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3891 - accuracy: 0.4914 - val_loss: 1.4918 - val_accuracy: 0.4300\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3802 - accuracy: 0.4829 - val_loss: 1.4864 - val_accuracy: 0.4400\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3726 - accuracy: 0.4829 - val_loss: 1.4753 - val_accuracy: 0.4500\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3647 - accuracy: 0.5029 - val_loss: 1.4707 - val_accuracy: 0.4367\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3581 - accuracy: 0.5071 - val_loss: 1.4710 - val_accuracy: 0.4400\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3489 - accuracy: 0.5057 - val_loss: 1.4680 - val_accuracy: 0.4467\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3425 - accuracy: 0.5057 - val_loss: 1.4611 - val_accuracy: 0.4633\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3372 - accuracy: 0.5200 - val_loss: 1.4581 - val_accuracy: 0.4433\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3308 - accuracy: 0.5043 - val_loss: 1.4579 - val_accuracy: 0.4367\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3228 - accuracy: 0.5129 - val_loss: 1.4521 - val_accuracy: 0.4400\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3176 - accuracy: 0.5200 - val_loss: 1.4545 - val_accuracy: 0.4400\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3124 - accuracy: 0.5200 - val_loss: 1.4467 - val_accuracy: 0.4533\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3063 - accuracy: 0.5186 - val_loss: 1.4448 - val_accuracy: 0.4567\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2992 - accuracy: 0.5186 - val_loss: 1.4449 - val_accuracy: 0.4533\n",
      "Epoch 56/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 87us/step - loss: 1.2957 - accuracy: 0.5143 - val_loss: 1.4443 - val_accuracy: 0.4433\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2901 - accuracy: 0.5243 - val_loss: 1.4380 - val_accuracy: 0.4533\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2866 - accuracy: 0.5286 - val_loss: 1.4369 - val_accuracy: 0.4600\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2770 - accuracy: 0.5286 - val_loss: 1.4469 - val_accuracy: 0.4233\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2749 - accuracy: 0.5243 - val_loss: 1.4381 - val_accuracy: 0.4600\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2708 - accuracy: 0.5343 - val_loss: 1.4349 - val_accuracy: 0.4600\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2648 - accuracy: 0.5429 - val_loss: 1.4326 - val_accuracy: 0.4800\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2609 - accuracy: 0.5343 - val_loss: 1.4315 - val_accuracy: 0.4533\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2565 - accuracy: 0.5457 - val_loss: 1.4376 - val_accuracy: 0.4300\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2518 - accuracy: 0.5371 - val_loss: 1.4350 - val_accuracy: 0.4400\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2475 - accuracy: 0.5543 - val_loss: 1.4299 - val_accuracy: 0.4500\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2443 - accuracy: 0.5486 - val_loss: 1.4251 - val_accuracy: 0.4500\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2400 - accuracy: 0.5429 - val_loss: 1.4285 - val_accuracy: 0.4400\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2344 - accuracy: 0.5486 - val_loss: 1.4325 - val_accuracy: 0.4367\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.2312 - accuracy: 0.5529 - val_loss: 1.4251 - val_accuracy: 0.4633\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2281 - accuracy: 0.5429 - val_loss: 1.4257 - val_accuracy: 0.4533\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2233 - accuracy: 0.5557 - val_loss: 1.4366 - val_accuracy: 0.4433\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2190 - accuracy: 0.5500 - val_loss: 1.4323 - val_accuracy: 0.4333\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2157 - accuracy: 0.5514 - val_loss: 1.4273 - val_accuracy: 0.4600\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2119 - accuracy: 0.5557 - val_loss: 1.4323 - val_accuracy: 0.4367\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2087 - accuracy: 0.5500 - val_loss: 1.4236 - val_accuracy: 0.4600\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2030 - accuracy: 0.5471 - val_loss: 1.4322 - val_accuracy: 0.4367\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2005 - accuracy: 0.5600 - val_loss: 1.4247 - val_accuracy: 0.4533\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.1966 - accuracy: 0.5686 - val_loss: 1.4303 - val_accuracy: 0.4467\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1954 - accuracy: 0.5557 - val_loss: 1.4285 - val_accuracy: 0.4500\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.1906 - accuracy: 0.5557 - val_loss: 1.4244 - val_accuracy: 0.4533\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.1865 - accuracy: 0.5614 - val_loss: 1.4280 - val_accuracy: 0.4533\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.1845 - accuracy: 0.5543 - val_loss: 1.4253 - val_accuracy: 0.4467\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.1807 - accuracy: 0.5600 - val_loss: 1.4229 - val_accuracy: 0.4833\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.1784 - accuracy: 0.5514 - val_loss: 1.4313 - val_accuracy: 0.4333\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1751 - accuracy: 0.5643 - val_loss: 1.4326 - val_accuracy: 0.4533\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1724 - accuracy: 0.5643 - val_loss: 1.4266 - val_accuracy: 0.4633\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.1697 - accuracy: 0.5643 - val_loss: 1.4260 - val_accuracy: 0.4567\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.1646 - accuracy: 0.5629 - val_loss: 1.4293 - val_accuracy: 0.4633\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.1642 - accuracy: 0.5571 - val_loss: 1.4276 - val_accuracy: 0.4667\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.1607 - accuracy: 0.5600 - val_loss: 1.4286 - val_accuracy: 0.4467\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.1578 - accuracy: 0.5657 - val_loss: 1.4287 - val_accuracy: 0.4533\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.1546 - accuracy: 0.5643 - val_loss: 1.4272 - val_accuracy: 0.4667\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.1517 - accuracy: 0.5657 - val_loss: 1.4291 - val_accuracy: 0.4567\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.1473 - accuracy: 0.5743 - val_loss: 1.4334 - val_accuracy: 0.4600\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.1467 - accuracy: 0.5714 - val_loss: 1.4353 - val_accuracy: 0.4500\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.1432 - accuracy: 0.5700 - val_loss: 1.4355 - val_accuracy: 0.4567\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.1406 - accuracy: 0.5729 - val_loss: 1.4352 - val_accuracy: 0.4567\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.1387 - accuracy: 0.5700 - val_loss: 1.4309 - val_accuracy: 0.4600\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.1356 - accuracy: 0.5729 - val_loss: 1.4341 - val_accuracy: 0.4633\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.1322 - accuracy: 0.5786 - val_loss: 1.4337 - val_accuracy: 0.4733\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.1314 - accuracy: 0.5671 - val_loss: 1.4397 - val_accuracy: 0.4533\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.1286 - accuracy: 0.5757 - val_loss: 1.4321 - val_accuracy: 0.4667\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.1252 - accuracy: 0.5700 - val_loss: 1.4313 - val_accuracy: 0.4767\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.1225 - accuracy: 0.5843 - val_loss: 1.4407 - val_accuracy: 0.4533\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.1217 - accuracy: 0.5786 - val_loss: 1.4352 - val_accuracy: 0.4700\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.1197 - accuracy: 0.5671 - val_loss: 1.4414 - val_accuracy: 0.4533\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1166 - accuracy: 0.5843 - val_loss: 1.4363 - val_accuracy: 0.4600\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1156 - accuracy: 0.5714 - val_loss: 1.4423 - val_accuracy: 0.4500\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1116 - accuracy: 0.5786 - val_loss: 1.4412 - val_accuracy: 0.4567\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1074 - accuracy: 0.5957 - val_loss: 1.4503 - val_accuracy: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.1082 - accuracy: 0.5714 - val_loss: 1.4464 - val_accuracy: 0.4467\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1055 - accuracy: 0.5829 - val_loss: 1.4473 - val_accuracy: 0.4467\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.1025 - accuracy: 0.5871 - val_loss: 1.4513 - val_accuracy: 0.4467\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(xTrain,yTrain,epochs=3000,batch_size=10, validation_data=(xVal,yVal),callbacks=[es])\n",
    "#에폭 높게 줌 -> 오버피팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax=plt.subplots()\n",
    "acc_ax=loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='upper right')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어제 폐암 말기 환자 사망 여부 케라스 활용 예측\n",
    "dataset=np.loadtxt(\"C:/Users/student/Downloads/Python_JP/dataset (1)/ThoraricSurgery.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset[:,0:17]\n",
    "y=dataset[:,17]#1:수술 후 생존, 0:사망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(30, input_dim=17,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "470/470 [==============================] - 0s 565us/step - loss: 0.6485 - accuracy: 0.3234\n",
      "Epoch 2/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1497 - accuracy: 0.8489\n",
      "Epoch 3/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 4/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1481 - accuracy: 0.8511\n",
      "Epoch 5/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 6/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1485 - accuracy: 0.8511\n",
      "Epoch 7/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 8/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 9/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1478 - accuracy: 0.8532\n",
      "Epoch 10/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1474 - accuracy: 0.8532\n",
      "Epoch 11/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1480 - accuracy: 0.8511\n",
      "Epoch 12/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1475 - accuracy: 0.8511\n",
      "Epoch 13/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1481 - accuracy: 0.8511\n",
      "Epoch 14/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1472 - accuracy: 0.8532\n",
      "Epoch 15/30\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.1475 - accuracy: 0.8532\n",
      "Epoch 16/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1472 - accuracy: 0.8532\n",
      "Epoch 17/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1477 - accuracy: 0.8511\n",
      "Epoch 18/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1474 - accuracy: 0.8532\n",
      "Epoch 19/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1476 - accuracy: 0.8511\n",
      "Epoch 20/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1479 - accuracy: 0.8511\n",
      "Epoch 21/30\n",
      "470/470 [==============================] - 0s 72us/step - loss: 0.1470 - accuracy: 0.8532\n",
      "Epoch 22/30\n",
      "470/470 [==============================] - 0s 74us/step - loss: 0.1483 - accuracy: 0.8489\n",
      "Epoch 23/30\n",
      "470/470 [==============================] - 0s 72us/step - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 24/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1485 - accuracy: 0.8511\n",
      "Epoch 25/30\n",
      "470/470 [==============================] - 0s 74us/step - loss: 0.1475 - accuracy: 0.8511\n",
      "Epoch 26/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1446 - accuracy: 0.8511\n",
      "Epoch 27/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1434 - accuracy: 0.8489\n",
      "Epoch 28/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1458 - accuracy: 0.8511\n",
      "Epoch 29/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1451 - accuracy: 0.8532\n",
      "Epoch 30/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1437 - accuracy: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25c3c226f88>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=30, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 160us/step\n",
      "[0.14518341751808816, 0.8510638475418091]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#당뇨 데이터 예측 텐서플로 활용\n",
    "xy=np.loadtxt('C:/Users/student/Downloads/Python_JP/실습데이터/data-03-diabetes.csv',delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xdata=xy[:,0:-1]\n",
    "xdata\n",
    "ydata=xy[:,[-1]]\n",
    "# ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8) (759, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xdata.shape, ydata.shape) #759,8   759,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tf.Variable(tf.random_normal([8,1]))\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "x=tf.placeholder(tf.float32,shape=[None,8])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf=tf.sigmoid(tf.matmul(x,w)+b)\n",
    "cost=-tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=tf.cast(hf>0.5,dtype=tf.float32)\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(predicted,y),dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6588901\n",
      "200 0.6212276\n",
      "400 0.60513455\n",
      "600 0.5942359\n",
      "800 0.5850964\n",
      "1000 0.5770026\n",
      "1200 0.56974006\n",
      "1400 0.56319195\n",
      "1600 0.5572694\n",
      "1800 0.55189735\n",
      "2000 0.54701144\n",
      "2200 0.54255575\n",
      "2400 0.5384821\n",
      "2600 0.53474844\n",
      "2800 0.5313181\n",
      "3000 0.52815926\n",
      "3200 0.525244\n",
      "3400 0.5225475\n",
      "3600 0.5200487\n",
      "3800 0.5177282\n",
      "4000 0.5155693\n",
      "4200 0.5135574\n",
      "4400 0.51167905\n",
      "4600 0.5099226\n",
      "4800 0.5082777\n",
      "5000 0.5067349\n",
      "5200 0.50528574\n",
      "5400 0.5039228\n",
      "5600 0.5026393\n",
      "5800 0.50142914\n",
      "6000 0.50028676\n",
      "6200 0.4992071\n",
      "6400 0.49818572\n",
      "6600 0.4972184\n",
      "6800 0.49630135\n",
      "7000 0.49543124\n",
      "7200 0.49460486\n",
      "7400 0.4938193\n",
      "7600 0.49307194\n",
      "7800 0.49236035\n",
      "8000 0.4916823\n",
      "8200 0.49103567\n",
      "8400 0.49041852\n",
      "8600 0.48982927\n",
      "8800 0.48926613\n",
      "9000 0.48872763\n",
      "9200 0.4882123\n",
      "9400 0.48771888\n",
      "9600 0.48724622\n",
      "9800 0.48679313\n",
      "10000 0.4863585\n",
      "[[0.4260255 ]\n",
      " [0.92599666]\n",
      " [0.1564888 ]\n",
      " [0.9510748 ]\n",
      " [0.27395073]\n",
      " [0.72131926]\n",
      " [0.9460343 ]\n",
      " [0.5896516 ]\n",
      " [0.21512163]\n",
      " [0.5487529 ]\n",
      " [0.71949965]\n",
      " [0.16023248]\n",
      " [0.2871047 ]\n",
      " [0.25939953]\n",
      " [0.7503699 ]\n",
      " [0.5257337 ]\n",
      " [0.7161838 ]\n",
      " [0.90113246]\n",
      " [0.8331346 ]\n",
      " [0.61917937]\n",
      " [0.7230009 ]\n",
      " [0.09452012]\n",
      " [0.59948915]\n",
      " [0.6462646 ]\n",
      " [0.38369554]\n",
      " [0.9215203 ]\n",
      " [0.4654636 ]\n",
      " [0.6546469 ]\n",
      " [0.76785994]\n",
      " [0.4068444 ]\n",
      " [0.9419849 ]\n",
      " [0.83260924]\n",
      " [0.55828685]\n",
      " [0.8261795 ]\n",
      " [0.34144652]\n",
      " [0.6849304 ]\n",
      " [0.859794  ]\n",
      " [0.68479097]\n",
      " [0.37982088]\n",
      " [0.41053396]\n",
      " [0.79779863]\n",
      " [0.17415681]\n",
      " [0.35063758]\n",
      " [0.06871653]\n",
      " [0.56344086]\n",
      " [0.9340425 ]\n",
      " [0.73828316]\n",
      " [0.7156196 ]\n",
      " [0.91250247]\n",
      " [0.92508864]\n",
      " [0.9225845 ]\n",
      " [0.22041932]\n",
      " [0.36750114]\n",
      " [0.96839345]\n",
      " [0.18389004]\n",
      " [0.6029222 ]\n",
      " [0.18425637]\n",
      " [0.73119915]\n",
      " [0.91104496]\n",
      " [0.49316436]\n",
      " [0.9600208 ]\n",
      " [0.66454196]\n",
      " [0.6809073 ]\n",
      " [0.8386371 ]\n",
      " [0.6107493 ]\n",
      " [0.71126515]\n",
      " [0.9431946 ]\n",
      " [0.6147627 ]\n",
      " [0.8718945 ]\n",
      " [0.6161939 ]\n",
      " [0.31018746]\n",
      " [0.679021  ]\n",
      " [0.9227631 ]\n",
      " [0.9117601 ]\n",
      " [0.90784717]\n",
      " [0.8111801 ]\n",
      " [0.44502953]\n",
      " [0.83419883]\n",
      " [0.85873926]\n",
      " [0.9291243 ]\n",
      " [0.878333  ]\n",
      " [0.7747632 ]\n",
      " [0.424082  ]\n",
      " [0.82215136]\n",
      " [0.5674661 ]\n",
      " [0.8873669 ]\n",
      " [0.39667422]\n",
      " [0.87578523]\n",
      " [0.94702184]\n",
      " [0.7542474 ]\n",
      " [0.8748455 ]\n",
      " [0.66287017]\n",
      " [0.7037414 ]\n",
      " [0.5551767 ]\n",
      " [0.90109295]\n",
      " [0.97287345]\n",
      " [0.8861316 ]\n",
      " [0.68960893]\n",
      " [0.29218048]\n",
      " [0.5744959 ]\n",
      " [0.57479125]\n",
      " [0.95591146]\n",
      " [0.8413135 ]\n",
      " [0.7971562 ]\n",
      " [0.8573206 ]\n",
      " [0.6551669 ]\n",
      " [0.9320667 ]\n",
      " [0.8158324 ]\n",
      " [0.41562214]\n",
      " [0.3399993 ]\n",
      " [0.9320527 ]\n",
      " [0.894254  ]\n",
      " [0.39636242]\n",
      " [0.47618696]\n",
      " [0.642116  ]\n",
      " [0.870244  ]\n",
      " [0.8531405 ]\n",
      " [0.9185585 ]\n",
      " [0.18148988]\n",
      " [0.71675235]\n",
      " [0.8527385 ]\n",
      " [0.65406716]\n",
      " [0.6045258 ]\n",
      " [0.901903  ]\n",
      " [0.744504  ]\n",
      " [0.8378283 ]\n",
      " [0.82727396]\n",
      " [0.6744487 ]\n",
      " [0.4169857 ]\n",
      " [0.45097983]\n",
      " [0.388884  ]\n",
      " [0.81820905]\n",
      " [0.9208047 ]\n",
      " [0.8217069 ]\n",
      " [0.8163334 ]\n",
      " [0.83636504]\n",
      " [0.43277833]\n",
      " [0.8022504 ]\n",
      " [0.72436297]\n",
      " [0.7605517 ]\n",
      " [0.8790019 ]\n",
      " [0.6498444 ]\n",
      " [0.50278175]\n",
      " [0.73736566]\n",
      " [0.9229491 ]\n",
      " [0.79680276]\n",
      " [0.49988186]\n",
      " [0.917778  ]\n",
      " [0.64531666]\n",
      " [0.76192117]\n",
      " [0.26465803]\n",
      " [0.3977987 ]\n",
      " [0.11890185]\n",
      " [0.28220195]\n",
      " [0.92359966]\n",
      " [0.8663132 ]\n",
      " [0.9359102 ]\n",
      " [0.11816543]\n",
      " [0.4643461 ]\n",
      " [0.81095916]\n",
      " [0.6293954 ]\n",
      " [0.887035  ]\n",
      " [0.4033981 ]\n",
      " [0.8129683 ]\n",
      " [0.5499138 ]\n",
      " [0.65588677]\n",
      " [0.7380289 ]\n",
      " [0.8434883 ]\n",
      " [0.76885283]\n",
      " [0.6060432 ]\n",
      " [0.8932068 ]\n",
      " [0.9219183 ]\n",
      " [0.9566121 ]\n",
      " [0.19414732]\n",
      " [0.8447193 ]\n",
      " [0.35826492]\n",
      " [0.45693484]\n",
      " [0.46151954]\n",
      " [0.8651577 ]\n",
      " [0.6508963 ]\n",
      " [0.93162525]\n",
      " [0.9121828 ]\n",
      " [0.56497693]\n",
      " [0.12254596]\n",
      " [0.18179744]\n",
      " [0.6424321 ]\n",
      " [0.7204322 ]\n",
      " [0.5814026 ]\n",
      " [0.8352788 ]\n",
      " [0.6236442 ]\n",
      " [0.31963083]\n",
      " [0.29584837]\n",
      " [0.8929852 ]\n",
      " [0.3683293 ]\n",
      " [0.8815116 ]\n",
      " [0.8760965 ]\n",
      " [0.7559234 ]\n",
      " [0.58381945]\n",
      " [0.6436266 ]\n",
      " [0.58632326]\n",
      " [0.6853951 ]\n",
      " [0.92871416]\n",
      " [0.82130706]\n",
      " [0.77063465]\n",
      " [0.12875032]\n",
      " [0.3201762 ]\n",
      " [0.9287412 ]\n",
      " [0.1731104 ]\n",
      " [0.93193614]\n",
      " [0.27315885]\n",
      " [0.2314376 ]\n",
      " [0.46594587]\n",
      " [0.69736254]\n",
      " [0.22584781]\n",
      " [0.7717581 ]\n",
      " [0.69805413]\n",
      " [0.830042  ]\n",
      " [0.7204856 ]\n",
      " [0.15534338]\n",
      " [0.40879044]\n",
      " [0.6805057 ]\n",
      " [0.5542881 ]\n",
      " [0.9143312 ]\n",
      " [0.9382341 ]\n",
      " [0.6965711 ]\n",
      " [0.3610776 ]\n",
      " [0.04346481]\n",
      " [0.6653048 ]\n",
      " [0.38538343]\n",
      " [0.52541107]\n",
      " [0.94686294]\n",
      " [0.6512139 ]\n",
      " [0.9499651 ]\n",
      " [0.2321831 ]\n",
      " [0.11921874]\n",
      " [0.21943495]\n",
      " [0.69830424]\n",
      " [0.9280852 ]\n",
      " [0.8856256 ]\n",
      " [0.59564555]\n",
      " [0.6781025 ]\n",
      " [0.5870298 ]\n",
      " [0.12437513]\n",
      " [0.5444677 ]\n",
      " [0.13559675]\n",
      " [0.561175  ]\n",
      " [0.84035766]\n",
      " [0.69795024]\n",
      " [0.6679909 ]\n",
      " [0.93748504]\n",
      " [0.8153373 ]\n",
      " [0.77018386]\n",
      " [0.81488943]\n",
      " [0.7784494 ]\n",
      " [0.83166355]\n",
      " [0.28974605]\n",
      " [0.32166615]\n",
      " [0.5099615 ]\n",
      " [0.8230845 ]\n",
      " [0.6670323 ]\n",
      " [0.692241  ]\n",
      " [0.84811413]\n",
      " [0.3336653 ]\n",
      " [0.55853343]\n",
      " [0.6712174 ]\n",
      " [0.58050144]\n",
      " [0.5263061 ]\n",
      " [0.9086901 ]\n",
      " [0.73833513]\n",
      " [0.9550451 ]\n",
      " [0.5915825 ]\n",
      " [0.8310646 ]\n",
      " [0.783072  ]\n",
      " [0.7880889 ]\n",
      " [0.71182424]\n",
      " [0.843032  ]\n",
      " [0.3353324 ]\n",
      " [0.56840086]\n",
      " [0.6344303 ]\n",
      " [0.32145852]\n",
      " [0.8306507 ]\n",
      " [0.2957566 ]\n",
      " [0.69436616]\n",
      " [0.9197773 ]\n",
      " [0.80362105]\n",
      " [0.8868497 ]\n",
      " [0.7104733 ]\n",
      " [0.58594614]\n",
      " [0.7087575 ]\n",
      " [0.380937  ]\n",
      " [0.44490552]\n",
      " [0.5935372 ]\n",
      " [0.56447774]\n",
      " [0.6642041 ]\n",
      " [0.6513877 ]\n",
      " [0.18674621]\n",
      " [0.6539089 ]\n",
      " [0.9223802 ]\n",
      " [0.58422494]\n",
      " [0.5471398 ]\n",
      " [0.78453046]\n",
      " [0.3862526 ]\n",
      " [0.6633198 ]\n",
      " [0.48610005]\n",
      " [0.7233075 ]\n",
      " [0.9017597 ]\n",
      " [0.68236774]\n",
      " [0.61369836]\n",
      " [0.85161436]\n",
      " [0.61714023]\n",
      " [0.8538684 ]\n",
      " [0.91945946]\n",
      " [0.2449637 ]\n",
      " [0.8033326 ]\n",
      " [0.19256717]\n",
      " [0.7376049 ]\n",
      " [0.7919442 ]\n",
      " [0.63791835]\n",
      " [0.2904758 ]\n",
      " [0.8240561 ]\n",
      " [0.64211196]\n",
      " [0.7741292 ]\n",
      " [0.1502335 ]\n",
      " [0.8474388 ]\n",
      " [0.8464682 ]\n",
      " [0.57095575]\n",
      " [0.9438411 ]\n",
      " [0.29303676]\n",
      " [0.6508562 ]\n",
      " [0.93854487]\n",
      " [0.22045842]\n",
      " [0.5377789 ]\n",
      " [0.7076339 ]\n",
      " [0.30812955]\n",
      " [0.1706307 ]\n",
      " [0.80029106]\n",
      " [0.91924924]\n",
      " [0.8606476 ]\n",
      " [0.62161505]\n",
      " [0.7549288 ]\n",
      " [0.60980695]\n",
      " [0.7421213 ]\n",
      " [0.77705336]\n",
      " [0.91624916]\n",
      " [0.7846978 ]\n",
      " [0.8143176 ]\n",
      " [0.54971826]\n",
      " [0.95301914]\n",
      " [0.938316  ]\n",
      " [0.8349689 ]\n",
      " [0.23665267]\n",
      " [0.73254293]\n",
      " [0.38408226]\n",
      " [0.7957884 ]\n",
      " [0.18583632]\n",
      " [0.19504401]\n",
      " [0.438921  ]\n",
      " [0.7697385 ]\n",
      " [0.47627348]\n",
      " [0.5343414 ]\n",
      " [0.86030626]\n",
      " [0.61326015]\n",
      " [0.8291512 ]\n",
      " [0.93846893]\n",
      " [0.7490363 ]\n",
      " [0.11368737]\n",
      " [0.5666228 ]\n",
      " [0.88093954]\n",
      " [0.87200767]\n",
      " [0.7294784 ]\n",
      " [0.32418978]\n",
      " [0.83582306]\n",
      " [0.91888213]\n",
      " [0.34432203]\n",
      " [0.70027864]\n",
      " [0.8487159 ]\n",
      " [0.77284014]\n",
      " [0.88374627]\n",
      " [0.91069496]\n",
      " [0.83645684]\n",
      " [0.8919605 ]\n",
      " [0.6886679 ]\n",
      " [0.66831523]\n",
      " [0.56705594]\n",
      " [0.85270035]\n",
      " [0.898828  ]\n",
      " [0.24523601]\n",
      " [0.79500705]\n",
      " [0.8441789 ]\n",
      " [0.3172235 ]\n",
      " [0.6354667 ]\n",
      " [0.8830007 ]\n",
      " [0.5017753 ]\n",
      " [0.90349054]\n",
      " [0.20738328]\n",
      " [0.84693867]\n",
      " [0.61354566]\n",
      " [0.88278896]\n",
      " [0.33418095]\n",
      " [0.7534405 ]\n",
      " [0.7414931 ]\n",
      " [0.74584895]\n",
      " [0.07737225]\n",
      " [0.24880171]\n",
      " [0.6984128 ]\n",
      " [0.82860345]\n",
      " [0.49500486]\n",
      " [0.769747  ]\n",
      " [0.52531123]\n",
      " [0.29167724]\n",
      " [0.84874153]\n",
      " [0.4725123 ]\n",
      " [0.91480744]\n",
      " [0.7774172 ]\n",
      " [0.7290102 ]\n",
      " [0.92873764]\n",
      " [0.75763786]\n",
      " [0.8231634 ]\n",
      " [0.350798  ]\n",
      " [0.24037501]\n",
      " [0.75843835]\n",
      " [0.39976975]\n",
      " [0.44859177]\n",
      " [0.9145747 ]\n",
      " [0.8779572 ]\n",
      " [0.919513  ]\n",
      " [0.949458  ]\n",
      " [0.6338603 ]\n",
      " [0.89834857]\n",
      " [0.3836741 ]\n",
      " [0.33639687]\n",
      " [0.43292907]\n",
      " [0.93271506]\n",
      " [0.63840896]\n",
      " [0.12354478]\n",
      " [0.93421245]\n",
      " [0.8000519 ]\n",
      " [0.603507  ]\n",
      " [0.77891815]\n",
      " [0.04335138]\n",
      " [0.911548  ]\n",
      " [0.78093505]\n",
      " [0.75017846]\n",
      " [0.7105246 ]\n",
      " [0.9568933 ]\n",
      " [0.60759115]\n",
      " [0.798476  ]\n",
      " [0.78475356]\n",
      " [0.87989306]\n",
      " [0.14160958]\n",
      " [0.6939204 ]\n",
      " [0.906316  ]\n",
      " [0.64575815]\n",
      " [0.7098324 ]\n",
      " [0.94471234]\n",
      " [0.885575  ]\n",
      " [0.87863827]\n",
      " [0.47389105]\n",
      " [0.7505474 ]\n",
      " [0.93310857]\n",
      " [0.77074206]\n",
      " [0.6337239 ]\n",
      " [0.34354776]\n",
      " [0.50385153]\n",
      " [0.4605647 ]\n",
      " [0.59718114]\n",
      " [0.50961137]\n",
      " [0.7555211 ]\n",
      " [0.5413479 ]\n",
      " [0.80774826]\n",
      " [0.7793796 ]\n",
      " [0.690928  ]\n",
      " [0.6657333 ]\n",
      " [0.4708946 ]\n",
      " [0.54767096]\n",
      " [0.93368006]\n",
      " [0.84672165]\n",
      " [0.29858524]\n",
      " [0.44834462]\n",
      " [0.60496646]\n",
      " [0.15361524]\n",
      " [0.8634201 ]\n",
      " [0.13100895]\n",
      " [0.92118514]\n",
      " [0.89265835]\n",
      " [0.8412142 ]\n",
      " [0.70753473]\n",
      " [0.9029083 ]\n",
      " [0.35112458]\n",
      " [0.7544442 ]\n",
      " [0.94034517]\n",
      " [0.23309022]\n",
      " [0.4095136 ]\n",
      " [0.86341655]\n",
      " [0.892249  ]\n",
      " [0.7362009 ]\n",
      " [0.84313345]\n",
      " [0.848325  ]\n",
      " [0.8251195 ]\n",
      " [0.21594393]\n",
      " [0.7880809 ]\n",
      " [0.93400526]\n",
      " [0.64133763]\n",
      " [0.79543746]\n",
      " [0.6401524 ]\n",
      " [0.82530916]\n",
      " [0.8699256 ]\n",
      " [0.9179896 ]\n",
      " [0.52690196]\n",
      " [0.40806937]\n",
      " [0.80034477]\n",
      " [0.70817053]\n",
      " [0.9656129 ]\n",
      " [0.74802184]\n",
      " [0.6941964 ]\n",
      " [0.44445723]\n",
      " [0.7022366 ]\n",
      " [0.9265829 ]\n",
      " [0.9464564 ]\n",
      " [0.85587806]\n",
      " [0.65982515]\n",
      " [0.6342442 ]\n",
      " [0.79332864]\n",
      " [0.54678386]\n",
      " [0.88604337]\n",
      " [0.8159523 ]\n",
      " [0.9262071 ]\n",
      " [0.5968286 ]\n",
      " [0.7021798 ]\n",
      " [0.92824566]\n",
      " [0.4809108 ]\n",
      " [0.5772995 ]\n",
      " [0.73169565]\n",
      " [0.7122686 ]\n",
      " [0.72809064]\n",
      " [0.91113746]\n",
      " [0.9292803 ]\n",
      " [0.16152069]\n",
      " [0.17212328]\n",
      " [0.7284526 ]\n",
      " [0.5306258 ]\n",
      " [0.16733262]\n",
      " [0.84652734]\n",
      " [0.9134543 ]\n",
      " [0.7289096 ]\n",
      " [0.9377025 ]\n",
      " [0.93402207]\n",
      " [0.7125803 ]\n",
      " [0.8677688 ]\n",
      " [0.71516126]\n",
      " [0.6398457 ]\n",
      " [0.7654384 ]\n",
      " [0.64333296]\n",
      " [0.10053778]\n",
      " [0.9219966 ]\n",
      " [0.87208104]\n",
      " [0.7261233 ]\n",
      " [0.91303277]\n",
      " [0.9089242 ]\n",
      " [0.8978383 ]\n",
      " [0.5455813 ]\n",
      " [0.6749846 ]\n",
      " [0.9102751 ]\n",
      " [0.7016961 ]\n",
      " [0.84645057]\n",
      " [0.90967155]\n",
      " [0.5531353 ]\n",
      " [0.8302603 ]\n",
      " [0.8234094 ]\n",
      " [0.67737925]\n",
      " [0.46851775]\n",
      " [0.1300742 ]\n",
      " [0.29343712]\n",
      " [0.79156625]\n",
      " [0.60699373]\n",
      " [0.7255037 ]\n",
      " [0.5560165 ]\n",
      " [0.9216809 ]\n",
      " [0.4352732 ]\n",
      " [0.78518724]\n",
      " [0.2905498 ]\n",
      " [0.8803059 ]\n",
      " [0.44922566]\n",
      " [0.7998581 ]\n",
      " [0.60954344]\n",
      " [0.8949857 ]\n",
      " [0.60910535]\n",
      " [0.15583375]\n",
      " [0.868233  ]\n",
      " [0.9570864 ]\n",
      " [0.37086284]\n",
      " [0.9091675 ]\n",
      " [0.8409643 ]\n",
      " [0.83023036]\n",
      " [0.780982  ]\n",
      " [0.4478106 ]\n",
      " [0.26150852]\n",
      " [0.7602724 ]\n",
      " [0.1951488 ]\n",
      " [0.9394566 ]\n",
      " [0.3217237 ]\n",
      " [0.8998529 ]\n",
      " [0.8736517 ]\n",
      " [0.39019758]\n",
      " [0.20691392]\n",
      " [0.69660664]\n",
      " [0.44979286]\n",
      " [0.81462157]\n",
      " [0.6567069 ]\n",
      " [0.9742751 ]\n",
      " [0.57604665]\n",
      " [0.60244876]\n",
      " [0.80136037]\n",
      " [0.81756496]\n",
      " [0.09138179]\n",
      " [0.8211669 ]\n",
      " [0.8408464 ]\n",
      " [0.867976  ]\n",
      " [0.6120566 ]\n",
      " [0.4832691 ]\n",
      " [0.62159586]\n",
      " [0.904184  ]\n",
      " [0.6354963 ]\n",
      " [0.7642838 ]\n",
      " [0.8010752 ]\n",
      " [0.80831105]\n",
      " [0.77897954]\n",
      " [0.56717694]\n",
      " [0.80564016]\n",
      " [0.9005687 ]\n",
      " [0.7643182 ]\n",
      " [0.93848985]\n",
      " [0.765028  ]\n",
      " [0.6105442 ]\n",
      " [0.46947587]\n",
      " [0.8475477 ]\n",
      " [0.84431577]\n",
      " [0.46631828]\n",
      " [0.55697805]\n",
      " [0.2039757 ]\n",
      " [0.49712896]\n",
      " [0.7556212 ]\n",
      " [0.9418803 ]\n",
      " [0.84166   ]\n",
      " [0.7189238 ]\n",
      " [0.7487313 ]\n",
      " [0.8841771 ]\n",
      " [0.4887839 ]\n",
      " [0.9127625 ]\n",
      " [0.6826587 ]\n",
      " [0.8827486 ]\n",
      " [0.2657277 ]\n",
      " [0.09585586]\n",
      " [0.24845633]\n",
      " [0.36749643]\n",
      " [0.7195658 ]\n",
      " [0.8313533 ]\n",
      " [0.6161351 ]\n",
      " [0.6990335 ]\n",
      " [0.84426486]\n",
      " [0.4410987 ]\n",
      " [0.37575576]\n",
      " [0.91133463]\n",
      " [0.90334606]\n",
      " [0.5280583 ]\n",
      " [0.7741196 ]\n",
      " [0.13722894]\n",
      " [0.33071232]\n",
      " [0.7589983 ]\n",
      " [0.7237084 ]\n",
      " [0.88616925]\n",
      " [0.97756565]\n",
      " [0.20537975]\n",
      " [0.77124256]\n",
      " [0.60243106]\n",
      " [0.5320792 ]\n",
      " [0.71099335]\n",
      " [0.67074066]\n",
      " [0.8858659 ]\n",
      " [0.66829187]\n",
      " [0.5922299 ]\n",
      " [0.63634276]\n",
      " [0.14684492]\n",
      " [0.7220677 ]\n",
      " [0.58875364]\n",
      " [0.90143824]\n",
      " [0.5016213 ]\n",
      " [0.47817394]\n",
      " [0.75357246]\n",
      " [0.6971575 ]\n",
      " [0.5682916 ]\n",
      " [0.75533646]\n",
      " [0.64046097]\n",
      " [0.3560344 ]\n",
      " [0.6736659 ]\n",
      " [0.8567813 ]\n",
      " [0.8619262 ]\n",
      " [0.5819459 ]\n",
      " [0.7744123 ]\n",
      " [0.2563718 ]\n",
      " [0.8770436 ]\n",
      " [0.5111833 ]\n",
      " [0.7408745 ]\n",
      " [0.4525684 ]\n",
      " [0.6226313 ]\n",
      " [0.8334893 ]\n",
      " [0.15368852]\n",
      " [0.28377485]\n",
      " [0.8007356 ]\n",
      " [0.8412109 ]\n",
      " [0.834216  ]\n",
      " [0.90204275]\n",
      " [0.84570754]\n",
      " [0.681393  ]\n",
      " [0.7566122 ]\n",
      " [0.7976212 ]\n",
      " [0.73835593]\n",
      " [0.8028395 ]\n",
      " [0.40323424]\n",
      " [0.3164679 ]\n",
      " [0.88954294]\n",
      " [0.7631887 ]\n",
      " [0.57131445]\n",
      " [0.29231983]\n",
      " [0.87225854]\n",
      " [0.83534765]\n",
      " [0.8508774 ]\n",
      " [0.643468  ]\n",
      " [0.90480417]\n",
      " [0.90479267]\n",
      " [0.83536893]\n",
      " [0.4982548 ]\n",
      " [0.8953361 ]\n",
      " [0.89767706]\n",
      " [0.33112592]\n",
      " [0.17247355]\n",
      " [0.7210756 ]\n",
      " [0.45688108]\n",
      " [0.8911448 ]\n",
      " [0.28858882]\n",
      " [0.39940077]\n",
      " [0.4389472 ]\n",
      " [0.7944857 ]\n",
      " [0.84209013]\n",
      " [0.11930245]\n",
      " [0.3471405 ]\n",
      " [0.66854703]\n",
      " [0.46869645]\n",
      " [0.5667384 ]\n",
      " [0.8129537 ]\n",
      " [0.16296294]\n",
      " [0.9217065 ]\n",
      " [0.19416215]\n",
      " [0.8255086 ]\n",
      " [0.77063423]\n",
      " [0.7344377 ]\n",
      " [0.7855194 ]\n",
      " [0.75052994]\n",
      " [0.89368415]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.770751\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        cv,_=sess.run([cost,train],feed_dict={x:xdata,y:ydata})\n",
    "        if step%200==0:\n",
    "            print(step,cv)\n",
    "    hv,pv,av=sess.run([hf,predicted,accuracy],feed_dict={x:xdata,y:ydata})\n",
    "    print(hv,pv,av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#주식 close 예측 케라스\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>829.219971</td>\n",
       "      <td>840.849976</td>\n",
       "      <td>829.219971</td>\n",
       "      <td>838.549988</td>\n",
       "      <td>838.549988</td>\n",
       "      <td>1671500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>831.359985</td>\n",
       "      <td>835.179993</td>\n",
       "      <td>829.036011</td>\n",
       "      <td>834.570007</td>\n",
       "      <td>834.570007</td>\n",
       "      <td>1045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>835.510010</td>\n",
       "      <td>842.450012</td>\n",
       "      <td>830.719971</td>\n",
       "      <td>831.409973</td>\n",
       "      <td>831.409973</td>\n",
       "      <td>1555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>832.400024</td>\n",
       "      <td>836.390015</td>\n",
       "      <td>826.460022</td>\n",
       "      <td>827.880005</td>\n",
       "      <td>827.880005</td>\n",
       "      <td>1254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>827.960022</td>\n",
       "      <td>828.484985</td>\n",
       "      <td>820.513000</td>\n",
       "      <td>824.669983</td>\n",
       "      <td>824.669983</td>\n",
       "      <td>1057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>749</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>1126.469971</td>\n",
       "      <td>1148.900024</td>\n",
       "      <td>1086.010010</td>\n",
       "      <td>1102.489990</td>\n",
       "      <td>1102.489990</td>\n",
       "      <td>4081500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>1111.800049</td>\n",
       "      <td>1169.969971</td>\n",
       "      <td>1093.530029</td>\n",
       "      <td>1161.750000</td>\n",
       "      <td>1161.750000</td>\n",
       "      <td>3571700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>751</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>1125.670044</td>\n",
       "      <td>1150.670044</td>\n",
       "      <td>1105.910034</td>\n",
       "      <td>1110.709961</td>\n",
       "      <td>1110.709961</td>\n",
       "      <td>3208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>752</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>1125.040039</td>\n",
       "      <td>1151.630005</td>\n",
       "      <td>1096.479980</td>\n",
       "      <td>1146.819946</td>\n",
       "      <td>1146.819946</td>\n",
       "      <td>2574100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1147.300049</td>\n",
       "      <td>1175.310059</td>\n",
       "      <td>1138.140015</td>\n",
       "      <td>1162.810059</td>\n",
       "      <td>1162.810059</td>\n",
       "      <td>2486400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>754 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Open         High          Low        Close  \\\n",
       "0    2017-04-03   829.219971   840.849976   829.219971   838.549988   \n",
       "1    2017-04-04   831.359985   835.179993   829.036011   834.570007   \n",
       "2    2017-04-05   835.510010   842.450012   830.719971   831.409973   \n",
       "3    2017-04-06   832.400024   836.390015   826.460022   827.880005   \n",
       "4    2017-04-07   827.960022   828.484985   820.513000   824.669983   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "749  2020-03-25  1126.469971  1148.900024  1086.010010  1102.489990   \n",
       "750  2020-03-26  1111.800049  1169.969971  1093.530029  1161.750000   \n",
       "751  2020-03-27  1125.670044  1150.670044  1105.910034  1110.709961   \n",
       "752  2020-03-30  1125.040039  1151.630005  1096.479980  1146.819946   \n",
       "753  2020-03-31  1147.300049  1175.310059  1138.140015  1162.810059   \n",
       "\n",
       "       Adj Close   Volume  \n",
       "0     838.549988  1671500  \n",
       "1     834.570007  1045400  \n",
       "2     831.409973  1555300  \n",
       "3     827.880005  1254400  \n",
       "4     824.669983  1057300  \n",
       "..           ...      ...  \n",
       "749  1102.489990  4081500  \n",
       "750  1161.750000  3571700  \n",
       "751  1110.709961  3208500  \n",
       "752  1146.819946  2574100  \n",
       "753  1162.810059  2486400  \n",
       "\n",
       "[754 rows x 7 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"C:/Users/student/Downloads/Python_JP/실습데이터/GOOG.csv\",delimiter=\",\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>829.219971</td>\n",
       "      <td>840.849976</td>\n",
       "      <td>829.219971</td>\n",
       "      <td>838.549988</td>\n",
       "      <td>838.549988</td>\n",
       "      <td>1671500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>831.359985</td>\n",
       "      <td>835.179993</td>\n",
       "      <td>829.036011</td>\n",
       "      <td>834.570007</td>\n",
       "      <td>834.570007</td>\n",
       "      <td>1045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>835.510010</td>\n",
       "      <td>842.450012</td>\n",
       "      <td>830.719971</td>\n",
       "      <td>831.409973</td>\n",
       "      <td>831.409973</td>\n",
       "      <td>1555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>832.400024</td>\n",
       "      <td>836.390015</td>\n",
       "      <td>826.460022</td>\n",
       "      <td>827.880005</td>\n",
       "      <td>827.880005</td>\n",
       "      <td>1254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>827.960022</td>\n",
       "      <td>828.484985</td>\n",
       "      <td>820.513000</td>\n",
       "      <td>824.669983</td>\n",
       "      <td>824.669983</td>\n",
       "      <td>1057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>1126.469971</td>\n",
       "      <td>1148.900024</td>\n",
       "      <td>1086.010010</td>\n",
       "      <td>1102.489990</td>\n",
       "      <td>1102.489990</td>\n",
       "      <td>4081500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>1111.800049</td>\n",
       "      <td>1169.969971</td>\n",
       "      <td>1093.530029</td>\n",
       "      <td>1161.750000</td>\n",
       "      <td>1161.750000</td>\n",
       "      <td>3571700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>1125.670044</td>\n",
       "      <td>1150.670044</td>\n",
       "      <td>1105.910034</td>\n",
       "      <td>1110.709961</td>\n",
       "      <td>1110.709961</td>\n",
       "      <td>3208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>1125.040039</td>\n",
       "      <td>1151.630005</td>\n",
       "      <td>1096.479980</td>\n",
       "      <td>1146.819946</td>\n",
       "      <td>1146.819946</td>\n",
       "      <td>2574100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1147.300049</td>\n",
       "      <td>1175.310059</td>\n",
       "      <td>1138.140015</td>\n",
       "      <td>1162.810059</td>\n",
       "      <td>1162.810059</td>\n",
       "      <td>2486400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>754 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "2017-04-03   829.219971   840.849976   829.219971   838.549988   838.549988   \n",
       "2017-04-04   831.359985   835.179993   829.036011   834.570007   834.570007   \n",
       "2017-04-05   835.510010   842.450012   830.719971   831.409973   831.409973   \n",
       "2017-04-06   832.400024   836.390015   826.460022   827.880005   827.880005   \n",
       "2017-04-07   827.960022   828.484985   820.513000   824.669983   824.669983   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2020-03-25  1126.469971  1148.900024  1086.010010  1102.489990  1102.489990   \n",
       "2020-03-26  1111.800049  1169.969971  1093.530029  1161.750000  1161.750000   \n",
       "2020-03-27  1125.670044  1150.670044  1105.910034  1110.709961  1110.709961   \n",
       "2020-03-30  1125.040039  1151.630005  1096.479980  1146.819946  1146.819946   \n",
       "2020-03-31  1147.300049  1175.310059  1138.140015  1162.810059  1162.810059   \n",
       "\n",
       "             Volume  \n",
       "2017-04-03  1671500  \n",
       "2017-04-04  1045400  \n",
       "2017-04-05  1555300  \n",
       "2017-04-06  1254400  \n",
       "2017-04-07  1057300  \n",
       "...             ...  \n",
       "2020-03-25  4081500  \n",
       "2020-03-26  3571700  \n",
       "2020-03-27  3208500  \n",
       "2020-03-30  2574100  \n",
       "2020-03-31  2486400  \n",
       "\n",
       "[754 rows x 6 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.set_index('Date')\n",
    "data.index.names=[None]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata=data[data.columns.difference(['Close'])].values\n",
    "xp=xdata[730:]\n",
    "xdata=xdata[:730]\n",
    "#values 붙여서 array형식으로\n",
    "ydata=data.iloc[:,3].values\n",
    "label=ydata[730:]\n",
    "label=label.reshape(24,1)\n",
    "ydata=ydata[:730]\n",
    "ydata=ydata.reshape(730,1)\n",
    "scaler=StandardScaler()\n",
    "xdata=scaler.fit_transform(xdata)\n",
    "xp=scaler.fit_transform(xp)\n",
    "es=EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(xdata,ydata,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(30,input_dim=4,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 527 samples, validate on 227 samples\n",
      "Epoch 1/1000\n",
      "527/527 [==============================] - 0s 516us/step - loss: 1276926.0757 - accuracy: 0.0000e+00 - val_loss: 1252710.7594 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 1275141.3999 - accuracy: 0.0000e+00 - val_loss: 1250582.4917 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "527/527 [==============================] - 0s 142us/step - loss: 1272769.5332 - accuracy: 0.0000e+00 - val_loss: 1247676.0374 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 1269541.9241 - accuracy: 0.0000e+00 - val_loss: 1243822.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "527/527 [==============================] - 0s 144us/step - loss: 1265315.9360 - accuracy: 0.0000e+00 - val_loss: 1238868.7819 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 1259987.9146 - accuracy: 0.0000e+00 - val_loss: 1232740.5253 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 1253564.3480 - accuracy: 0.0000e+00 - val_loss: 1225623.5248 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 1246138.2296 - accuracy: 0.0000e+00 - val_loss: 1217331.7638 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 1237669.3423 - accuracy: 0.0000e+00 - val_loss: 1208222.9928 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "527/527 [==============================] - 0s 120us/step - loss: 1228207.4386 - accuracy: 0.0000e+00 - val_loss: 1198152.0925 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 1217925.3468 - accuracy: 0.0000e+00 - val_loss: 1186974.5721 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "527/527 [==============================] - 0s 118us/step - loss: 1206652.6715 - accuracy: 0.0000e+00 - val_loss: 1175167.1300 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "527/527 [==============================] - 0s 118us/step - loss: 1194605.7780 - accuracy: 0.0000e+00 - val_loss: 1162436.2583 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "527/527 [==============================] - 0s 118us/step - loss: 1181708.8944 - accuracy: 0.0000e+00 - val_loss: 1148970.3155 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 1168079.6620 - accuracy: 0.0000e+00 - val_loss: 1134759.1041 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 1153785.9068 - accuracy: 0.0000e+00 - val_loss: 1119981.5270 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 1138943.8864 - accuracy: 0.0000e+00 - val_loss: 1104482.0341 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 1123481.7343 - accuracy: 0.0000e+00 - val_loss: 1088684.1883 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 1107548.5681 - accuracy: 0.0000e+00 - val_loss: 1072298.1167 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 1091095.3814 - accuracy: 0.0000e+00 - val_loss: 1055437.3304 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 1074148.8639 - accuracy: 0.0000e+00 - val_loss: 1038217.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 1056825.0164 - accuracy: 0.0000e+00 - val_loss: 1020543.9945 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 1039135.7222 - accuracy: 0.0000e+00 - val_loss: 1002451.4091 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 1021022.1118 - accuracy: 0.0000e+00 - val_loss: 984234.7048 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 1002636.0873 - accuracy: 0.0000e+00 - val_loss: 965658.4898 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "527/527 [==============================] - 0s 146us/step - loss: 984055.0215 - accuracy: 0.0000e+00 - val_loss: 946896.6619 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 965273.8017 - accuracy: 0.0000e+00 - val_loss: 927987.2373 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "527/527 [==============================] - 0s 142us/step - loss: 946341.6702 - accuracy: 0.0000e+00 - val_loss: 908963.4111 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "527/527 [==============================] - 0s 156us/step - loss: 927338.9554 - accuracy: 0.0000e+00 - val_loss: 889862.9257 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "527/527 [==============================] - 0s 144us/step - loss: 908165.9635 - accuracy: 0.0000e+00 - val_loss: 870898.2208 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "527/527 [==============================] - 0s 144us/step - loss: 889000.9415 - accuracy: 0.0000e+00 - val_loss: 851542.1206 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 869723.0503 - accuracy: 0.0000e+00 - val_loss: 832379.7445 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 850500.5804 - accuracy: 0.0000e+00 - val_loss: 813350.5752 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "527/527 [==============================] - 0s 148us/step - loss: 831315.1482 - accuracy: 0.0000e+00 - val_loss: 794322.7877 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "527/527 [==============================] - 0s 152us/step - loss: 812251.3965 - accuracy: 0.0000e+00 - val_loss: 775380.0460 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 793222.4305 - accuracy: 0.0000e+00 - val_loss: 756692.4510 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 774384.2740 - accuracy: 0.0000e+00 - val_loss: 738253.3411 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 755722.2319 - accuracy: 0.0000e+00 - val_loss: 719883.4001 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 737259.1979 - accuracy: 0.0000e+00 - val_loss: 701759.2751 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "527/527 [==============================] - 0s 120us/step - loss: 718996.4524 - accuracy: 0.0000e+00 - val_loss: 683974.9444 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 700982.8846 - accuracy: 0.0000e+00 - val_loss: 666454.1396 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 683213.7214 - accuracy: 0.0000e+00 - val_loss: 649305.6611 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 665788.1137 - accuracy: 0.0000e+00 - val_loss: 632375.7442 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 648579.4080 - accuracy: 0.0000e+00 - val_loss: 615725.6828 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "527/527 [==============================] - 0s 146us/step - loss: 631716.6310 - accuracy: 0.0000e+00 - val_loss: 599294.9807 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "527/527 [==============================] - 0s 159us/step - loss: 615076.3021 - accuracy: 0.0000e+00 - val_loss: 583443.4381 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 598817.7056 - accuracy: 0.0000e+00 - val_loss: 567884.3155 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 582938.9529 - accuracy: 0.0000e+00 - val_loss: 552534.6597 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 567280.5870 - accuracy: 0.0000e+00 - val_loss: 537626.8420 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527/527 [==============================] - 0s 127us/step - loss: 551976.7983 - accuracy: 0.0000e+00 - val_loss: 523215.5330 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 537110.3844 - accuracy: 0.0000e+00 - val_loss: 508951.4939 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 522486.6768 - accuracy: 0.0000e+00 - val_loss: 495264.9458 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 508306.6414 - accuracy: 0.0000e+00 - val_loss: 481648.7368 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 494365.2870 - accuracy: 0.0000e+00 - val_loss: 468709.8888 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 480821.2281 - accuracy: 0.0000e+00 - val_loss: 455826.2609 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 467596.3551 - accuracy: 0.0000e+00 - val_loss: 443289.5040 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "527/527 [==============================] - 0s 142us/step - loss: 454650.0778 - accuracy: 0.0000e+00 - val_loss: 431240.1249 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "527/527 [==============================] - 0s 154us/step - loss: 442096.0769 - accuracy: 0.0000e+00 - val_loss: 419396.6316 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 429825.1948 - accuracy: 0.0000e+00 - val_loss: 407892.6834 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 417802.9835 - accuracy: 0.0000e+00 - val_loss: 396892.7481 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "527/527 [==============================] - 0s 118us/step - loss: 406167.1404 - accuracy: 0.0000e+00 - val_loss: 386030.8553 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 394840.8197 - accuracy: 0.0000e+00 - val_loss: 375148.2448 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 383640.9961 - accuracy: 0.0000e+00 - val_loss: 364986.8071 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 372807.9467 - accuracy: 0.0000e+00 - val_loss: 354862.8217 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 362152.6517 - accuracy: 0.0000e+00 - val_loss: 344893.2928 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 351774.1120 - accuracy: 0.0000e+00 - val_loss: 335209.5953 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 341596.8324 - accuracy: 0.0000e+00 - val_loss: 325700.4162 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 331641.4829 - accuracy: 0.0000e+00 - val_loss: 316467.8798 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "527/527 [==============================] - 0s 116us/step - loss: 321930.7326 - accuracy: 0.0000e+00 - val_loss: 307466.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 312451.9789 - accuracy: 0.0000e+00 - val_loss: 298666.0931 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 303188.9951 - accuracy: 0.0000e+00 - val_loss: 289916.4347 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 294148.9701 - accuracy: 0.0000e+00 - val_loss: 281333.6384 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 285247.9046 - accuracy: 0.0000e+00 - val_loss: 273200.2775 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 276601.4885 - accuracy: 0.0000e+00 - val_loss: 265063.7953 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 268121.0060 - accuracy: 0.0000e+00 - val_loss: 257077.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 259895.8346 - accuracy: 0.0000e+00 - val_loss: 249161.1492 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "527/527 [==============================] - 0s 142us/step - loss: 251831.2505 - accuracy: 0.0000e+00 - val_loss: 241754.7318 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 244009.5743 - accuracy: 0.0000e+00 - val_loss: 234122.4558 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 236281.6127 - accuracy: 0.0000e+00 - val_loss: 227088.7322 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 228817.2473 - accuracy: 0.0000e+00 - val_loss: 219976.0600 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 221476.2161 - accuracy: 0.0000e+00 - val_loss: 213114.9202 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 214358.8793 - accuracy: 0.0000e+00 - val_loss: 206346.5257 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 207388.9258 - accuracy: 0.0000e+00 - val_loss: 199755.8477 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 200636.5227 - accuracy: 0.0000e+00 - val_loss: 193288.3499 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 194024.2998 - accuracy: 0.0000e+00 - val_loss: 187180.3084 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 187674.7523 - accuracy: 0.0000e+00 - val_loss: 181050.1522 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "527/527 [==============================] - 0s 144us/step - loss: 181456.2361 - accuracy: 0.0000e+00 - val_loss: 175103.1026 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 175419.8031 - accuracy: 0.0000e+00 - val_loss: 169523.3047 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "527/527 [==============================] - 0s 144us/step - loss: 169678.9592 - accuracy: 0.0000e+00 - val_loss: 163826.1399 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 163983.1286 - accuracy: 0.0000e+00 - val_loss: 158547.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 158540.3423 - accuracy: 0.0000e+00 - val_loss: 153445.0505 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 153308.8268 - accuracy: 0.0000e+00 - val_loss: 148243.1549 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 148143.6505 - accuracy: 0.0000e+00 - val_loss: 143441.6134 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 143155.6145 - accuracy: 0.0000e+00 - val_loss: 138738.6872 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 138325.8831 - accuracy: 0.0000e+00 - val_loss: 134184.2933 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 133691.4777 - accuracy: 0.0000e+00 - val_loss: 129738.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 129189.1907 - accuracy: 0.0000e+00 - val_loss: 125254.6851 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 124751.2036 - accuracy: 0.0000e+00 - val_loss: 121165.3429 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 120534.9343 - accuracy: 0.0000e+00 - val_loss: 116976.8866 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000\n",
      "527/527 [==============================] - 0s 138us/step - loss: 116456.6748 - accuracy: 0.0000e+00 - val_loss: 113006.5516 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 112474.3251 - accuracy: 0.0000e+00 - val_loss: 109236.8000 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 108647.3802 - accuracy: 0.0000e+00 - val_loss: 105447.3583 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 104913.2246 - accuracy: 0.0000e+00 - val_loss: 101890.5319 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 101334.1374 - accuracy: 0.0000e+00 - val_loss: 98365.2036 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 97814.4421 - accuracy: 0.0000e+00 - val_loss: 94919.6895 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 94402.9424 - accuracy: 0.0000e+00 - val_loss: 91657.1177 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 91088.7299 - accuracy: 0.0000e+00 - val_loss: 88454.2989 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 87886.5787 - accuracy: 0.0000e+00 - val_loss: 85271.6791 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 84725.5747 - accuracy: 0.0000e+00 - val_loss: 82224.5241 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 81696.8323 - accuracy: 0.0000e+00 - val_loss: 79286.5846 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 78711.0298 - accuracy: 0.0000e+00 - val_loss: 76311.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 75821.4660 - accuracy: 0.0000e+00 - val_loss: 73536.7569 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 72972.0454 - accuracy: 0.0000e+00 - val_loss: 70783.3698 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 70245.7794 - accuracy: 0.0000e+00 - val_loss: 68138.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 67557.8200 - accuracy: 0.0000e+00 - val_loss: 65588.6004 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 64982.9866 - accuracy: 0.0000e+00 - val_loss: 62985.6180 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 62457.9929 - accuracy: 0.0000e+00 - val_loss: 60584.4361 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "527/527 [==============================] - 0s 146us/step - loss: 60066.7621 - accuracy: 0.0000e+00 - val_loss: 58170.6191 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 57654.3446 - accuracy: 0.0000e+00 - val_loss: 55907.9781 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 55356.9223 - accuracy: 0.0000e+00 - val_loss: 53705.7972 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 53149.8698 - accuracy: 0.0000e+00 - val_loss: 51573.2366 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 51002.2815 - accuracy: 0.0000e+00 - val_loss: 49516.6751 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 48928.7141 - accuracy: 0.0000e+00 - val_loss: 47495.4422 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 46945.6727 - accuracy: 0.0000e+00 - val_loss: 45550.8096 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 44995.3876 - accuracy: 0.0000e+00 - val_loss: 43720.9399 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 43147.8853 - accuracy: 0.0000e+00 - val_loss: 41986.0822 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 41392.7957 - accuracy: 0.0000e+00 - val_loss: 40226.1198 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 39705.0784 - accuracy: 0.0000e+00 - val_loss: 38604.8488 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 38091.3110 - accuracy: 0.0000e+00 - val_loss: 37020.2490 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 36539.9162 - accuracy: 0.0000e+00 - val_loss: 35519.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 35050.7471 - accuracy: 0.0000e+00 - val_loss: 34063.6539 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 33628.2555 - accuracy: 0.0000e+00 - val_loss: 32686.1420 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 32269.3189 - accuracy: 0.0000e+00 - val_loss: 31407.3001 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 30980.9145 - accuracy: 0.0000e+00 - val_loss: 30091.5901 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 29722.7105 - accuracy: 0.0000e+00 - val_loss: 28906.0782 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 28543.4348 - accuracy: 0.0000e+00 - val_loss: 27732.3776 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "527/527 [==============================] - 0s 144us/step - loss: 27428.4529 - accuracy: 0.0000e+00 - val_loss: 26622.7581 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "527/527 [==============================] - 0s 142us/step - loss: 26347.3143 - accuracy: 0.0000e+00 - val_loss: 25617.3103 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 25328.9268 - accuracy: 0.0000e+00 - val_loss: 24638.9457 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 24355.8819 - accuracy: 0.0000e+00 - val_loss: 23673.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "527/527 [==============================] - 0s 142us/step - loss: 23440.4981 - accuracy: 0.0000e+00 - val_loss: 22734.9427 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 22543.3894 - accuracy: 0.0000e+00 - val_loss: 21915.6342 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 21708.5635 - accuracy: 0.0000e+00 - val_loss: 21137.5541 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 20937.5942 - accuracy: 0.0000e+00 - val_loss: 20310.8744 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 20181.1153 - accuracy: 0.0000e+00 - val_loss: 19632.4683 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 19453.5200 - accuracy: 0.0000e+00 - val_loss: 18920.8893 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 18768.5459 - accuracy: 0.0000e+00 - val_loss: 18269.4762 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 18119.3675 - accuracy: 0.0000e+00 - val_loss: 17623.6693 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 17481.4680 - accuracy: 0.0000e+00 - val_loss: 17049.4938 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 16885.2491 - accuracy: 0.0000e+00 - val_loss: 16424.6313 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 16301.7098 - accuracy: 0.0000e+00 - val_loss: 15888.3328 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 15752.1655 - accuracy: 0.0000e+00 - val_loss: 15365.5208 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 15208.5147 - accuracy: 0.0000e+00 - val_loss: 14847.7612 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 14704.5044 - accuracy: 0.0000e+00 - val_loss: 14352.7615 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 14199.3209 - accuracy: 0.0000e+00 - val_loss: 13919.5113 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 13719.5897 - accuracy: 0.0000e+00 - val_loss: 13479.0236 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 13265.9069 - accuracy: 0.0000e+00 - val_loss: 13015.7855 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 12816.1661 - accuracy: 0.0000e+00 - val_loss: 12633.6666 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 12387.4460 - accuracy: 0.0000e+00 - val_loss: 12221.2160 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 11983.8243 - accuracy: 0.0000e+00 - val_loss: 11810.4950 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 11584.5792 - accuracy: 0.0000e+00 - val_loss: 11477.2693 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 11191.3958 - accuracy: 0.0000e+00 - val_loss: 11106.1241 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 10824.9798 - accuracy: 0.0000e+00 - val_loss: 10776.0855 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 10467.7310 - accuracy: 0.0000e+00 - val_loss: 10453.4962 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 10120.8537 - accuracy: 0.0000e+00 - val_loss: 10090.8265 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 9778.5014 - accuracy: 0.0000e+00 - val_loss: 9811.4553 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "527/527 [==============================] - 0s 118us/step - loss: 9456.4319 - accuracy: 0.0000e+00 - val_loss: 9528.8888 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 9148.6185 - accuracy: 0.0019 - val_loss: 9238.8644 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 8844.9119 - accuracy: 0.0019 - val_loss: 8966.0002 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 8559.5156 - accuracy: 0.0000e+00 - val_loss: 8690.9069 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 8268.2025 - accuracy: 0.0019 - val_loss: 8446.1316 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 8004.1641 - accuracy: 0.0019 - val_loss: 8210.1690 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 7740.1599 - accuracy: 0.0000e+00 - val_loss: 7987.3896 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/1000\n",
      "527/527 [==============================] - 0s 120us/step - loss: 7490.9969 - accuracy: 0.0019 - val_loss: 7733.9279 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 7248.8618 - accuracy: 0.0000e+00 - val_loss: 7541.8930 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 7004.4674 - accuracy: 0.0000e+00 - val_loss: 7318.7295 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 6781.0199 - accuracy: 0.0000e+00 - val_loss: 7096.2955 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 6562.2492 - accuracy: 0.0000e+00 - val_loss: 6904.5725 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 6349.4106 - accuracy: 0.0000e+00 - val_loss: 6736.5226 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 6137.5042 - accuracy: 0.0000e+00 - val_loss: 6560.3277 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 5938.0405 - accuracy: 0.0000e+00 - val_loss: 6362.2746 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 5737.6562 - accuracy: 0.0000e+00 - val_loss: 6186.6499 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 5552.6349 - accuracy: 0.0000e+00 - val_loss: 6031.5404 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 5375.5048 - accuracy: 0.0000e+00 - val_loss: 5854.3404 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "527/527 [==============================] - 0s 121us/step - loss: 5201.1138 - accuracy: 0.0000e+00 - val_loss: 5718.5063 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 5020.4914 - accuracy: 0.0000e+00 - val_loss: 5562.1044 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 4852.2737 - accuracy: 0.0000e+00 - val_loss: 5400.1047 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 4693.0384 - accuracy: 0.0000e+00 - val_loss: 5256.5971 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 4538.5615 - accuracy: 0.0000e+00 - val_loss: 5118.5046 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 4385.9218 - accuracy: 0.0000e+00 - val_loss: 4982.5689 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 4236.4196 - accuracy: 0.0000e+00 - val_loss: 4838.1401 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 4094.8535 - accuracy: 0.0000e+00 - val_loss: 4699.7470 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 3956.2708 - accuracy: 0.0000e+00 - val_loss: 4584.4456 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 3823.4000 - accuracy: 0.0000e+00 - val_loss: 4452.6903 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 3696.1360 - accuracy: 0.0000e+00 - val_loss: 4338.5883 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 3571.7710 - accuracy: 0.0000e+00 - val_loss: 4211.7017 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 3457.1410 - accuracy: 0.0000e+00 - val_loss: 4105.5931 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 3343.6926 - accuracy: 0.0000e+00 - val_loss: 3979.0471 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 3226.7553 - accuracy: 0.0000e+00 - val_loss: 3873.8111 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527/527 [==============================] - 0s 120us/step - loss: 3135.6417 - accuracy: 0.0000e+00 - val_loss: 3772.1565 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 3019.6696 - accuracy: 0.0000e+00 - val_loss: 3660.4356 - val_accuracy: 0.0044\n",
      "Epoch 202/1000\n",
      "527/527 [==============================] - 0s 120us/step - loss: 2916.8273 - accuracy: 0.0000e+00 - val_loss: 3601.1311 - val_accuracy: 0.0044\n",
      "Epoch 203/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 2811.8524 - accuracy: 0.0000e+00 - val_loss: 3473.3345 - val_accuracy: 0.0044\n",
      "Epoch 204/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 2725.3067 - accuracy: 0.0000e+00 - val_loss: 3372.4891 - val_accuracy: 0.0044\n",
      "Epoch 205/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 2624.3757 - accuracy: 0.0000e+00 - val_loss: 3285.6003 - val_accuracy: 0.0044\n",
      "Epoch 206/1000\n",
      "527/527 [==============================] - 0s 138us/step - loss: 2533.4295 - accuracy: 0.0000e+00 - val_loss: 3190.7039 - val_accuracy: 0.0044\n",
      "Epoch 207/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 2450.6157 - accuracy: 0.0000e+00 - val_loss: 3093.4371 - val_accuracy: 0.0044\n",
      "Epoch 208/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 2360.3389 - accuracy: 0.0000e+00 - val_loss: 3034.5726 - val_accuracy: 0.0044\n",
      "Epoch 209/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 2281.4585 - accuracy: 0.0000e+00 - val_loss: 2931.1530 - val_accuracy: 0.0044\n",
      "Epoch 210/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 2194.3969 - accuracy: 0.0000e+00 - val_loss: 2859.8068 - val_accuracy: 0.0044\n",
      "Epoch 211/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 2116.4339 - accuracy: 0.0000e+00 - val_loss: 2772.8542 - val_accuracy: 0.0044\n",
      "Epoch 212/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 2040.2216 - accuracy: 0.0000e+00 - val_loss: 2696.2749 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 1967.6399 - accuracy: 0.0000e+00 - val_loss: 2612.8152 - val_accuracy: 0.0044\n",
      "Epoch 214/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 1897.5884 - accuracy: 0.0000e+00 - val_loss: 2555.3565 - val_accuracy: 0.0044\n",
      "Epoch 215/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 1826.5232 - accuracy: 0.0000e+00 - val_loss: 2484.9069 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 1763.0228 - accuracy: 0.0000e+00 - val_loss: 2414.5251 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "527/527 [==============================] - 0s 146us/step - loss: 1702.1360 - accuracy: 0.0000e+00 - val_loss: 2353.7877 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 1637.4465 - accuracy: 0.0000e+00 - val_loss: 2287.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/1000\n",
      "527/527 [==============================] - 0s 146us/step - loss: 1576.4489 - accuracy: 0.0019 - val_loss: 2208.3970 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 1520.4263 - accuracy: 0.0038 - val_loss: 2138.5674 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 1463.3360 - accuracy: 0.0000e+00 - val_loss: 2087.0987 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 1412.8283 - accuracy: 0.0057 - val_loss: 2038.3026 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 1360.4596 - accuracy: 0.0019 - val_loss: 1978.8132 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 1310.2459 - accuracy: 0.0019 - val_loss: 1928.0565 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 1266.9801 - accuracy: 0.0019 - val_loss: 1864.6111 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 1218.3674 - accuracy: 0.0000e+00 - val_loss: 1813.0868 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 1173.8476 - accuracy: 0.0000e+00 - val_loss: 1765.2713 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 1134.2294 - accuracy: 0.0000e+00 - val_loss: 1715.5970 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 1094.8856 - accuracy: 0.0000e+00 - val_loss: 1658.6712 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 1052.5745 - accuracy: 0.0000e+00 - val_loss: 1623.1674 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 1016.1592 - accuracy: 0.0000e+00 - val_loss: 1585.7277 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 979.6388 - accuracy: 0.0000e+00 - val_loss: 1521.4355 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 944.0432 - accuracy: 0.0019 - val_loss: 1473.2841 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 907.5719 - accuracy: 0.0000e+00 - val_loss: 1455.2579 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 874.2067 - accuracy: 0.0000e+00 - val_loss: 1388.1700 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 839.7644 - accuracy: 0.0000e+00 - val_loss: 1359.2946 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 811.5312 - accuracy: 0.0000e+00 - val_loss: 1311.1659 - val_accuracy: 0.0044\n",
      "Epoch 238/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 779.0803 - accuracy: 0.0000e+00 - val_loss: 1279.5811 - val_accuracy: 0.0044\n",
      "Epoch 239/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 751.5027 - accuracy: 0.0000e+00 - val_loss: 1237.1156 - val_accuracy: 0.0044\n",
      "Epoch 240/1000\n",
      "527/527 [==============================] - 0s 142us/step - loss: 721.6626 - accuracy: 0.0000e+00 - val_loss: 1204.6034 - val_accuracy: 0.0044\n",
      "Epoch 241/1000\n",
      "527/527 [==============================] - 0s 146us/step - loss: 695.4309 - accuracy: 0.0000e+00 - val_loss: 1164.1703 - val_accuracy: 0.0044\n",
      "Epoch 242/1000\n",
      "527/527 [==============================] - 0s 144us/step - loss: 669.5185 - accuracy: 0.0019 - val_loss: 1137.7779 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/1000\n",
      "527/527 [==============================] - 0s 148us/step - loss: 644.7567 - accuracy: 0.0019 - val_loss: 1093.7785 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 617.9093 - accuracy: 0.0019 - val_loss: 1066.4708 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 593.6589 - accuracy: 0.0019 - val_loss: 1028.5773 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/1000\n",
      "527/527 [==============================] - 0s 142us/step - loss: 570.9941 - accuracy: 0.0019 - val_loss: 997.4086 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 550.3579 - accuracy: 0.0000e+00 - val_loss: 969.8330 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/1000\n",
      "527/527 [==============================] - 0s 144us/step - loss: 529.0585 - accuracy: 0.0019 - val_loss: 943.4595 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 509.7038 - accuracy: 0.0019 - val_loss: 909.8022 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/1000\n",
      "527/527 [==============================] - 0s 131us/step - loss: 490.9760 - accuracy: 0.0019 - val_loss: 883.7103 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527/527 [==============================] - 0s 137us/step - loss: 472.2381 - accuracy: 0.0019 - val_loss: 859.4104 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 454.8447 - accuracy: 0.0019 - val_loss: 836.1889 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/1000\n",
      "527/527 [==============================] - 0s 146us/step - loss: 437.8878 - accuracy: 0.0019 - val_loss: 801.6618 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 423.6093 - accuracy: 0.0000e+00 - val_loss: 773.7748 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 406.2964 - accuracy: 0.0019 - val_loss: 759.0377 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 394.7255 - accuracy: 0.0019 - val_loss: 730.7072 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 378.0170 - accuracy: 0.0000e+00 - val_loss: 715.5711 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/1000\n",
      "527/527 [==============================] - 0s 144us/step - loss: 365.1923 - accuracy: 0.0019 - val_loss: 693.6484 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 354.0676 - accuracy: 0.0000e+00 - val_loss: 661.4651 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 340.9006 - accuracy: 0.0000e+00 - val_loss: 644.2700 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 328.8410 - accuracy: 0.0019 - val_loss: 622.8616 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 318.3726 - accuracy: 0.0000e+00 - val_loss: 608.7515 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/1000\n",
      "527/527 [==============================] - 0s 129us/step - loss: 308.2945 - accuracy: 0.0000e+00 - val_loss: 585.7688 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 298.1600 - accuracy: 0.0000e+00 - val_loss: 572.2377 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 288.0800 - accuracy: 0.0000e+00 - val_loss: 550.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 278.9099 - accuracy: 0.0000e+00 - val_loss: 535.6065 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 269.8121 - accuracy: 0.0000e+00 - val_loss: 522.7531 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 262.8122 - accuracy: 0.0000e+00 - val_loss: 506.3775 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/1000\n",
      "527/527 [==============================] - 0s 127us/step - loss: 253.8322 - accuracy: 0.0000e+00 - val_loss: 495.7244 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 246.6879 - accuracy: 0.0000e+00 - val_loss: 478.8968 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 239.6071 - accuracy: 0.0000e+00 - val_loss: 461.7785 - val_accuracy: 0.0044\n",
      "Epoch 272/1000\n",
      "527/527 [==============================] - 0s 144us/step - loss: 232.0469 - accuracy: 0.0000e+00 - val_loss: 450.6017 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 225.3211 - accuracy: 0.0000e+00 - val_loss: 434.5947 - val_accuracy: 0.0044\n",
      "Epoch 274/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 219.6459 - accuracy: 0.0000e+00 - val_loss: 420.9437 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 212.9981 - accuracy: 0.0000e+00 - val_loss: 413.3917 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 207.5037 - accuracy: 0.0000e+00 - val_loss: 400.3681 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 202.6830 - accuracy: 0.0019 - val_loss: 383.5647 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 196.0736 - accuracy: 0.0000e+00 - val_loss: 380.1576 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 191.4581 - accuracy: 0.0019 - val_loss: 366.7500 - val_accuracy: 0.0044\n",
      "Epoch 280/1000\n",
      "527/527 [==============================] - 0s 120us/step - loss: 187.0347 - accuracy: 0.0000e+00 - val_loss: 356.0096 - val_accuracy: 0.0044\n",
      "Epoch 281/1000\n",
      "527/527 [==============================] - 0s 116us/step - loss: 182.2007 - accuracy: 0.0019 - val_loss: 350.1970 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 177.8578 - accuracy: 0.0000e+00 - val_loss: 335.2177 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "527/527 [==============================] - 0s 120us/step - loss: 173.6928 - accuracy: 0.0019 - val_loss: 326.8974 - val_accuracy: 0.0044\n",
      "Epoch 284/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 169.6251 - accuracy: 0.0019 - val_loss: 317.4733 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 166.1130 - accuracy: 0.0000e+00 - val_loss: 310.2527 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 162.0768 - accuracy: 0.0000e+00 - val_loss: 304.9521 - val_accuracy: 0.0044\n",
      "Epoch 287/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 160.0670 - accuracy: 0.0019 - val_loss: 301.0221 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 157.5340 - accuracy: 0.0000e+00 - val_loss: 287.8327 - val_accuracy: 0.0044\n",
      "Epoch 289/1000\n",
      "527/527 [==============================] - 0s 142us/step - loss: 152.2937 - accuracy: 0.0000e+00 - val_loss: 278.9341 - val_accuracy: 0.0044\n",
      "Epoch 290/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 149.4457 - accuracy: 0.0000e+00 - val_loss: 274.7000 - val_accuracy: 0.0044\n",
      "Epoch 291/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 147.1549 - accuracy: 0.0000e+00 - val_loss: 271.0670 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 142.9152 - accuracy: 0.0000e+00 - val_loss: 256.1600 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 141.7004 - accuracy: 0.0000e+00 - val_loss: 251.2816 - val_accuracy: 0.0044\n",
      "Epoch 294/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 138.5140 - accuracy: 0.0000e+00 - val_loss: 246.8335 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/1000\n",
      "527/527 [==============================] - 0s 123us/step - loss: 136.5394 - accuracy: 0.0019 - val_loss: 239.9622 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "527/527 [==============================] - 0s 140us/step - loss: 134.2094 - accuracy: 0.0000e+00 - val_loss: 236.8044 - val_accuracy: 0.0044\n",
      "Epoch 297/1000\n",
      "527/527 [==============================] - 0s 142us/step - loss: 133.2762 - accuracy: 0.0000e+00 - val_loss: 230.7223 - val_accuracy: 0.0044\n",
      "Epoch 298/1000\n",
      "527/527 [==============================] - 0s 148us/step - loss: 130.2263 - accuracy: 0.0000e+00 - val_loss: 225.7013 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/1000\n",
      "527/527 [==============================] - 0s 139us/step - loss: 128.7036 - accuracy: 0.0000e+00 - val_loss: 221.2115 - val_accuracy: 0.0044\n",
      "Epoch 300/1000\n",
      "527/527 [==============================] - 0s 137us/step - loss: 126.0195 - accuracy: 0.0000e+00 - val_loss: 219.2181 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/1000\n",
      "527/527 [==============================] - 0s 125us/step - loss: 124.2879 - accuracy: 0.0000e+00 - val_loss: 214.3124 - val_accuracy: 0.0044\n",
      "Epoch 302/1000\n",
      "527/527 [==============================] - 0s 135us/step - loss: 123.3695 - accuracy: 0.0000e+00 - val_loss: 210.3564 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000\n",
      "527/527 [==============================] - 0s 133us/step - loss: 121.5806 - accuracy: 0.0000e+00 - val_loss: 210.5756 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(x_train,y_train,epochs=1000, batch_size=10, validation_data=(x_test,y_test),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax=plt.subplots()\n",
    "acc_ax=loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='upper right')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model.predict(xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(yhat)\n",
    "plt.plot(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1320.1549 ],\n",
       "       [1257.4115 ],\n",
       "       [1338.8611 ],\n",
       "       [1365.4257 ],\n",
       "       [1347.463  ],\n",
       "       [1305.7493 ],\n",
       "       [1233.6555 ],\n",
       "       [1152.9353 ],\n",
       "       [1195.3937 ],\n",
       "       [1169.4849 ],\n",
       "       [1052.8802 ],\n",
       "       [1087.621  ],\n",
       "       [1000.52344],\n",
       "       [ 979.0193 ],\n",
       "       [ 945.08344],\n",
       "       [1001.8591 ],\n",
       "       [1002.8226 ],\n",
       "       [ 914.8589 ],\n",
       "       [1000.4891 ],\n",
       "       [1009.8391 ],\n",
       "       [1028.0492 ],\n",
       "       [1023.38116],\n",
       "       [1023.7537 ],\n",
       "       [1062.5815 ]], dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 1)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 4)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
